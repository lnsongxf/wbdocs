Options for Results Monitoring and Evaluation for
         Resilience-building Operations
                   Anna Williams




Scoping Paper

April 2016
© 2016 International Bank for Reconstruction and Development / International Development Association or

The World Bank
1818 H Street NW
Washington DC 20433
Telephone: 202-473-1000
Internet: www.worldbank.org

This work is a product of the staff of The World Bank with external contributions. The findings, interpretations,
and conclusions expressed in this work do not necessarily reflect the views of The World Bank, its Board of
Executive Directors, or the governments they represent.

The World Bank does not guarantee the accuracy of the data included in this work. The boundaries, colors,
denominations, and other information shown on any map in this work do not imply any judgment on the part
of The World Bank concerning the legal status of any territory or the endorsement or acceptance of such
boundaries.



Rights and Permissions

The material in this work is subject to copyright. Because The World Bank encourages dissemination of its
knowledge, this work may be reproduced, in whole or in part, for noncommercial purposes as long as full attribution
to this work is given.

Any queries on rights and licenses, including subsidiary rights, should be addressed to World Bank Publications,
The World Bank Group, 1818 H Street NW, Washington, DC 20433, USA; fax: 202-522-2625; e-mail:
pubrights@worldbank.org.


Cover photo credit: Mahfuzul Hasan Rana
Table of Contents


Executive Summary ....................................................................................................................................................... 1

I.            Introduction..................................................................................................................................................... 3
II.           M&E Overarching Objectives and Components ................................................................................ 9
III.          Overview of Climate and Disaster Resilience M&E Work .......................................................... 15
IV.           Resilience M&E Insights .......................................................................................................................... 32
V.            Recommendations ..................................................................................................................................... 37
VI.           Path Forward ............................................................................................................................................... 52


Annex 1. Bibliography ............................................................................................................................................. 54
Annex 2. World Bank Project Indicator Examples ....................................................................................... 61
Annex 3. PPCR Results Framework ................................................................................................................... 64
Annex 4. Reference List of Indicators Used by Selected Institutions/Efforts ................................... 65
Annex 5. Considerations Regarding Results Frameworks ........................................................................ 74
List of Acronyms

CCA          Climate change adaptation
CIF          Climate Investment Funds
DFID         United Kingdom Department for International Development
DIME         Development Impact Evaluation Initiative
DRM          Disaster risk management
GCF          Green Climate Fund
GFDRR        Global Facility for Disaster Reduction and Recovery
GEF          Global Environment Facility
GEFEO        Global Environment Facility Evaluation Office
GIS          Geographic Information System
IBRD         International Bank for Reconstruction and Development
IDA          International Development Association
IEG          Independent Evaluation Group
IPCC         Intergovernmental Panel on Climate Change
LDCF/ SCCF   Global Environment Facility Least Developed Countries Fund and the
             Special Climate Change Fund
OECD         Organization for Economic Cooperation and Development
PPCR         Pilot Program for Climate Resilience
RMS          Results Measurement System
SCCF         Special Climate Change Fund
SFDCC        Strategic Framework on Development and Climate Change
SPCR         Strategic Program for Climate Resilience
TAMD         Tracking Adaptation and Measuring Development
UNFCCC       United Nations Framework Convention on Climate Change
WB           World Bank
Acknowledgments
This publication was prepared by Anna Williams, under the direction of Nathan Engle (Climate
Change Specialist, Climate Change Policy Team) and Ulf Narloch (Economist, Sustainable
Development Practice Group). Christina Irene also provided research and analytical
contributions to this work, and Paula Garcia, Patricia Braxton, and Perpetual Boateng provided
valuable support to the team. Management oversight was provided by Stephen Hammer
(Manager, Climate Change Policy Team) and Marianne Fay (Chief Economist, Sustainable
Development Practice Group).

The study was produced under the Resilience Monitoring & Evaluation project, which is part of
a broader Programmatic Approach on Enhancing Climate and Disaster Resilience of World Bank
Sustainable Development Operations.

We wish to acknowledge with gratitude the inputs of those that participated in the September
2015 World Bank Workshop on Measuring Resilience—Strengthening Monitoring and
Evaluation for Resilience-building Operations: Dinara Akhmetova, Margarita Arguelles,
Charlotte Benson, Rosina Bierbaum, Andy Blohm, Dennis Bours, Ademola Braimoh, Ayesha
Dinshaw, Ana Elisa Bucher, Doreen Bwalya, Shun Chonabayashi, James Close, Ana Campos
Garcia, Ken Chomitz, Eric Dickson, Maricarmen Esquivel, Isidro Fote, Francis Ghesquiere, Habiba
Gitay, Stephane Hallegatte, Rumana Huque, Fareeha Iqbal, Kazuko Ishigaki, Chiyo Kanda, Melanie
Kappes, Debra Knopman, Florence Kondylis, Kouassi Emmanuel Kouadio, Carolyn Kousky,
Holger Kray, Timo Leiter, Hugh MacLeman, Nancy MacPherson, David Maleki, Lizardo Narvaez
Marulanda, Krishna Matturi, Heather McGray, Andre Mershon, Davinah Milenge-Uwella, Chris
Nelson, Becky Nicodemus, Robert Phillips, Alison Pollard, Sumati Rajput, Martin Ras, Christine
Roehrer, Esther Rojas-Garcia, Julie Rozenberg, Rebecca Soares, Junu Shrestha, Vladimir Stenek,
Carol Tan, Luis Tineo, Hori Tsuneki, Cassidy Travis, and Sam Wedderbuen.

This publication was supported in part by the Global Facility for Disaster Reduction and
Recovery (GFDRR).
Executive Summary
Across the world, donors and a broad array of stakeholders are seeking to understand whether
climate change adaptation, disaster risk management, and other resilience interventions are
working, and what lessons from early implementation of investments can be shared to inform the
field and improve results over time. Monitoring and evaluation (M&E) can play an important role
in achieving these objectives toward learning, accountability, and improved impact.

The World Bank (WB) 1 has commissioned this paper and initiated a related program of work
focused on M&E of operations that build resilience to both climate-related natural disasters and
long-term climatic changes, or “climate and disaster resilience M&E” for shorthand. This program
of work forms part of a programmatic approach to enhancing climate and disaster resilience of WB
operations. Climate and disaster resilience M&E has been rapidly evolving over recent years, with
increasing investment in M&E of both mitigation and adaptation. Still, this field is nascent and
rapidly evolving.

This paper synthesizes recent work on climate and disaster resilience M&E to help identify
emerging lessons from early applications and to define the key steps to develop a M&E system
for climate and disaster resilience-building operations, particularly at the project level. Another
objective of this paper is to support dialogue among a broader group of M&E experts and resilience
project managers and implementers to further advance the design, implementation, and utility of
climate and disaster resilience M&E.2

The paper explains overarching objectives and components for climate and disaster resilience
M&E, including the common M&E objectives of learning and accountability, and four
primary M&E components: principles, results frameworks, indicators, and evaluation.

The paper provides an illustrative overview of climate and disaster resilience M&E work being
undertaken within and beyond the WB. Described are examples of M&E systems, other resilience
and related M&E work at the WB, and broader efforts to build capacity for climate and disaster
resilience M&E.

For many projects and programs, particularly those associated with the recent increased level of
investment in climate change resilience, M&E is in the early stages of implementation. Much is
being learned about what indicators of resilience are useful for understanding results, especially
mid- and long-term outcomes and impacts, which are particularly difficult to measure in a
resilience context. Evaluations beyond those in place to meet minimum/routine requirements
are to date less common. Experts are considering how evaluation of climate and disaster
resilience can be conducted to authoritatively inform project design and implementation, as well
as provide credible evidence of results.


1 The WB is comprised of the International Development Association (IDA) and the International Bank for
Reconstruction and Development (IBRD) within the World Bank Group.
2 This report was initially prepared prior to a technical workshop held on September 23-24, 2015. It was

subsequently updated to reflect the ideas generated by workshop participants and further reflection on the
work to date.


                                                    1
A set of high-level climate and disaster resilience M&E insights and good practices has emerged
based on experience to date. Three high-level insights are that:
   1. Wicked problems3 require creative, adaptive solutions;
   2. Climate and disaster resilience M&E poses a number of methodological challenges;
       and
   3. The field of climate and disaster resilience M&E is young and learning (quickly)
       from experience.

The experience to date with climate and disaster resilience M&E has illustrated that:
    It is easy to be overly ambitious at first.
    Basing climate and disaster resilience M&E systems on what others are doing is not
       enough.
    Still, insights can be gained from others’ innovations, both within and outside of the
       climate and disaster resilience sector.
    Stakeholder engagement is particularly critical for climate and disaster resilience
       M&E; and
    It is wise to plan to learn from early experience and adapt M&E systems accordingly
       over time.

Acting upon five high-level recommendations will support an effective climate and
disaster resilience M&E system. The recommendations are oriented for the WB, given its
current, relatively early stage of advancing a climate and disaster resilience M&E system
that can be used both for and across projects, if not also across programs. The
recommendations are also generally applicable to other large, multi-program, multi-
sectoral institutions seeking to develop or refine their own climate and disaster resilience
M&E. The recommendations are:
    1. Adopt an operational definition of resilience, while allowing individual programs to use
       their own (comparable) definitions.
    2. Develop a set of overarching guiding principles for climate and disaster resilience M&E.
    3. Identify a preliminary results framework for climate and disaster resilience M&E.
    4. Define and test a set of indicators.
    5. Develop guidance on evaluation options.




3The term “wicked problem” was originally coined in 1967 by Churchman, C. West in "Wicked Problems".
Management Science 14 (4) and then built upon by Rittel, Horst W. and M. Webber (1973) in "Dilemmas in a
General Theory of Planning" Policy Sciences 4: 155–169. It has been applied to climate change and other
resilience challenges. See also, Levin, Kelly, et al (2012). "Overcoming the tragedy of super wicked problems:
constraining our future selves to ameliorate global climate change" Policy Sciences 45 (2): 123–152.

                                                      2
I. Introduction
Background
Global investments in adapting to climate change, and managing risk associated with natural
hazards and disasters have increased dramatically in recent years, with unprecedented
commitments made by international finance institutions and bilateral donors, as well as funders
in other sectors including philanthropy. As attention to the pressing needs of climate change
grows—and is more and more recognized across sectors—so does the demand for
understanding the progress we are collectively making toward both climate change adaptation
(CCA) and disaster risk management (DRM). Investing in climate and disaster resilience yields
direct benefits as well as “spill over” co-benefits that can be social, economic, and/or
environmental (Overseas Development Institute et al. 2015).

Donors, practitioners, and stakeholders are seeking to understand what CCA and DRM or
resilience interventions work and do not work, and what lessons from early implementation of
investments can be shared to inform the field and improve results over time. Monitoring and
evaluation (M&E) play an important role in gauging progress toward impact as well as
supporting the climate finance field to become more strategic and effective over time. Climate
and disaster resilience M&E has been rapidly evolving over recent years. As described below,
finance institutions have established M&E systems—and some have already revised and
improved these based on early experience—and evaluations of resilience interventions are
becoming more common as interventions are being implemented.

The climate and disaster resilience M&E field is considered a multi-part field, divided into CCA
and DRM initiatives. This paper focuses on M&E of operations that build resilience to both
climate-related natural disasters and long-term climatic changes, or “climate and disaster
resilience M&E” for shorthand. M&E of climate change mitigation is not the focus here, however,
there are instances where M&E of mitigation and resilience overlap, particularly where climate
change investments have synergies that cross over both realms, such as protection of vital forests
and other natural resources.

Many climate and disaster resilience programs and projects are just getting underway—and
achieving resilience is a long-term objective with few concrete and easily measurable mileposts
along the way—posing challenges in terms of identifying results for M&E purposes. Further, as
discussed below, resilience is complex, dynamic, and context-specific. Even some basic M&E
fundamentals, such as establishing baselines, are particularly challenging in the context of
climate and disaster resilience M&E.

The M&E field is therefore positioned to innovate, experiment, and learn from the good practices
emerging across many sectors. Both traditional and new M&E approaches are being tested, and
insights are being gained on how to approach these particular M&E challenges. Those in the
forefront of the climate and disaster resilience M&E field recognize that it involves learning by
doing, just like resilience itself requires. Still, there is a set of emerging lessons and good
practices, as well as several recent publications with guidance to help launch or improve climate
and disaster resilience M&E systems.

                                                3
This paper synthesizes recent work on climate and disaster resilience M&E so as to identify
existing approaches. This work was commissioned by the World Bank (WB)4 to inform a new
program on climate and disaster resilience M&E, particularly at the project level. This program
was initiated as part of a programmatic approach to enhancing climate and disaster resilience of
WB operations.

Another objective of this paper is to support dialogue among a broader group of M&E experts
and resilience project managers and implementers in order to further advance thinking around
climate and disaster resilience M&E, and in so doing, strengthen climate and disaster resilience
M&E both at the WB and beyond.

Resilience Building Initiatives at the World Bank

Resilience initiatives are gaining increasing attention and priority at the WB and beyond. For
example, the WB helped countries secure nearly US$4.1 billion in 2013, and US$5.9 billion in
2014—funding that contributed to climate and disaster resilience (World Bank 2015a). With
donor money pouring into the resilience sector, it is critical that the development community
have the necessary capacity and tools in place to monitor and evaluate its effort for transparency,
accountability, learning, and impact.

At the WB, there is increasing demand for robust methodologies and indicators that measure the
resilience results achieved by WB operations to integrate resilience in WB corporate
measurement frameworks, such as the World Bank Group’s Corporate Scorecard 5 , the
International Development Association’s (IDA) Results Measurement System (World Bank
2015e), the core sector indicators (World Bank 2012, 2013), and other sectoral and project
results frameworks.

These frameworks are generally structured around three tiers: (i) “Development context”
measuring progress on development goals made by WB client countries (Tier 1); (ii) “Results”
measuring sectoral and cross-sectoral results supported by WB-financed operations (i.e.,
projects) (Tier 2); and “Performance” measuring operational and organizational effectiveness of
the WB (Tier 3). We refer in this paper to national-level, project-level, and performance-level
indicators to reflect Tier 1, Tier 2, and Tier 3, respectively. While there are inter linkages between
these three tiers, this work focuses on the project-level tier (Tier 2). Additional work is ongoing
to better measure development goals (Tier 1) and WB performance related to resilience (Tier 3).

Despite ongoing work by several units within the WB and other development institutions, a
harmonized climate change and disaster resilience M&E framework and corresponding
measurement approaches for such resilience-building operations are lacking. This is also largely
the case across the broader climate finance and development community, which is only now

4 The WB is comprised of the International Development Association (IDA) and the International Bank for
Reconstruction and Development (IBRD) within the World Bank Group
5 The Corporate Scorecard provides a high-level and strategic overview of the World Bank Group’s

performance toward achieving the institution’s goals. It is the apex from which indicators cascade into the
monitoring frameworks of the WB, and the International Finance Cooperation and Multilateral Investment
Guarantee Agency. See http://www.worldbank.org/en/about/results/corporatescorecard

                                                    4
beginning to make inroads into climate and disaster resilience M&E. Although some technical
solutions exist, they have either found limited application due to the costs and capacities
required or are largely in the nascent stages of development or field-testing. To date, very few
of these solutions have been applied at scale or assessed in term of overarching utility and
relevance.

Even though there is enough knowledge and experience upon which to base a solid foundation
for climate and disaster resilience M&E, further field experience over the next few years will
inform and advance the body of knowledge substantially.

Regarding the Terms Adaptation, Disaster Risk Management, and
Resilience
As noted above, this paper focuses on projects/operations that build resilience to both climate-
related natural disasters and long-term climatic changes (i.e., climate and disaster resilience).
Many of the terms and concepts at the center of climate and disaster resilience M&E, including
the term resilience, do not have standard definitions, and as a result can cause confusion and
analytical challenges. As briefly discussed below, for the purposes of this scoping paper, we refer
to definitions used by others in the field, acknowledging definitional differences and the
challenges they can lead to.

At the same time, at the systems level, the overarching issues—including M&E challenges and
opportunities—are consistently identified and agreed upon field-wide. Therefore, advancing
climate and disaster resilience M&E does not appear to be hampered by the current lack of
standard nomenclature. Still, an understanding of how these terms are defined and useful for
perspective and conceptual clarity, and therefore some discussion of these terms is provided.

Adaptation versus Resilience

Much of the work done on climate and disaster M&E has been done in the context of climate
change adaptation, resilience, and/or DRM. Reviewing definitions used for these terms provides
a conceptual underpinning to the remainder of this paper, which generally refers to “resilience”
to capture the concepts of adaptation as well as DRM.

Adaptation has been defined by the Inter-governmental Panel on Climate Change (IPCC) in a
few ways:

   In 2007, the IPCC defined “adaptation” as the process of adjustments to actual or expected
   climate and its effects, in order to moderate harm or exploit potential benefits (IPCC 2007).

A more recent IPCC definition for adaptation is:
   Adjustments in ecological, social, or economic systems in response to actual or expected
   climatic stimuli and their effects or impacts. [Adaptation] refers to changes in processes,
   practices, and structures to moderate potential damages or to benefit from opportunities
   associated with climate change (UNFCCC 2014).



                                                 5
Others have various definitions of adaptation as a process, adjustment, set of practical steps, or
outcome (see OECD 2006).

Definitions of resilience tend to center on a system’s ability to anticipate, respond, and recover
from hazardous events in a way that maintains if not improves essential structures and
functions. The Rockefeller Foundation explains how resilience is “the capacity of individuals,
communities and systems to survive, adapt, and grow in the face of stress and shocks, and even
transform when conditions require it. Building resilience is about making people, communities
and systems better prepared to withstand catastrophic events—both natural and manmade—
and able to bounce back more quickly and emerge stronger from these shocks and stresses ”
(Rockefeller Foundation 2015).

The concept of resilience thus has additional components beyond adaptation’s focus on adjusting
to minimize harm. Again, as with adaptation there is no one correct or best definition, nor
necessarily does there need to be. It is more a matter of being aware of the fact that there are a
variety of definitions and have some understanding of their similarities and (typically) subtle
differences.

The IPCC in its 2014 Fifth Assessment Report uses a definition of resilience developed by the
Arctic Council:
   The capacity of a social-ecological system to cope with a hazardous event or disturbance,
   responding or reorganizing in ways that maintain its essential function, identity, and
   structure, while also maintaining the capacity for adaptation, learning, and
   transformation (Arctic Council 2013).

Another definition of resilience, more directly related to development, used by the United
Kingdom’s Department for International Development (DFID) report, is:
   The ability of countries, communities, and households to manage change, by maintaining or
   transforming living standards in the face of shocks or stresses without compromising their long-
   term prospects (UK DFID 2011).

These above definitions span a range of hazardous events including but not exclusive to climate
change rather than singling out climate change as part of the definition. Indeed, building climate
and disaster resilience may require addressing climate and non-climate stressors.

Some organizations, including the Climate Investment Funds (CIF), are using resilience (instead
of adaptation) as the overarching organizing construct for some of their programs, though many
international climate finance institutions (e.g., the IPCC, Adaptation Fund, Global Environment
Facility (GEF), Green Climate Fund (GCF), and other bilateral institutions) still default to
categorizing the major climate change categories as mitigation and adaptation. There could be
a conscious shift toward a more holistic resilience view as compared to adaptation. Still, there is
a lack of consensus—or even overt discussion—among practitioners on how concepts relate and
whether this relationship is of paramount importance. Some continue to view adaptation as the
overarching construct under which resilience belongs—as a subfield; whereas others view
resilience as a broader and thus more preferable concept as compared to adaptation.



                                                6
Resilience versus DRM

Along these lines, this paper also considers the concept of DRM to be embraced within the term
resilience, while also considering that DRM has an even more explicit focus on up-front planning
and design—concepts embedded within resilience though not always clearly spelled out.

A common definition of DRM used by the IPCC and others is as follows:

      Processes for designing, implementing and evaluating strategies, policies and measures to
      improve the understanding of disaster risk, foster risk reduction and transfer, and promote
      continuous improvement in disaster preparedness, response and recovery practices, with the
      explicit purpose of increasing human security, wellbeing, quality of life and sustainable
      development (IPCC 2012).

CCA and DRM go hand-in-hand in reducing risk and building resilience. To build resilience, it is
necessary to incorporate both CCA—focused on long-term objectives—and DRM—more focused
on short-term risk reduction, prevention, and protection—into the broader resilience of projects
and larger-scale interventions.

Ultimately, there is no single “right” definition, and it may not be necessary to adopt one single
definition for resilience or the other related terms, given the similarity in different definitions’
intents and scope, and slight variations in definitions usually do not affect M&E, even though they
should be noted. As noted in the recommendations below, an overarching definition for
resilience may be adopted, likely based on the Arctic Council definition referred to by the IPCC—
while still allowing programs to use variations on this definition as long as they are not
incompatible conceptually.

Again, for the sake of simplicity, this paper uses the term climate and disaster resilience
throughout to cover the concepts of adaptation, resilience, and DRM.



Objectives and Organization of this Scoping Study
The specific objectives of this scoping study are as follows:
   1. Identify approaches suitable for results monitoring and impact evaluation for climate and
      disaster resilience-building operations.
   2. Inform a technical expert workshop, held on September 23-24, 2015, designed to
      formulate recommendations for developing indicators and measurement approaches for
      results monitoring and evaluation studies for climate and disaster resilience-building
      operations. This report was initially prepared prior to the workshop as a preparatory
      paper. It was subsequently updated to reflect the ideas generated by workshop
      participants and further reflection on the work to date.




                                                 7
This study is organized in six sections, starting with this Introduction, as follows:

 Section II, M&E Overarching Objectives and Components, provides background on
 fundamental building blocks of M&E.

 Section III, Overview of Climate and Disaster Resilience M&E work, summarizes related
 M&E work within the WB and among peer institutions.

 Section IV, Climate and Disaster Resilience M&E Insights, offers high-level lessons and
 good practices ideas based on experience with climate and disaster resilience M&E to
 date.

 Section V, Recommendations, provides high-level recommendations for advancing this
 work.

 Section VI, Path Forward, offers summary reflections and ideas on next steps.




                                                8
II. M&E Overarching Objectives and Components
Overarching M&E Objectives
The two central objectives of M&E are learning and accountability, with each of these emphasized
to different degrees in different applications. M&E both support accountability and learning, in
different ways. For example, monitoring supports routine reporting which can be used for both
accountability and learning purposes, whereas evaluation typically provides independent
assessments of results achieved and where the greatest opportunities for learning and
improvement lie. For the purposes of this scoping study, we assume that M&E systems are
intended to support both learning and accountability, and specific applications of M&E can
emphasize one or the other of these (or both). Other objectives may also apply on an ad-hoc
basis.

High-level M&E Components
For the purposes of this paper, M&E is conceptualized according to four components:
   1. Results frameworks
   2. Indicators
   3. Monitoring and Reporting
   4. Evaluation

As shown in Exhibit 1 below, a results framework—often depicted as a theory of change, logic
model, or log frame—identifies the intended results an intervention aims to achieve and the
logical cause-and-effect relationship between the intervention’s inputs and activities and these
results. Indicators are then identified as markers of progress toward the intended results
outlined in the results framework. Monitoring and reporting is then based on these indicators,
often at annual (or more/less frequent) intervals, to take stock of progress and support routine
management and accountability purposes.

Evaluation is a separate analysis that draws upon all the aforementioned components, but also
involves additional independent data collection and analysis. Evaluation typically examines why
and how results have been achieved, what has worked well and not worked well, and what kind
of changes to design and implementation could improve results. Although evaluation often takes
place either mid-course during an intervention or after an intervention is completed, different
evaluation types are planned and implemented at any stage.

On occasion, M&E systems include other components, such as knowledge management systems.
These may or may not be considered part of M&E, and are therefore considered supplementary
unless otherwise noted on an ad-hoc basis.


                                               9
Additional discussion of these concepts is included below.


                         Exhibit 1. Primary Components of an M&E System


 Results Framework                          Indicators                        Monitoring &
                                                                              Reporting
                                Serves as                         Serves as
                                basis for                         basis for

 Answers: What are we                       Answers: What do we               Answers: How are we
 trying to achieve and how                  use to track and                  doing?
 are we going to achieve it?                measure progress
                                            toward results?



                                                   Informs




  Evaluation
  Evaluation

  Involves additional independent data collection and analysis.

  Answers: What results—outcomes and impact—have been achieved? What worked well and did not work
  well, and why? What lessons can be identified from implementation? How can project design be
  improved?




1. Results Frameworks

Results frameworks are the overarching conceptual guideposts that generally serve as the basis
for M&E. Most M&E frameworks are based on visual tools such as theories of change, log frames,
logic models, or similar results frameworks. These tools visualize the pathway connecting inputs
and activities to anticipated outcomes through a set of causal mechanisms. The tools can be
applied at different levels, including project, program, portfolio, and institutional.

M&E frameworks are the basis for establishing a monitoring system—to track progress toward
results according to the log frame (or equivalent). Indicators, the fundamental component of
most monitoring systems, are usually chosen because they measure progress toward realizing
the log frame. Similarly, evaluations are often aimed at determining whether the log frame as
visualized is viable in practice, whether progress toward the intended results is occurring as
envisioned, and what changes to the design—including the log frame itself—and implementation
could improve outcomes and impact.


                                                      10
Several equivalent and alternative tools can also be used
                                                               Exhibit 2. Typical Levels of a Results
to depict project/program logic and casual mechanisms.
                                                                            Framework
These include results chains, results hierarchies, impact
chains, outcome maps, and other tools. There is no              Impact
“right” tool to use; however, the most common among             The ultimate durable change, long-term
international climate finance institutions are linear,          condition, or end state sought
typically hierarchical logic models or log frames. These
tools define a combination of the targeted inputs,
activities, outputs, outcomes, and impacts (short,              Outcomes
medium, and/or long-term impacts) that interventions            Intended project/program results (can
intend to achieve. Exhibit 2 provides a simplified              be separated into shorter- and longer-
                                                                term
explanation of these terms and what they mean; noting
that there is some variation in how these terms are
defined and used by different institutions.6
                                                                Outputs
                                                                What the project/program produces
Note as well that some institutions depict these
frameworks vertically with impact at the top, others
depict these vertically with activities or inputs at the top
(and impact at the bottom), and others choose                Inputs
horizontal frameworks with activities/inputs on the left     What actions, strategies, or products
and impact on the right. Some institutions have              the project/program provides
organizational level frameworks, and then more specific
frameworks for programs and/or projects. At the WB, each project has its own results
framework, and these are also aligned with each project’s respective funding source or strategic
program. These results frameworks are structured around results directly related to the project
development objectives and intermediate results that contribute to these final objectives.

2. Indicators

Indicators are measures used to demonstrate the status of an activity, project, or program. Over
time, reporting on indicators provides information on whether a certain condition exists or
certain results have been achieved. Indicators are defined by the physical, social, financial, or
other measured dimension, such as, for example, the percentage of households served by early
warning systems.

Indicators are typically first measured against a baseline—the status or condition before the
intervention is implemented. Targets for each indicator are typically set to measure change
relative to the baseline. For example, a target could be a 50 percent increase in households
served by early warning systems as compared to a baseline of 10 percent.

Indicators are usually designed to be quantifiable—to be aggregatable and comparable across
countries, projects, and programs. However, there also exist customized, qualitative indicators
and other data collection approaches, such as routine progress reports.

3. Monitoring and Reporting

6A lack of standard nomenclature does not disrupt progress on M&E system design or delivery even though
refinements and more standard usage would benefit the field in the long run.

                                                  11
Monitoring generally refers to the systematic tracking of indicators as well as tracking of other
routine data to serve ongoing management and fiduciary purposes. Monitoring occurs at
different intervals depending on the context and application; intervals can range from daily or
continuous monitoring to monitoring every two to five years for long-term interventions with
measures that are slow to change.

Reporting on the monitored data/indicators occurs at intervals which range in frequency;
however semi-annual, annual, and biennial reporting are common intervals.

4. Evaluation7

Evaluation is a systematic and impartial assessment often focused on identifying the results of
projects or programs in an authoritative and defensible manner. Organizations often define
evaluation slightly differently. One commonly used definition is from the Organization for
Economic Co-operation and Development (OECD), which defines evaluation as the systematic
and objective assessment of an ongoing or completed project, program, or policy, including its
design, implementation and results (UNODC 2015).

There are numerous types of evaluation, including developmental, empowerment, ex-post,
formative, impact, meta, mid-term, outcome, participatory, portfolio, program, summative,
terminal, thematic, and utilization-focused.8

Unfortunately, there is no standard evaluation typology or even standard set of definitions for
specific evaluation types, however this list reflects many of the common evaluation types for
climate change and DRM interventions. Also, most evaluations—regardless of label or type— are
based on similar core concepts:
       Overarching objectives of accountability and learning;
       Ensuring that evaluations are based on independent and impartial assessments;
       Understanding whether interventions are designed well and working as intended; and
       Identifying lessons and possible recommendations to improve results and impact.

From these conceptual starting points, most evaluation types—and the specific methods they
use—are simply variations on these core concepts. Learning is intended to be embedded into
evaluation to connect lessons from implementation with future adaptation and improvement
throughout the project/program cycle—links that are too often missing as shown in Exhibit 3
below. The timing of evaluation is also often a critical issue, requiring close linkages with the
operational and/or strategy cycle to be effective. While many organizations espouse continuous
learning and adaptation as part of their culture and practice, actual efforts to use evaluation in
this way often fall flat (Williams 2014).


7 Information in this section is partially based on Williams, A. & World Bank E Institute. 2015. Climate Change
Mitigation M&E E Learning Course. Internal working draft.
8 This is not an exhaustive list of evaluation types and some of these evaluation types are very similar, even if

they go by different names.

                                                       12
One type of evaluation is rigorous impact evaluation
using experimental or quasi-experimental design.         Exhibit 3. The Oft-missing Learning
This is important to note because the term “impact       Link
evaluation” refers to two general approaches,
explained more below: (1) statistically rigorous
impact evaluations that collect (observed) data
using experimental or quasi-experimental design
techniques, and (2) impact evaluations that do not
use control and treatment groups or that use other
methods to retrospectively try to establish what
would have happened in the absence of the
intervention (a.k.a. the counterfactual).

Group 1 involves implementing the project with a
control group, or those not receiving the
intervention, and a treatment group, or those Source: Williams 2014.
intentionally receiving the intervention. This helps
to test what happens both with and without the project to quantitatively analyze causal links
between projects and particular outcomes. This approach offers more statistical rigor than ex-
post impact evaluations, but is not suitable for all projects.

The methods used in this kind of statistically rigorous impact evaluation generally refer to how
the control and treatment groups are selected. Two common methods used are experimental
design and quasi-experimental design.

Experimental design involves randomly allocating eligible participants into treatment or
control groups to ensure that the only difference between the two groups is that the measured
intervention is provided to the treatment group (not the control group).

Quasi-experimental design involves constructing a comparison group using matching or
reflexive comparisons. Matching involves identifying non–program participants comparable in
observable characteristics to participants to create two groups that can be compared as if they
were treatment and control groups—even though they are not randomly selected treatment and
control groups as in the experimental approach. Advantages of evaluations using quasi-
experimental matching methods is that they do not require as close collaboration between the
research design and the operational roll out of the program, and they often cost less to
implement than the experimental approach. The principal disadvantages are that the reliability
of the results is often reduced. Two quasi-experimental methods used are propensity score
matching and regression discontinuity design. To date, this kind statistically rigorous impact
evaluation is only beginning to be tested on climate change resilience operations. (One example
of an impact evaluation being planned for a Pilot Program for Climate Resilience (PPCR) project
in Mozambique is discussed below.)

Group 2—the second type of impact evaluation—is more common. This type of impact
evaluation is undertaken retrospectively after projects are completed—observed data are not
collected for the evaluation during project implementation itself. These impact evaluations
either do not identify a counterfactual or they create a hypothetical counterfactual scenario that
is not based on data collected through direct observation. Several different methods can be used
                                               13
for this generalized “group”—though as a basic rule the methods used for these impact
evaluations are typically less statistically rigorous from an economics perspective. On the other
hand, these kinds of ex-post impact evaluations are more feasible and less costly than statistically
rigorous impact evaluations which use experimental or quasi-experimental methods. And some
are quite systematically rigorous, using different analytical techniques.

Notably, there is a healthy debate within the evaluation field about the relevance and
appropriateness of this evaluation approach for resilience. This debate is not exclusive to
climate and disaster resilience—it is a broader debate about applying these methods to any
complex development context, or even any context where linear, formulaic results cannot
typically be expected as with dose-response types of interventions such as immunizations.

Tackling this debate is beyond the scope of this paper. Nonetheless, the debate need not hold
back progress on climate and disaster resilience M&E, for a few reasons:
   There is widespread understanding of the challenges surrounding climate and disaster
    resilience M&E and a substantial amount of creative energy being put into addressing those
    challenges.
   Different types of evaluation serve different purposes, and there is no need to discount or
    exclude any evaluation types when they complement each other.
   The field is still learning from experience, and over time it will become more clear where
    certain types of evaluation are most well-suited for the intended purposes.


Other Components of M&E Systems

There are sometimes additional components of M&E systems beyond results frameworks,
indicators, monitoring and reporting systems, and evaluation. These additional components
often focus on knowledge, learning, fiduciary responsibilities, and/or communication, for
example. Where applicable, these inform and are informed by the primary M&E components
already outlined. A current trend in the M&E field is to directly target learning as a primary
component of M&E, and as such to call these systems monitoring, evaluation, and learning
systems, or Monitoring, Evaluation, and Learning (MEL) systems. (MLE and other similar
derivatives are also commonly used.) For the purposes of this paper, learning is assumed to be
inherently embedded into the M&E system, rather than as a separate component.




                                                14
III. Overview of Climate and Disaster Resilience M&E
Work
In the past few years there has been increasing attention on climate and disaster resilience M&E
within the international climate finance community, national governments, philanthropy, think
tanks, and civil society.

Below are additional illustrative examples of work being undertaken within and beyond the WB,
included here for the purpose of further describing the state of current work and for laying the
groundwork to advance climate and disaster resilience M&E.

This paper does not provide an exhaustive stocktaking of all climate and disaster resilience M&E
work; rather it summarizes key themes that are relevant for advancing the field, points to the
key efforts that have already undertaken substantial stocktaking work, and offers additional
examples of ongoing work on climate and disaster resilience M&E. This collective body of work
is taking place at the project, program, organizational, national, and field levels.

This section covers the following:

   1. Examples of climate and disaster resilience M&E systems, including results frameworks,
      indicators, monitoring and reporting (considered together), and evaluation. These
      examples span WB-IDA/IBRD-funded projects, as well as climate and disaster focused
      programs, such as PPCR and Global Facility for Disaster Reduction and Recovery
      (GFDRR), to offer a glimpse of others’ climate and disaster resilience M&E work.

       There are hundreds of WB-IDA/IBRD-funded projects with a scope that includes
       resilience as a direct or indirect objective. These projects each identify Project
       Development Objectives and associated results frameworks and related indicators. While
       some projects have made a concentrated effort to integrate resilience considerations into
       their results frameworks and indicators, this is not yet done in a systematic way that
       would allow for comparison between projects.

       Some climate and disaster resilience programs have developed notable M&E systems,
       such as PPCR, GFDRR, the Global Environment Facility (GEF) Least Developed Countries
       Fund and the Special Climate Change Fund (LDCF/SCCF), the Tracking Adaptation and
       Measuring Development (TAMD) framework, and the under-development M&E system
       at the GCF.

       Formal evaluations of resilience projects are taking place for some projects that are at a
       relatively advanced stage of implementation. On the whole, however, evaluations of
       resilience projects and, in particular, climate change resilience projects, are not yet
       common in part because many projects are in early stages.

   2. Examples of other resilience and related M&E work at the WB, including efforts that are
      either directly or tangentially related to resilience measurement and/or M&E. All have


                                              15
       some relationship and can inform and/or be informed by the climate and disaster
       resilience M&E work.

   3. Climate and Disaster Resilience M&E: Learning & Capacity Building Work. These examples
      reflect work of other institutions to support learning and build capacity for resilience
      M&E among funders, countries and other implementing partners and M&E practitioners.
      These examples cut across the major M&E components (of results frameworks,
      indicators, etc.) and therefore are references as overarching useful M&E resources. These
      efforts are the GEF—Climate-Eval Community of Practice, AdaptationCommunity.net,
      OECD Studies on Climate Change Adaptation M&E, and SEA Change Community of
      Practice (CoP).

In general, while some projects and programs are more advanced in integrating resilience
considerations in their M&E systems than others, some sophisticated and effective approaches
for climate and disaster M&E are rapidly developing. As described in more detail below,
experience with climate and disaster resilience M&E within the WB and across the broader
international development community is providing a strong basis for strengthening M&E at both
project and program levels. For improving the current approaches it will be important to: (i)
systematize the variety of approaches to resilience M&E used by different programs (and even
projects within programs) so as to make them more compatible and limit reporting burdens; (ii)
tailor resilience M&E approaches to the demands of project teams to use them as effective project
management tools, (iii) translate M&E into learning and knowledge management to better
understand what works for resilience-building in different programs.

These examples summarized above are elaborated upon next.

1. Examples of Climate and Disaster Resilience M&E Systems
Below are examples of climate and disaster M&E systems associated with WB (i.e., IDA or IBRD)
funded projects and programs, and other climate and disaster related funds, such as PPCR,
GFDRR, the GEF LDCF/SCCF, TAMD, and GCF.

In most of these examples, the emphasis to date has been on establishing results frameworks,
developing indicators, and monitoring and reporting on the indicators.

As described below, within the WB, projects are required to identify project-specific results
frameworks and associated indicators, and then to report on progress toward those indicators
throughout the duration of the projects. In some cases, projects are tied to the overarching M&E
systems that are associated with the parent program or a particular funder which has its own
reporting requirements. This common, required monitoring and reporting at the project level
does not, however, equate to a strategic climate and disaster resilience M&E system across
projects. In addition, in some cases, there is room for improvement in terms project-level M&E
design and implementation to support stronger, more efficient, and more useful climate and
disaster resilience M&E.

Further, many WB programs are either in the early stages of developing program-level climate
and disaster resilience M&E systems or they are now learning from early implementation of such

                                               16
M&E systems and are identifying opportunities for improvement based on experience. At the
higher, cross-program and corporate levels of the WB, a strategic, cross-cutting climate and
disaster resilience M&E system has yet to be developed, with the exception of the development
of a WB indicator to understand resilience at the country level (as described in Exhibit 8).

Below are examples of the existing climate and disaster resilience M&E work occurring both
within and outside of the WB.


World Bank-IDA/IBRD-funded projects

When planning a project at the WB, teams develop Project Development Objectives (PDOs) and an
associated results framework. Based on these, teams identify indicators measuring the
objectives of the project and interim results indicators, which measure other aspects that
contribute to these objectives. These project-specific indicators are expected to consider the WB
Core Sector Indicators (World Bank 2012).

Despite some links to resilience9, these Core Sector Indicators are not well suited to measure
climate and disaster resilience results at the project level, so teams often have to identify their
own indicators for resilience results if the project or one of its components is resilience related.
In addition, projects that form part of a strategic or regional program (such as the Caribbean
Resilience Initiative or the Small Island State Resilience Initiative), or those that receive co-
financing from non-WB sources (such as the GEF and PPCR), fulfill additional reporting
requirements. This has led to a variety of indicators being developed that could be deemed
“resilience-related”, but have not been systematized across the WB.

In the case of the PPCR, for example, a project such as the Disaster Vulnerability Reduction Project
in Dominica (World Bank 2015d), reports on WB PDO indicators, the PPCR core indicators (CIF
2015c), and (through written reports) on the country’s Strategic Climate Resilience Program (CIF
2015a). These include, in the Dominica case, for example:
       Number of days of interrupted traffic due to landslips, flooding and other climate-related
        events in project areas;
       Number of households with uninterrupted water service in project area due to water
        shortage or hazard events; and
       Climate risk analysis reflected in drainage and transport infrastructure design.

Annex 2 provides additional examples of the PDO indicators used for WB resilience-related
projects in Bosnia and Herzegovina, Saint Vincent and the Grenadines, and the Senegal River
Basin.




9 The WB currently monitors progress and reports on an aggregated project-level disaster resilience indicator
on an annual basis through the Corporate Scorecard. The indicator that is currently monitored is the number
of countries supported in ensuring that disaster risk reduction is a national priority. This tier 2 (project-level)
indicator seeks to demonstrate WB contribution towards disaster resilience results via operations.

                                                       17
Pilot Program for Climate Resilience (PPCR)

The PPCR Results Framework, which includes both core and optional indicators (see Annex 3) is
based on the PPCR Logic Model (see Exhibit 4), which begins with the inputs (at the bottom) and
ends with the long-term intended outcome (or impact) at the top.

PPCR uses five core indicators developed to reflect the results identified in the PPCR Logic Model.
Thus, the Logic Model “drove” the indicators, which is a typical progression and reason why the
practice is to first develop the M&E results framework (logic model, theory of change, log frame,
or other) and then to identify indicators. The PPCR core indicators are as follows:
   1. Degree of integration of climate change into national including sector planning;
   2. Evidence of strengthened government capacity and coordination mechanism to
      mainstream climate resilience;
   3. Quality and extent to which climate responsive instruments/investment models are
      developed and tested;
   4. Extent to which vulnerable households, communities, businesses and public sector
      services use improved PPCR supported tools, instruments, strategies, activities to
      respond to Climate Variability and Climate Change; and
   5. Number of people supported by the PPCR to cope with the effects of climate change.

Of the five PPCR core indicators, one and two are monitored at the national (pilot country)
level, and the remainder are based on information gathered from PPCR projects,
aggregated and monitored at the program level for each PPCR pilot country. PPCR also has
optional indicators which to date have not been reported on. For a complete list of
indicators and depiction of how these relate to the PPCR Logic Model, see the PPCR Results
Framework (CIF 2015c). These indicators are included in Annex 4, a combined reference
list with indicators from several other organizations and efforts cited throughout this
paper).




                                                18
                                       Exhibit 4. PPCR Logic Model




 Key
 SPCR: Strategic Program for Climate Resilience
 CC: Climate change
 CV: Climate vulnerability
 ODA: Overseas Development Assistance

PPCR designed its monitoring and reporting system based on four principles, which are
expanded upon in Exhibit 5: Use of mixed methods; country ownership; stakeholder
engagement; and learning by doing. These principles have guided country-driven indicator
development and reporting, and have become part of the PPCR intervention itself.

Reporting on PPCR indicators occurs through annual Results Reports, published for the first time
in 2013. Semi-Annual Operational Reports are also reported by PPCR, but these do not include
reporting on the core indicators. Below in Exhibit 6 is an example of reporting in 2014 on PPCR
core indicator 1: Degree of integration of climate change into national including sector planning.
The intent is to show progress of integration of climate change into national including sector
planning (as measured in percent of integration), both relative to the 2011 baseline and toward
the target of 100 percent integration.


                                                  19
             Exhibit 5. Key Principles of PPCR Monitoring and Reporting System

 Use of mixed methods: The PPCR monitoring and reporting system combines quantitative and
 qualitative methods to collect and analyze data, and generate knowledge and lessons in
 implementing PPCR investments. Core indicators 1, 2, and 3 are qualitative in nature. Core
 indicators 4 and 5 are quantitative.

 Country ownership: The monitoring of the five PPCR core indicators is a country-driven and
 participatory process, entirely managed by the pilot countries through their PPCR focal point and
 supported by the MDBs. Country focal points are responsible for collecting, aggregating and
 submitting their reports annually to the CIF Administrative Unit.

 Stakeholder engagement: Empowering stakeholders and ensuring their active contribution to
 the monitoring and reporting process is a key feature of the PPCR result measurement system. The
 PPCR monitoring and reporting system is rooted in the desire to maintain a programmatic
 approach in the implementation of the investment plans through projects and programs. It aims to
 engage PPCR stakeholder groups, including government institutions at national, sub-national and
 local levels, as well as civil society, local communities and the private sector, in discussing progress
 with the implementation of PPCR investments. The monitoring and reporting process on the PPCR
 five core indicators is also used to share lessons learned and discuss the challenges encountered
 with a view to identify feasible solutions.

 Learning by doing: Everyone recognizes that monitoring and reporting in the PPCR is an iterative
 learning process. The 2014 reporting round showed improvements in quality over the first
 reporting round, and it is expected that the quality will improve even further over time as countries
 gain experience.

 Source: CIF 2015c.



PPCR is enacting its learning-by-doing approach, for example, by synthesizing its key lessons
(World Bank, CIF, and PPCR 2015). These lessons—scheduled to be published in the fall of
2015—draw upon many information sources, including PPCR monitoring and reporting, to
identify not only lessons from PPCR experience to date, but also how these lessons can be
applicable more broadly to other resilience investments. One likely lesson related to PPCR
monitoring and reporting is that the PPCR stakeholder engagement around indicator
development has provided an effective base for national consultation, dialogue, and action
around resilience more broadly—not solely for monitoring and reporting purposes. A related
recommendation coming from these lessons will be to work within each country to embed
resilience indicators into national planning processes and systems (Op. cit.).




                                                  20
Exhibit 6. Example of Reporting on PPCR Core Indicator #1: Degree of Integration of Climate
                     Change into National (Including Sector) Planning

                                                       National
                                Cambodia               Planning
                                                     100
                                                      80
                                                      60
                                      Urban           40                    Water
                                     planning         20                  Resources
                                                       0




                                         Transport                  Agriculture


                                         Baseline (2011)          2014        Target




Global Facility for Disaster Reduction and Recovery (GFDRR)

In 2013, GFDRR developed an M&E framework, starting with the GFDRR Program Logic on the
GFDRR Monitoring and Evaluation website (GFDRR 2015b), available here. Since 2013, GFDRR
has been measuring its activities, output types, outcomes, and impact across the five pillars:
Risk Identification, Risk Reduction, Preparedness, Financial Protection, and Resilient Recovery.
Examples of the GFDRR indicators include the following:
          Improved generation or communication of disaster risk information;
          Increased application of risk information in public policy and investment planning;
          Schools and other public infrastructure made safer (retrofitting or new construction);
          Countries/cities implementing new or revised policies to address disaster risks; and
          Increased accuracy and timeliness of weather forecasts and early warning.

Annex 4 includes the complete set of GFDRR indicators.

Project proposals submitted to GFDRR must be aligned with the program logic, identify
indicators that are aligned with this framework, and report on these when the project is
implemented. Teams utilizing GFDRR funds are required to report on activities and outputs to
understand aggregated progress on country-level engagements across the five pillars.

In 2014, GFDRR conducted a program-wide evaluation (GFDRR 2014b) in four countries10 which
sheds light on identifying program outputs, testing assumptions, and drawing lessons learned
from GFDRR implementation to date (GFDRR 2015b). Among other findings, the evaluation
identified that GFDRR has increased in-house capacity around DRM at the government level and


10   Guatemala, Malawi, Nepal, and Sri Lanka.

                                                           21
helped to mainstreaming DRM in development planning. It also identified that common obstacles
include weak institutional capacities (at the national or sub-national level), competition of
agendas within the government, and limited appropriateness of Technical Assistance/DRM tools
(GFDRR 2014b).

The next phase of assessing outcomes is already ongoing, and an evaluation team is supporting
GFDRR to prioritize and implement the country evaluation recommendations such as defining
intermediate outcomes, establishing baselines, setting targets for the future, and considering
“process-based” or “intermediate” outcome indicators to measure the progress made on DRM.
This second evaluation is specifically designed to: (i) analyze and evaluate the overall impact of
GFDRR activities, specifically in terms of leveraging new investments and influencing ongoing
programs; and (ii) generate a better understanding of how and why GFDRR contributes to
making countries more resilient.

Global Environment Facility Least Developed Countries Fund and the Special Climate
Change Fund (LDCF/ SCCF)

In May 2014 the LDCF/SCCF Council adopted a revised Results-based Management Framework
for the GEF LDCF/SCCF. The revised framework and indicators form the basis for portfolio-level
monitoring and reporting of the expected and actual results of LDCF/SCCF-financed climate
change adaptation projects. The results framework has also been simplified, with 14 indicators
instead of the previous 52 included in the earlier framework. It now excludes outputs, which will
not be monitored at the portfolio level. It is also designed to be broadly consistent with the
results frameworks and logic models of other similar funds. A complete list of the 14 indicators
is included in Annex 4, and examples of these are as follows:
      Number of direct beneficiaries;
      Type and extent of assets strengthened and/or better managed to withstand the effects
       of climate change; and
      Population benefiting from the adoption of diversified, climate-resilient livelihood
       options.

The GEF in 2014 also updated its M&E guidance for the LDCF/SCCF (GEF IEO 2014). This
Guidance Document provides LDCF/SCCF stakeholders with direction on how to monitor and
evaluate results within the overarching framework of the GEF M&E Policy, modified as necessary
to adapt to the LDCF/SCCF focus.


Tracking Adaptation and Measuring Development (TAMD)

TAMD is a conceptual framework to monitor and evaluate climate change adaptation developed
by the International Institute for Environment and Development and sponsored by the UK DFID.
TAMD is designed to be used by national and local governments, or within a program or project
to assess both institutional climate risk management and adaptation and development
outcomes. It is designed to promote thinking about outcomes and encourage longer-term
thinking about resilience and climate change adaptation.


                                               22
TAMD is a “twin track” framework that evaluates adaptation success as a combination of how
widely and how well countries or institutions manage climate risks (Track 1) and how successful
adaptation interventions are in reducing climate vulnerability and in keeping development on
course (Track 2). (See Exhibit 7.) There are nine TAMD indicators for Track 1 (climate risk
management) that are being customized in different contexts (these are listed in Annex 4). These
indicators are used to assess the extent and quality of institutional processes and mechanisms
for addressing climate-related risks.


  Exhibit 7. The Tracking Adaptation and Measuring Development (TAMD) (Climate Risk
 Management & Development Performance) “Twin Track” Framework (Brooks et al. 2013)




The TAMD framework has been piloted and/or has started in several countries: Kenya, Nepal,
Pakistan, Mozambique, Cambodia, Ethiopia, Uganda, and Tanzania.


Green Climate Fund (GCF)—Draft Results Management Framework and Initial M&E
Policy

The GCF is developing a Results Management Framework, and within that, an M&E Policy and
Performance Measurement Framework (see GCF 2015). This work is still underway and is
anticipated to be further refined and adopted by the GCF Board in 2016. Principles guiding the
GCF’s M&E work include a country-ownership, a gender-sensitive approach, optional national-
level reporting on indicators, and indicators at the output, activity, and input levels that will be
determined for each project/program on a case-by-case basis. The Draft GCF Performance
Measurement Framework is also being informed by the best-in-class work of peer institutions
and experience on implementation of climate change M&E thus far.




                                                23
Examples of adaptation indicators adopted by the GCF Board thus far are:
      Total number of direct and indirect beneficiaries; Number of beneficiaries relative to total
       population;
      Number of food-secure households (in areas/periods at risk of climate change impacts);
      Number of males and females with year-round access to reliable and safe water supply
       despite climate shocks and stresses; and
      Number of males and females made aware of climate threats and related appropriate
       responses.

A complete list of the GCF indicators that have been adopted and proposed to date is included
in Annex 4.

Evaluation Examples

To date, evaluations of climate and disaster resilience—to the extent they have been
undertaken—have more often been routine project-level mid-term, summative, or ex-post
evaluations. However, as already mentioned, evaluations of resilience on the whole are relatively
new given that many projects are in the design stage or early stages of implementation, and also
given that only in the past few years has there been an influx of interest in resilience evaluation
by donors, countries, and other stakeholders. Below are examples of evaluations that have been
undertaken or are underway at the WB and/or partner institutions. (Many additional examples
of evaluations are available from the resources listed under Resilience M&E: Learning & Capacity
Building Work.)

In one example (De Nys and Engle 2015), the WB is in the process of completing a three-year
engagement with the Government of Brazil to help build drought resilience, particularly in the
country’s semi-arid Northeast. Fostering drought resilience, and, as a consequence, climate
change resilience, in this particular case meant tackling many challenges through: the promotion
of knowledge exchange (between Brazil and other countries and between institutions and
professionals inside Brazil); development of plans, tools and methodologies; integration and role
clarification between institutions across sectors and scales; and the promotion of bottom-up and
regionally-led initiatives.

In this case, to address these challenges and to match their complexity, the program required a
planning, monitoring, and evaluation approach (PM&E), which focused on outcomes understood
as institutional changes, as well as outcomes that went beyond the direct control of the program.
The PM&E called for a non-traditional/non-linear (non-cause-effect) approach, and endeavored
to learn how milestones were linked to more transformative changes by measuring “progress
markers”. The outcome mapping and harvesting techniques employed by the approach also
captured intended and unintended outcomes during implementation to inform corrections and
next steps and to help evaluate and articulate how the project was advancing toward impact. One
of the greatest challenges of this approach will continue to be concretely linking long-term
resilience evaluation outcomes with the program’s interventions.




                                                24
In another example, a statistically rigorous impact evaluation is currently in the planning phase
for the US$15.8 million PPCR Sustainable & Land Water Resource Management Project in
Mozambique. Funding for the evaluation is being provided jointly by PPCR and the WB-based
Development Impact Evaluation Initiative (DIME). The evaluation will study the impact of the
placement of irrigation kits in 56 villages covering five to ten hectares of land each in the
southern province of Gaza in Mozambique (World Bank 2015f). One source of Mozambique’s
difficulty to develop widespread irrigation infrastructure has been an inability to sustain and
protect previous investments in the sector.

To uncover the efficacy of different targeting regimes, the evaluation will randomize the model
of kit deliveries in half the villages. The evaluation will use a combination of experimental and
quasi-experimental techniques to answer three primary questions: (1) Which targeting
mechanism generates the highest average yields?; (2) Which targeting mechanism achieves
better distributional equity and better efficiency in providing kits to small holders?; and (3) How
targeting regimes interact and perform in the face of positive spillovers in the “good” being
targeted, in this case the irrigation kits?

The evaluation is part of a wider, long-term research agenda aimed at understanding how to best
leverage the irrigation investments to increase resilience of small farmers; and how to build local
institutions to ensure sustainability of these schemes. DIME is also preparing to conduct several
impact evaluations of interventions with resilience components, including interventions in
Kenya, Rwanda, and Nepal.

There are also several different examples from various parts of the WB that have either focused
solely on evaluating resilience measures, or include resilience within the evaluations. For
example, in 2012 the Social Protection unit evaluated progress on the Productive Safety Nets
Programme (PSNP), which began in 2005, in the Ethiopian lowlands (World Bank 2005). The
evaluation addressed ten research questions; such as whether the PSNP targeted the right people
(ESSP II 2013).

Most evaluations of resilience interventions to date have not yet been the type of statistically
rigorous impact evaluation undertaken during project implementation, for the following
reasons:
      Many resilience projects are in the early stages of development or implementation —
       whereas most evaluation takes place at least mid-course or after the end of projects;
      Rigorous impact evaluation built into the project design has to be carefully planned up
       front, it is generally costly, and it requires specialized expertise—factors that are limiting
       and opportunities are just being explored;
      There have not been many identified “matches” between resilience intervention and
       suitable (and fundable) opportunities for statistically rigorous impact evaluation; and
      The benefits of resilience will often be realized far into the future.




                                                25
2. Examples of Other Resilience and Related M&E Work at the World
Bank
Within the WB, several initiatives related to climate and disaster resilience M&E are underway.
While some efforts explicitly focus on climate and disaster resilience M&E, such as the Climate
Smart Agriculture indicators effort, others are related but do not directly lead to improved M&E
systems. For example, they may be more focused on the project preparation and design phase,
such as risk screening, and less on measuring and evaluating results from project
implementation. Similarly, some efforts are more directly about project-level results, and others
focus on development of indicators at the national or WB corporate levels.

Nonetheless, these efforts are all contributing to a better definition and measurement of
resilience results at the project-level and are also informing each other.

Note that this is not a comprehensive list of all WB climate and disaster resilience initiatives, but
rather an initial stocktaking.

Considering the above, Exhibit 8 provides a brief overview of the following WB initiatives:
              Climate Change and DRM co-benefit tracking and joint MDB climate finance
               tracking to identify resilience-building projects;
              Development of climate and disaster risk screening tools to identify projects that
               are exposed to climate and disaster risks;
              Analytical tools to support decision making under uncertainty to make project
               design more resilient to uncertain climate and disaster risks;
              Identification of Climate-Smart Agriculture indicators to monitor and evaluate
               results of resilience-building agricultural projects;
              Development of forest predictive proxy indicators to monitor and evaluate results
               of forestry projects, including environmental benefits, such as ecosystem
               resilience; and
              Development of a national-level resilience indicator to track the socio-economic
               resilience of countries over time.


     Exhibit 8. Examples of Other Resilience and Related M&E Work at the World Bank
 Climate Change and DRM Co-benefit Tracking and Joint MDB Climate Finance Tracking
 Focus: Corporate level reporting, planning, and investment monitoring

 In accordance with the WB's commitments set out in the 2008 Strategic Framework for
 Development and Climate Change and the IDA16 replenishment, the WB developed a system to
 measure funding that contributes to climate change adaptation and mitigation. Before this climate
 finance tracking system became operational, activities contributing to climate change adaptation
 and/or mitigation could only be tracked through the WB’s theme coding framework, which solely
 captures activities whose primary objective(s) involve(s) climate change. With the addition of the
 climate change “co-benefit” tracking system, the WB now systematically evaluates the financing of
 adaptation and mitigation in all of its lending operations, during the project commitment phase.

                                                 26
Development activities provide climate change co-benefits when they contribute to climate change
adaptation and/or mitigation, even when adaptation and/or mitigation is not their main objective.
In practice, activities with adaptation co-benefits are those that aim to address climate
vulnerabilities through the project’s components.

Similarly, the WB recently initiated a DRM co-benefits tracking project, which reviews the WB active
projects portfolio to systematically capture the financing of DRM in all of its lending operations,
irrespective of their objectives.

In addition, since 2012, the WB has been involved with the production of the Joint Report on
Multilateral Development Banks Climate Finance and has recently joined with the other multilateral
development banks (MDBs) to work on harmonizing the tracking of climate finance with other
International Finance Institutions (IFIs). The WB’s reporting to this group is based on the
internal WB’s tracking of projects via the climate change “co-benefits” system.

For more information on the Climate Finance Tracking at the WB, see:
www.worldbank.org/en/news/feature/2015/04/03/common-principles-for-tracking-climate-finance
and 2014 Joint Report on Multilateral Development Banks’ Climate Finance.

Climate and Disaster Risk Screening Tools
Focus: Planning/Strategy/Investment

The Climate and Disaster Risk Screening Tools developed by the WB provide a systematic,
consistent, and transparent way of considering short- and long-term climate and disaster risks in
project and national/sector planning processes. Screening is an initial, but essential, step to ensure
these risks are assessed and managed to support mainstreaming of climate and disaster resilience
into key development policies, programs, and projects.

These self-paced tools provide high-level screening at an early stage of program and/or project
development. The tools do not provide a detailed risk analysis, nor do they suggest specific options
for increasing the project’s effects on resilience. They are intended to help determine the need for
further studies, consultation, and/or dialogue in the course of program or project design.

These tools can be applied to a range of development sectors in support of a) national plans and
strategies and b) project level investments. The ratings, while instructive, should be seen as
informing further consultations and dialogue, and to help determine the need for further studies in
the course of project design or planning at the national/sector level.

For more information on the Screening Tools: http://climatescreeningtools.worldbank.org/

Decision Making Under Uncertainty
Focus: Planning/Strategy/Investment

The performance of long-term infrastructure projects is sensitive to future changes in prices,
demand, technological innovation, and climate change. Making these projects resilient to long-term
changes is challenged by the irreducible uncertainty that surrounds future climate change and socio-
economic developments. There is therefore an increasing demand for new methodologies that take
this uncertainty into account during the economic analysis of projects and that put more emphasis
on robustness than on optimality.

                                                27
Several methodologies, referred to as Decision Making Under Uncertainty (DMU), are increasingly
being applied by different teams within the WB to address these drawbacks. These approaches seek
to identify robust decisions, which promote solutions that perform well in a broad range of possible
futures and favors strategies which evolve over time in response to new information and avoid lock-
in into potentially dangerous solutions.

These methodologies could be used to measure “potential regret” (i.e. comparing the maximum loss
implementing the project across a large number of possible futures to the maximum loss of not
implementing the project across the same set of scenarios), which could then be tracked over time.

Currently, DMU approaches are being tested in WB projects on urban water supply in Peru,
hydropower investments in Nepal and Africa, urban flood management in Sri Lanka, and transport
network’s vulnerability in Peru and Ecuador.

As part of the DMU initiative, a Decision Tree Methodology was developed to include climate
uncertainty in water resources planning and project design to assess and manage the risks posed by
climate uncertainty. The approach adopted here is a robustness-based, bottom-up alternative to
previous top-down approaches to climate risk assessment, the quality of which have been
contingent on the accuracy of future climate projections derived from General Circulation Models
(GCMs, also known as Global Climate Models).

Source: World Bank. April 2015. Decision Making Under Uncertainty Technical Note. Internal Draft.
Washington, DC: World Bank.

For more information on the Water Decision Tree Methodology:
http://water.worldbank.org/publications/uncertainty-and-climate-variability-design-and-operation-
water-resources-projects

Climate-Smart Agriculture (CSA) Results Indicators (Draft)
Focus: Indicators, monitoring, and reporting

The draft CSA-Results indicators are part of the set of three CSA related indicators: CSA-Technology,
CSA-Policy, and CSA-Results indicators. The draft project-level CSA-Results indicator set has two
purposes: (i) to inform stakeholders about indicators for relevant for M&E systems in CSA
interventions; and (ii) to calculate the CSA-results index, which provides stakeholders with an
indication of how the respective project has performed in jointly reaching the CSA triple-wins:
resilience, mitigation, and productivity.

The draft CSA results indicators are categorized as follows:
   1. Indicators measuring the direct outputs of a CSA intervention: (a) Beneficiaries; (b) Land area;
      (c) Livestock;
   2. Indicators measuring the CSA enabling environment (which may be a consequence of an
      intervention or not); and
   3. Indicators measuring the medium to long-term consequences of CSA interventions: (a)
      Resources; (b) Emission; (c) Yield; (d) Benefits.




                                                28
This information is based on an internal draft document on CSA indicators for projects. For more
information on CSA, see World Bank (2014b).

Forest Predictive Proxy Indicators
Focus: Indicators, monitoring and reporting

The WB Program on Forests (PROFOR)-financed study, Understanding Long-Term Impacts in the
Forest Sector: Predictive Proxy Indicators, responds to the lack of evidence for performance of forest
sector interventions and to a broader demand from donors, government agencies, and implementing
organizations to develop robust, yet practical means to better understand the impacts of forest
sector investments. It focuses in particular on potential predictive proxies for longer-term term
outcomes and suggests that such indicators do in fact exist. The report identifies a set of theory-
based predictive proxy indicators relevant to one or more overarching development objectives:
poverty reduction and economic growth, biodiversity conservation, climate change mitigation and
adaption, and good governance.

Source: World Bank (2015g).

For more general information on the WBG’s overarching work in the forest sector, see
www.worldbank.org/en/topic/forests

Resilience Indicator Development (National Level)
Focus: Indicator related to tracking development outcomes and progress at country-level

A national-level resilience-related indicator and quantifiable definition of socio-economic resilience
is being developed to evaluate the resilience of socio-economic status in countries. Exposure to
climate risk is incorporated into the calculation of this national level resilience metric. This metric
could be used to help in project screening and selection, and for determining what the most
promising resilience levers—or leverage points—are for projects within a certain country.

To evaluate the resilience of socio-economic status in countries, a quantifiable definition of socio-
economic resilience was developed (the ratio of asset losses to welfare losses): socio-economic
resilience = welfare losses / asset losses.

The model-based metric combines data on hazard, population and asset location, asset vulnerability,
and socio-economic characteristics and uses insights from natural and social sciences to assess how
hazards will affect well-being (measured using a social welfare function, the metric used by
economists to measure well-being). Using available macro- and micro-economic data, the model
defines and assesses the socio-economic resilience of 90 countries to be able to identify policy
priorities to reduce the impact on wellbeing, and help design holistic risk management strategies
tailored to each country. Currently it has been calculated for flood risks only, but extensions to other
hazards – including how they are affected by climate change – are planned.




                                                 29
3. Climate and Disaster Resilience M&E—Field-Level Learning & Capacity
Building Work
Four efforts aimed at building capacity for climate and disaster resilience M&E are briefly
summarized below. These are broader efforts aimed at learning and capacity building for donors,
M&E practitioners, and implementing partners at all levels (fund, national, local, etc.). These are
important because they are focused specifically on adaptation/resilience M&E, and as such are
considered “go-to” efforts that include examples of M&E at different levels. The efforts offer
analysis of M&E systems and their various components and provide guidance and ideas for
climate and disaster resilience M&E. These efforts are:
      GEF—Climate-Eval Community of Practice,
      AdaptationCommunity.net,
      OECD Studies on Climate Change Adaptation M&E, and
      SEA Change Community of Practice (CoP).

Global Environment Facility (GEF)—Climate-Eval Community of Practice

The GEF-hosted Climate-Eval Community of Practice (Climate-Eval CoP) is an on-line community
of practice and global network of M&E practitioners hosted by the GEF Independent Evaluation
Office to establish standards and norms, support capacity development, and share good practices
of climate change and natural resource management evaluations. Support from multiple donors
has, in addition to hosting the on-line CoP, sponsored several field-building studies and two
global conferences, the latest of which was the International Conference on Evaluating Climate
Change and Development held in November 2014 in Washington, DC (Climate-Eval 2014).

A recent report published by GEF on behalf of the Climate-Eval CoP is a Good Practice Study on
Indicator Development, Selection and Use Principles for Climate Change Adaptation M&E (Climate-
Eval Community of Practice, June 2015). The Good Practices study identifies and addresses key
challenges concerning M&E for climate change adaptation by documenting good practices and
good practice principles on the development, selection, and use of indicators used in the M&E of
adaptation interventions. The study also emphasizes the importance of evaluative evidence
supporting adaptation-related policymaking. Several of the key findings from this study are
referenced below in the following section.

AdaptationCommunity.net

AdaptationCommunity.net is an on-line community of practice sponsored by the German
international development agency Gesellschaft für Internationale Zusammenarbeit (GIZ) to
support adaptation to climate change. Since March 2013, AdapationCommunity.net has been
providing knowledge through an inventory of methods for adaptation to climate change with
examples of practical application in the form of Method Briefs and webinars. The Community
also provides a platform for exchange among practitioners such as decision-makers, planners
and advisors on adaptation to climate change, particularly in the global South through webinars
and an area for exchanging ideas. AdaptationCommunity.net has a section devoted to M&E,
which includes national-level adaptation M&E, project-level adaptation M&E, examples from

                                                30
application, M&E Training, and additional resources. Examples of M&E resources available on
the site include:
      GIZ’s training modules on monitoring and evaluating adaptation based on the GIZ/OECD
       training Integrating climate change adaptation into development planning (OECD 2009);
      Monitoring and Evaluating Adaptation at Aggregated Levels: A Comparative Analysis of
       Ten Systems (GIZ 2014a) illustrates how countries are developing their adaptation M&E
       systems and provides recommendations for the design of M&E systems building on a
       previously published working paper on GIZ’s experience of supporting adaptation M&E
       in partner countries; and
      Forthcoming: The M&E Navigator: A Systematic Mapping and Decision Support Tool of
       Approaches and Methods for M&E of Adaptation to Climate Change (GIZ 2015).

OECD Studies on Climate Change Adaptation M&E

OECD has recently published useful climate change adaptation studies, including the following:

National Climate Change Adaptation: Emerging Practices in Monitoring and Evaluation (OECD
2015), which draws upon emerging M&E practices across developed and developing countries
to identify four tools that countries can draw upon in their own assessment frameworks: (1)
climate change risk and vulnerability assessments, (2) indicators to monitor progress on
adaptation priorities, (3) project and program evaluations to identify effective adaptation
approaches, and (4) national audits and climate expenditure reviews. The report also examines
how development co-operation providers can support partner countries in their efforts to
monitor and evaluate adaptation.

Monitoring and Evaluation of Climate Change Adaptation: Methodological Approaches (OECD
2014b), published in cooperation with the World Resources Institute and the International
Institute for Sustainable Development, summarizes several methods used in the cases
researched from evaluations in other development sectors, including DRM. This paper explores
methodological approaches that can be used to monitor and evaluate climate change adaptation
initiatives at the projects and program levels. It examines approaches that have been used in
other areas of development practice to see what lessons have been learned that can inform the
development of monitoring and evaluation frameworks targeted at adaptation.

SEA Change Community of Practice (CoP)

With funding from the Rockefeller Foundation and technical and logistical support from Pact
(www.pactwolrd.org), the SEA Change CoP (www.seachangecop.org) served from 2010 to 2014
as an on-line CoP focused on the monitoring and evaluation of climate change interventions in
Asia and beyond. While the community was initially focused on Southeast Asia—hence the “SEA”
in SEA Change—the focus grew to include the entire Asian continent in its widest definition.
Although the CoP website is still active with user-driven posting of new content, funding for the
site has been discontinued. Still, many useful resources are available on this well-organized site.




                                                31
IV. Resilience M&E Insights
Based on the experience of the growing field of climate and disaster resilience M&E, there are
several widely agreed-upon thematic insights and good practices to note. The high-level insights
summarized below are based on many of the resources cited throughout this paper as well as
experience in the field. These insights and corresponding good practices can inform further
development of climate and disaster resilience both within the WB and beyond.

Thus, there are three overarching insights about climate and disaster resilience M&E that have
field-wide implications and should be considered while developing climate and disaster
resilience M&E work:

Insight 1. Wicked problems require creative, adaptive solutions

Climate change, especially climate resilience, is a complex issue, what some term as a “wicked
problem” 11 —a problem that is extremely challenging to solve because of incomplete,
contradictory, and changing requirements that are often difficult to recognize. These kinds of
complex, evolving problems require adaptive and creative solutions—solutions that cross
sectors, are context-specific, and may be ever-changing as both problems and solutions shift over
time. This has implications for climate and disaster resilience M&E, including:
        What works well in one context may not work anywhere else. Therefore, the
         transferability, replicability, and scalability of solutions cannot be assumed;
        In general, neither the problems nor the solutions are formulaic (or agreed upon by the
         multitude of stakeholders), therefore M&E models that assume linear cause-and-effect
         relationships between interventions and outcomes/ impact may not apply, at least not in
         most instances; and
        The above realities strongly suggest that M&E frameworks and approaches should be
         innovative and iterative, adapting over time based on experience and a deeper
         understanding of what works both in each case and based on insights gained from
         broader experience.

The “wicked problem” framing informs some of the more specific challenges outlined below.


Insight 2. Climate and disaster resilience M&E poses a number of methodological
challenges

Due to the long-term, complex nature of climate change and the effects of disasters, including the
lack of predictability; shifting political, socioeconomic, and macroeconomic forces; widely

11 The term “wicked problem” was originally coined in 1967 by Churchman, C. West in "Wicked Problems".
Management Science 14 (4) and then built upon by Rittel, Horst W. and M. Webber (1973) in "Dilemmas in a
General Theory of Planning" Policy Sciences 4: 155–169. It has been more recently been applied to climate
change and other types of complex challenges that affect resilience. See, for example, Levin, Kelly, et al (2012).
"Overcoming the tragedy of super wicked problems: constraining our future selves to ameliorate global
climate change". Policy Sciences 45 (2): 123–152.

                                                       32
varying climate and disaster vulnerabilities impacts at the local level; differences in what matters
and can be measured at different scales; and a range of other factors that can affect risk and
resilience—climate and disaster resilience M&E poses several challenges, including:

    Challenge: Establishing clear baselines, given the fluid nature of climate change, hazards and
     disasters, and resilience, as well as associated data collection challenges and lack of a single,
     standard baseline indicator.
     Although this is true for climate change generally, this is particularly true for resilience,
     which can be a shifting “state” at any given time due to the multitude of influencing factors,
     such as local policy/political dynamics, natural fluctuations in climate (or seasonal
     variation), macroeconomic forces (such as the international price of basic commodities such
     as fuel or agricultural staples), or unpredictable natural disasters. Even when baselines are
     evident it is often difficult to establish baselines that are, for example, specific to the absence
     (or presence) of effects of climate change. More often than not, projects do not establish
     sound baselines at the beginning, posing an even harder challenge of retrospectively trying
     to establish baselines.12

     This challenge is further discussed in several other publications, including Dinshaw et al.
     (2014) and Bours et al. (January 2014).

    Challenge: Identifying common indicators that cut across contexts and scales, beyond
     particular projects, including sector, country, regional, and global levels.
     Again, for the underlying reasons already noted, this is a particularly pressing challenge for
     resilience, which is more context-specific, place-based, multi-sectoral, multi-faceted, and
     harder to identify/isolate from other factors than are most issues. Common indicators can
     fail to describe underlying dynamics (such as social norms that drive particular behaviors
     or attitudes that can affect resilience) or institutional realities (such as the lack of funding
     or technical expertise needed to strengthen policies and programs). This is one reason why
     qualitative indicators are now often suggested, even though these also pose challenges
     (more below).
     A clear example is the lack of a single common outcome measure, such as reduction of
     greenhouse gases for climate change mitigation. For resilience, different units of measure,
     or even the same units measured differently, pose ongoing challenges for comparison and
     aggregation. A common measure adopted as a proxy by some international climate finance
     institutions is the number of beneficiaries, but this indicator has several weaknesses,
     including not often being representative of actual outcomes or impacts, and often also being
     easy to manipulate or inflate. This lack of a common, measurable outcome/impact indicator
     is only one challenge associated with identifying indicators that are possible to summarize
     or compare, making program, country, and portfolio level analysis particularly challenging.
     Similarly, resilience at one scale—such as the local level—might not equate resilience at
     another scale. Thus, counting “success” in one place, or even at one point in time, does not
     mean that there is broader, durable, systems-level resilience. These and related trade-offs
     over space and time inherent in resilience that complicate M&E even further.

12Some organizations think that M&E resources could be best spent on establishing sound baselines as a
highest priority.

                                                  33
        Leiter (2015) is one source of interesting discussion on this topic, providing some practical
        ideas for how to approach addressing this challenge. This challenge is further discussed in
        Spearman and McGray (2011) and elsewhere.

       Challenge: Establishing realistic and stable targets for outcomes and impact, particularly
        given the long time frames associated with resilience and unpredictable nature of both the
        climate change and other factors associated with resilience (e.g., macroeconomic forces). It
        is difficult and in some cases impossible to predict when resilience will truly be “tested”
        through, for example, a natural disaster or extended drought. These shifts, which would
        allow for resilience “testing” are unpredictable and hopefully avoidable altogether, and they
        could happen years or decades in the future.

        Therefore, target setting at a reasonable period of time (e.g., three to five years) and
        “pressure testing” of those targets against the challenges resilience guards against is not
        realistic in many cases. Targets thus need to be geared to more flexible given the underlying
        “shifting sands” and/or be focused on measurable interim outcomes.

        This challenge relates to, but is not directly a function of the challenge of establishing
        baselines. Baseline identification certainly does complicate establishing targets (and
        assessing the difference from the baseline), but identifying specific targets is a challenge in
        its own right.

       Challenge: Identifying realistic long-term impact – whether in indicator form or in general.
        Defining long-term resilience impact in a measurable or otherwise clearly identifiable way
        that links back to a particular intervention is an ongoing challenge for several climate
        finance institutions. The ultimate resilience paradigm or transformational shifts sought are
        sometimes characterized in terms of sustainable development, or sometimes in terms of
        resilient societies or economies. Although these concepts are compelling, actually realizing
        these changes in tangible ways is not only a long-term endeavor (perhaps decades in the
        making), it is a function of many factors beyond any single intervention. Therefore, this level
        of the results pathway and how to measure it (as well as whether measurement is even
        appropriate) are both theoretical and practical challenges.
        As part of its ongoing work on its Performance Measurement Framework, the GCF is one
        institution working on identifying its long-term paradigm-shift objectives in a way that is
        aspirational and realistic, considering what can be measured and attributed to the GCF.

       Challenge: Accounting for maladaptation. This is the scenario where interventions
        unintentionally have the opposite effect of what they are designed for, such as increasing
        climate vulnerability. Although climate and disaster resilience M&E should conceptually be
        identifying and helping to rectify any such trends, ideally early on, maladaptation may not
        be caught or corrected by more wrote or rudimentary M&E systems.13

       Challenge: Selecting suitable evaluation methodologies. Given the complex “wicked problem”
        nature of resilience, and the long-term time horizon for change, selecting suitable evaluation
        methodologies is a challenge. This can be less so for more simple, well-understood

13   See discussion in GEF IEO (2015) and resources cited therein.

                                                       34
    interventions that are short-term and are aiming to achieve a short-term, measurable
    change (such as building a bridge or installing early warning systems). This is more so the
    case for interventions that aim to build long-term resilience or other forms of multi-
    dimensional change.

    Choosing suitable methodologies is even more of a challenge because globally, thus far, there
    is only a small group of evaluation experts who understand the landscape of evaluation —
    and the pros and cons associated with various evaluation approaches well enough to be able
    to advise on which evaluation options may be most well suited for any particular
    intervention. This is because most evaluators are familiar with one or perhaps a handful of
    approaches, and they tend to recommend what they know. On top of this, an even more
    narrow set of experts understand both evaluation and climate change, though the number
    of people with some level of expertise in both of these realms is quickly growing. Finally, a
    related challenge is that learning—whether it is considered to be part of evaluation or a
    separate set of intentional activities—is a popular concept, however, how this translates
    into actual systems and practice remains elusive for most organizations.

    Matching evaluation approaches to particular opportunities, including rigorous impact
    evaluation, is an ongoing discussion within the CIF and other climate finance institutions. A
    variety of tools and options with respect to this challenge are discussed in multiple
    publications, including OECD (2015), and CIF (2014).

Additional challenges are also described below in the context of the discussions on frameworks,
indicators, and/or evaluation.


Insight 3. The field of climate and disaster resilience M&E is young and learning
(quickly) from experience

Although the field of climate and disaster resilience M&E has been rapidly evolving over the past
few years, the field is still young and learning quickly from experience, in large part through trial
and error—which is how most effective learning occurs. Thematic examples, as highlighted in
the increasing number of works on climate and disaster resilience M&E, illustrate this point:
   It is easy to be overly ambitious at first. Several climate finance institutions (including GEF,
    Adaptation Fund, and PPCR) established M&E results frameworks, and after experience
    with monitoring and reporting based on these frameworks, revised (and typically
    simplified) these frameworks substantially after experience showed that complicated
    systems were overly burdensome and not practical, and as a result the knowledge and
    learning they could offer was insufficient to justify the investment.
   Basing climate and disaster resilience M&E systems on what others are doing is not enough.
    Many organizations are following the models of the leading institutions. That is, they are
    replicating M&E frameworks – including indicators—from early implementers such as
    PPCR, GEF, and the Adaptation Fund (as well as now the GCF). However, even the “leading
    edge” implementers are still in the early stages of implementation, reporting, and analysis
    based on these frameworks, and they are quickly learning from experience on the
    improvements they could make to their own systems.

                                                 35
       Still, insights can be gained from others’ innovations, both within and outside of the climate
        and disaster resilience sector. Climate and disaster resilience M&E is still a new field, and
        experience to date has revealed that innovative approaches that build on best-in-class M&E
        innovations from a variety of sectors can help to inform this field. Concepts that have risen
        to the surface from other sector M&E experiences include systems thinking, real-time and
        developmental evaluation, and rapid-, evidence-based adaptive learning and management.
        Furthermore, to be effective, climate and disaster resilience M&E approaches must be
        innovative and adaptive—more so than is the case for more formulaic dose-response
        sectors such as health care and education.
       Stakeholder engagement is critical. Although stakeholder engagement is recommended as a
        good practice for M&E generally speaking, this is even more important for a climate and
        disaster resilience M&E process to ensure context-relevance, cultural sensitivity, and
        ultimate utility. Stakeholder groups also should not be assumed to be homogenous and
        climate-vulnerable populations may need additional stakeholder analysis to identify
        vulnerable populations and work with them appropriately.14

       Plan to learn from experience and adapt accordingly. Climate and disaster resilience M&E
        will be a “learning by doing” field for some time to come. This can be fortuitous for
        organizations that are open to experience and evidence-based learning to improve
        strategies, implementation, and ultimate impact. PPCR and the UK’s International Climate
        Fund are two examples of prominent resilience programs which are identifying lessons
        from M&E implementation and adapting along the way, acknowledging that doing so takes
        time and patience.




14   See additional discussion in Bours et al. May 2014, and GIZ and United Nations University 2014.


                                                       36
V. Recommendations

Below is a set of high-level, step-wise recommendations to move forward on M&E for resilience-
building operations. The recommendations are oriented for the WB, given its current, relatively
early stage of advancing a climate and disaster resilience M&E system that can be used both for
and across projects, if not also across programs. There is substantial opportunity to advance
such a system at the WB, starting with identifying a set of intentional principles to guide system
design and implementation, and then to proceed in a step-wise fashion from the principles to
specific results frameworks, indicators, and evaluations.

The high-level recommendations are also generally applicable to other large, multi-program,
multi-sectoral institutions also seeking to develop or refine their own climate and disaster
resilience M&E.

Recommendations were initially developed prior to the workshop for which this paper was
prepared. Workshop participants discussed most of these recommendations and developed
further ideas and suggestions during the workshop. The ideas generated at the workshop have
been integrated below.

Recommendations:
   1. Adopt an operational definition of resilience, while allowing individual programs to use
      their own (comparable) definitions.
   2. Develop a set of overarching guiding principles for climate and disaster resilience M&E.
   3. Identify a preliminary results framework for climate and disaster resilience M&E.
   4. Define and test a set of indicators.
   5. Develop guidance on evaluation options.


Recommendation 1. Adopt an operational definition of resilience, while allowing
individual projects/programs to use their own (comparable) definitions.

Adopting a standard operational definition of “resilience” will provide a common vocabulary and
scope from which to monitor and evaluate resilience interventions.

Given the conceptual similarity between most definitions of resilience, and the reality that
requiring individual programs to change their current definitions would require a compelling
argument (where there is not one), the recommendation here for practical purposes is to use the
most recent Arctic Council definition of resilience cited by the IPCC in its Fifth Assessment
Report:
       The capacity of a social-ecological system to cope with a hazardous event or disturbance,
       responding or reorganizing in ways that maintain its essential function, identity, and
       structure, while also maintaining the capacity for adaptation, learning, and transformation
       (Arctic Council 2013).

                                               37
This would be the most practical option. The potential challenge would be if different program-
level definitions caused substantive analytical challenges when trying to compare program
outcomes based on different definitions. However, this scenario is unlikely and if it arises it could
be addressed accordingly.

Recommendation 2. Adopt a set of overarching guiding principles for climate and
disaster resilience M&E

The second recommendation is to adopt a set of overarching climate and disaster M&E guiding
principles, to inform and shape the approach to M&E including frameworks, indicators, and
evaluation approaches. Overarching guiding principles help to shape M&E strategy, decision-
making, learning, reporting, and unintended consequences. In essence, overarching M&E
principles serve as a type of cultural contract within an institution and its implementing partners
and stakeholders for how M&E will be approached, resourced, operationalized, and used.
Principles need to be consistent with institutional culture to ensure they are embraced and
operationalized.

To be realized, principles therefore need to be carefully considered by those responsible for
guiding, funding, implementing, and using M&E. The enclosed proposed principles therefore
should be discussed further and adopted conscientiously by these important stakeholders. With
this in mind, below is a list of proposed guiding overarching M&E principles. The list integrates
and builds upon those identified by participants at the September 23-34 workshop as well as the
underlying rationale behind many of these principles as explained in the earlier draft of this
scoping paper.

What stands behind these principles are considerations of both good M&E practices (generally
speaking), and also what is particularly important if not unique for climate and disaster
resilience M&E. Standard good practices, such as involving stakeholders early on and often
throughout the M&E process, are especially important for climate and disaster resilience M&E
given that resilience is particularly stakeholder-centered (i.e., resilience is defined and
experienced differently by different stakeholders, unlike many other interventions, such as
immunizations, where the outcomes are more universal and easy to define).

The question of how climate and disaster resilience M&E is unique is worth paying attention to,
even if many good practices for M&E in general also apply to climate and disaster resilience M&E.
This is a question under exploration by climate and disaster resilience M&E practitioners, and
they are generating some preliminary ideas on this question. For instance, from a functional
perspective, resilience interventions—as per the more holistic and long-term definitions of
resilience versus adaptation or recovery—are increasingly focused on more than simple one-
time shifts or responses. Resilience interventions are more about long-term preparedness, rapid
recovery, and building not only recovered systems (i.e., back to the baseline), but stronger
systems over time.

M&E of investments in climate and disaster resilience should thus aim to understand both the
“concrete” signals of resilience, such as establishment of sound emergency response systems, as
well as the more system-based signals of resilience, such as long-term economic stability. In

                                                 38
these ways, climate and disaster resilience M&E goes beyond M&E of other more concrete, easily
measurable, and short-term issues to embrace nuanced, multi-sectoral, complex, context-
specific, and systems-level changes over the long-term. It may very well be that resilience poses
a unique set of challenges for M&E, that there is no directly comparable M&E topic, and as such
climate and disaster resilience M&E should be considered both new and uncharted.

The following principles take these factors into consideration. While several are general good
practices for M&E, they are on the whole particularly important for optimizing climate and
disaster resilience M&E.

Principle 1. Accountability and learning are both priorities for climate and disaster
resilience M&E; however, the natural tensions and tradeoffs between these are
recognized and should be considered

     M&E systems historically have leaned toward supporting accountability—to identify results,
     to report to funders, and to communicate to core stakeholders. Whether programs and
     projects have met their targets and achieved their results, whether money has been efficiently
     spent, and whether there were any unintended consequences (positive or negative) are the
     types of accountability often supported by M&E. With an accountability focus, M&E is often
     viewed as an audit function, particularly when funding is contingent upon demonstrating
     particular results and value for money.

     M&E for learning purposes can also support accountability, but truly embracing learning
     involves recognizing the learning-by-doing and experimental nature of complex interventions
     (including by default essentially all resilience interventions). To embrace ongoing learning
     requires support for program adaptation, including, for example, adapting implementation
     strategies early and often, testing promising innovations which may have a high chance of
     failing, and experimenting with high-risk, high-return strategies.

     Among other things, a learning approach will thus involve permission to fail—or more
     specifically, as put by organizational learning expert Amy Edmonson, to plan for “intelligent
     failures” which promote organizational learning.15

     In the context of resilience, a more flexible approach to learning-by-doing—including trial and
     error and expecting failure along the way—may very well support long-term success more
     effectively than a traditional accountability approach. In this way, a different kind of
     accountability—accountability to learning—is perhaps a useful construct; however, achieving
     this means letting go of certain expectations that have traditionally accompanied M&E, such
     as adhering to plans or taking low-risk strategies with a guaranteed “return”.




15Edmondson discusses three kinds of failure: (1) Preventable failure: Process deviations in well-understood
domains, usually caused by behavior, skills, or support deficits; (2) Complex failures: Process or systems
breakdowns that arise due to inherent uncertainty and may or may not be identified in time to prevent
consequential accidents; and (3) Intelligent failures: the unsuccessful trials that occur as part of thoughtful
experiments and provide valuable new information or data. Source: Edmondson (2012).


                                                     39
  A learning approach will also lead to more real-time approaches to M&E than have historically
  been undertaken by the international development community. The traditional mid-term
  reviews and ex-post/terminal evaluations have often missed valuable opportunities for
  learning and continuous improvement—in the time frames that would be most useful for
  program/project improvement success. Therefore, alternative approaches including
  developmental and formative evaluation, and other approaches to continuous improvement
  that may not be considered “evaluation” such as rapid-stakeholder feedback techniques, are
  not automatically built into project implementation.

  A learning approach may also involve adjusting program design, including the results
  framework and indicators, more often than is common for institutions that prefer to monitor
  progress toward specific goals over the course of a few years or more.

  These are the kinds of tensions and tradeoffs inherent to designing for both accountability
  and learning.

Principle 2. User-focused and participatory

  Given that resilience is particularly unique to each intervention and stakeholder population,
  it is particularly important for M&E of resilience to be designed for specific users, whether
  these be funders, implementing entities, beneficiaries, or other stakeholders. Participation of
  M&E users should be built into the M&E process to make use of local and national knowledge,
  and ensure a design suited to each user’s needs and intended uses (e.g., to guide funding
  decisions, to understand whether an innovative investment is working as expected, or to
  know understand the sustainability of a particular intervention from the perspective of
  beneficiaries or implementing entities). Open data / data sharing and feedback loops with
  key users and stakeholders will improve participation and the utility of M&E findings.

Principle 3. Consider existing systems and requirements

  Climate and disaster resilience M&E systems should consider alignment with existing M&E
  frameworks and systems to keep the data collection burden to a minimum and enable macro-
  level analysis, while also acknowledging and planning for unique contexts. At the same time,
  existing M&E systems may have room for improvement—and as such should not necessarily
  be automatically adopted simply because they are in use elsewhere.

Principle 4. Consider—and invest in—local capacity, balancing building capacity with
realistic expectations

  Climate and disaster resilience M&E should consider data availability, local technical capacity,
  and resources available for data collection, reporting, and analysis. Building local capacity
  through, for example, offering trainings, utilizing local experts, providing funding for data
  collection, and encouraging stakeholder participation, will likely help, though may require a
  significant investment. Therefore, thought should be put into balancing a more “light touch”
  approach that is less burdensome and considers common capacity constraints versus
  investing in more ambitious and resource-intensive systems. Without considering these
  tradeoffs, the cost-to-value ratio may not be compelling.

                                               40
Principle 5. Encourage Innovation

  Given the unprecedented nature of climate and disaster resilience, and the corresponding
  need for creative, iterative M&E approaches that support ongoing learning, climate and
  disaster resilience M&E systems should be intentionally focused on innovation, creativity, and
  experimentation beyond traditional methods. These could involve pilot testing new
  qualitative, and/or quantitative approaches, experimenting with scalability and
  transferability, and considering creative options suited for systems-level analysis.

Principle 6. Factor in the inherently multidimensional and complex nature of
resilience

   M&E of climate and disaster resilience should consider up front the complexity and
   multiple dimensions of resilience, including:
      Climate and non-climate stressors;
      Multiple climate and disaster hazards;
      Vertical dimensions (e.g., different layers of society in a system and where resilience
       sits at the local, regional, and national levels, including governance aspects);
      Horizontal dimensions (e.g., multi-dimensional stakeholder and sectoral linkages);
      Time scales, given that resilience-related problems can take a long time to manifest
       (as can the solutions to these), and thus resilience-building (and related planning
       and M&E systems) needs to have short, medium, and long-term components; and
      Uncertainty: Approaches that are robust to a variety of uncertain future scenarios.

Principle 7. Flexibility and improvement over time are expected

   Climate and disaster resilience M&E is largely a learning-by-doing endeavor. Experience
   over time will inform what works and does not work well, and periodic updates to all major
   components of the M&E system should be expected. This could occur, for instance, through
   an annual or semi-annual review followed by a decision on whether to make formal updates.


Recommendation 3. Identify a preliminary results framework for climate and
disaster resilience M&E

A high-level, corporate-wide results framework for climate and disaster resilience M&E will
provide a substantive anchor and clear articulation of intended long-term resilience goals for
more program- and project-specific frameworks, and will enable the rollup and analysis of
program and project level M&E that is consistent with the corporate-level framework.

A straight-forward, linear, hierarchical framework (similar to the one in Exhibit 2 and the
conceptual example in Annex 5) is a practical option given its widespread use and clear and
simple construct that can be used as a guidepost for M&E over time. This is the recommended
framework approach, given its practicality.
                                               41
The trade-off to this approach is that this kind of linear framework does not clearly embrace the
evolving, non-linear “wicked problem” nature of resilience. One way to mitigate this weakness is
to update the linear framework every 1-2 years to reflect current knowledge and an
understanding of how resilience is materializing and working in the context at hand. Updating
frameworks this often would involve tradeoffs such as shifting guideposts in a potentially
confusing manner, and likely also shifting indicators correspondingly.

At the same time, the alternative frameworks that are not linear can be hard to understand,
raising questions about what the expected results and reporting requirements are, particularly
if any common reporting across projects or programs is expected. (Additional discussion on
options associated with different framework approaches is included in Annex 5.)

Regardless of which approach is chosen, the resulting corporate-level results framework can
then be referenced and reported on by different programs and projects.

To develop the framework more thoroughly, an additional research and consultation are
recommended. Research would involve examining existing program and project-specific results
frameworks to make informed recommendations on what outcomes are currently most
commonly articulated. Consultations with project teams will help to make informed decisions
about what kind of results (impacts, outcomes, and outputs) to prioritize for a straight-forward
corporate-wide framework that could be reflected and reported on by programs.

The extent to which each resilience-related program and project will be required to report on
components of the framework, such as common indicators across programs and projects, will
need to be determined through consultations on tradeoffs, such as required reporting versus
optional reporting; existing capacity for data collection and reporting; and whether the report is
for other corporate purposes.

September 2015 workshop participants suggested the following additional considerations on
how to approach results frameworks:
 •   All levels (corporate, program, project) should consider the tradeoffs between linear and
     non-linear frameworks. Either linear or non-linear frameworks could conceptually
     work, particularly if updated regularly; however, linear frameworks with regular
     iterations and feedback loops may be most practical.
 •   It may make sense to pilot innovative approaches to results frameworks where more
     conventional approaches are less applicable.
 •   At the project level, engage in the development of results frameworks early on based on a
     sound theory of change that includes a clear definition of the resilience challenge and
     needed solution. Based on stakeholder consultation and using a multi-sectoral
     perspective, answer fundamental questions such as, what do we want to change (or
     maintain)?; and who is resilience serving in this context (and over which time
     horizon)? Clearly define expected outcomes and impacts and the expected pathways
     to achieve them. Identify possible risks and unintended consequences, which should
     cover assumptions and preconditions, and account for shock/non- shock scenarios,
     maladaptation, existing capacities, other actors/interventions, etc.

                                                42
Recommendation 4. Define and test a set of indicators

A set of relevant, meaningful, and measurable indicators at each level of the results framework—
focusing on outcomes and impacts in particular—will strengthen results tracking and the ability
to identify whether the desired change is occurring as envisioned. Climate and disaster resilience
indicators should be based on underlying M&E principles and an agreed-upon results framework
because indicators are (as a general rule) intended to measure progress toward the specific
results identified in the results framework. It is thus premature to recommend specific
indicators at this time, pending adoption of a set of principles and a particular results framework.
Additional detailed analysis of in-use project indicators would also be informative to compare a
more top-down (institution and program-level) analysis of indicators with a bottom-up, project-
level indicator analysis. Doing so with in the above-discussed steps and considerations (e.g.,
avoid assuming that indicators currently in use are good indicators) will support a productive
analysis. An informed set of indicators can be selected once these foundational steps have been
completed.

What is therefore offered herein are suggestions on how to approach the selection and use of
indicators once the underlying groundwork has been completed and the time is right to do so.

A. Select an initial “menu” of indicators at different levels of the selected results framework(s),
covering a range different sectors/topics and types of outcomes and impact.

A menu of resilience indicators should be identified, considering options for both standardized
indicators and unique indicators that might be developed or adapted for specific contexts. At
a minimum, indicators will be needed for each level of the results framework(s) decided upon:
impact, outcomes, and outputs at a minimum. Issues of scale and data aggregation should also
be considered up front when considering indicators. Despite the reality that many resilience
indicators at the project level are context specific and unique, there is strong demand for
indicators that apply to different scales and to aggregate indicator data across scales.
Therefore, an informed decision is needed about where to design for scale and aggregation, as
well as where it cannot be done and should be avoided.

The menu of indicators could thus be divided into the following types of categories:

   Corporate-level indicators that align with a corporate-level results framework. There are likely
    to be only a handful of indicators that can apply corporate wide, given the diversity of
    resilience interventions and outcomes. However, some indicators may apply across all
    projects and programs, even if there are few that meet this standard. At this level, these are
    likely to be more generic and less sector-specific indicators (e.g., number of direct and
    indirect beneficiaries). Often institutions consider these indicators to be “core indicators”
    particularly if reporting is required.

   Program/sector-specific indicators that are collected for all projects within those programs.
    These indicators would be relevant for all projects within a particular program/sector—such
    as disaster preparedness or infrastructure improvement indicators for DRM programs,

                                                43
     hectares of forests/ecosystems protected for forestry/natural resource programs, or
     number of actors who adopted climate-smart agricultural practices for agricultural
     programs. Many of these indicators would not apply corporate-wide but could still be
     reported on at the corporate level for all applicable programs.

    Country- and sector-level indicators reflective of broader-scale resilience. Resilience is both a
     local and bigger-picture issue, and measuring resilience at the project level alone will not
     reflect or represent the systems-level improvements needed to achieve resilience at scale.
     For this reason, considering country-level indicators, and within countries, sector level
     indicators, will enable tracking of systems level shifts that matter. 16 Even if climate and
     disaster resilience M&E is focused more on project-level indicators, how these indicators can
     inform and be informed by country- and sector-level indicators will be important. Similarly,
     national and portfolio level indicators should be considered before choosing project
     indicators.17

    Ad-hoc indicators developed for each project. These indicators will be fit-for-purpose for each
     project’s unique context and objectives. Some indicators may not match any other indicators
     used by other projects, and some may be more narrative or qualitative in nature to match the
     unique circumstances of the project.


B. Indicators should be informed by and consistent with other institutions, while also considering
real-world experience and the own needs and priorities of particular institutions.

Even the leading institutions with the most experience implementing resilience indicators are
learning from experience, and are most often at some stage of updating their own indicators. In
other words, just because another institution (or set of institutions) uses particular indicators
does not automatically mean that these indicators represent the best options available, or that
they are as informed by experience as they could be. Indeed, some indicators in use have been
shown to be less feasible or useful than intended. It is therefore important to think beyond what
is in use by others and what is included in global normative frameworks such as the Sendai
Framework for Disaster Risk Reduction or the Sustainable Development Goals (SDGs).

At the same time, it is practical to expect that donors including CIF and (soon) the GCF—among
others—will require reporting on a set of indicators that receiving organizations will need to
report on. Similarly, many priorities and choices that are internal will have already been made,
including organizational priorities/mandates and investment plans at higher strategic levels,
and these will also define internal reporting requirements. Therefore, existing M&E systems and
reporting requirements and frameworks such as the SDGs should be considered and weighed
accordingly when selecting indicators.

C. Use should inform indicator selection.

16 PPCR, for example, focuses on country-level indicators that are derived from information that is a
combination of national level data and aggregate project information.
17 A suggestion from workshop participants for WB programs is to start the conversation on indicators in

Technical Assistance work, Country Partnership Frameworks, and Systematic Country Diagnostics to
understand and link to the broader resilience context before selecting project-level indicators.

                                                  44
Identifying what the indicators will be used for (and by whom) up front should inform indicator
selection, design, and use. Engaging with key audiences and stakeholders on indicator priorities
(e.g., what is most important to know?) and uses (e.g., documenting outcomes or informing
project design) is essential. Funders, program managers, project implementers, and
beneficiaries may all have different priorities and interests. As a general rule, if those collecting
the data do not have an interest in how the information can be of use to them, the reporting will
be less effective—more of a “check the box” exercise. Therefore, making the connection back to
how indicators are synthesized, reported, and used by those most involved is important.

Practical considerations such as data availability, technical capacity, and resource constraints
should be factored into indicator selection. In many cases, data (particularly quality data) are
not readily available, and collecting new data for indicator reporting is a burdensome task.

D. Consider tradeoffs

Different kinds of tradeoffs between indicators should be considered up front in order to make
informed decisions. These include the following.

      Indicators for both accountability and learning: Many indicators are geared more for
       accountability (toward results or to make a case of value for money). These tend to be the
       more numeric, simple, and aggregatable indicators. Learning indicators, on the other
       hand, tend to be more project/context-specific, nuanced, qualitative and quantitative,
       and associated with evaluation processes. In general, it is harder to design for learning
       indicators. Ideally both types of indicators will be used.

      Simplicity versus complexity: Simple indicators—or indicators that serve as relatively
       simple proxies for more complicated signals—are far easier to design and implement,
       and these are practical particularly under common capacity and resource constrained
       scenarios. However, to truly understand resilience and progress, at least a minimal
       number of more complicated indicators, requiring more resource intensive data
       collection and analysis, are likely to be needed. These will necessarily require a higher
       level of resource investment; however, without them resilience is not likely to be truly
       understood. One alternative to having more complicated indicators is to rely solely on
       evaluation to understand deeper and more comprehensive signals of resilience; however,
       this option would equate to a monitoring system based on indicators that could have
       important gaps or even be misleading.

      Quantitative and qualitative indicators: As previously mentioned, there is a growing
       consensus that that both qualitative and quantitative indicators are important for climate
       and disaster resilience M&E. (See also, point G below, on thinking SMART and beyond.)
       However, both types of indicators pose their own challenges. Quantitative indicators can
       oversimplify reality, involve false precision, and even be misleading when they do not
       convey a complete story. Qualitative indicators can provide a more real-world, holistic
       picture, but they can also be less clear, require a lot more time and thought, are difficult
       to aggregate, and can also be misleading if “gamed” to try to avoid or “gloss over” real



                                                 45
           issues. These kinds of tradeoffs should be considered, though ideally there would be
           both types of indicators.

          Time and money/investment associated with indicators: There are pros and cons to
           adopting existing indicators versus developing new indicators. As discussed above, many
           existing indicators are not optimal; however, new indicators often take a lot of time (and
           money) to develop. In general, indicator development and reporting is resource-
           intensive for everyone involved, therefore it may be wise to start modestly, or at least
           select a modest number of resource-intensive indicators, and increase the level of
           ambition over time. (This relates to the following point as well.)

E. Fewer indicators is generally better.

Systems with many indicators involve a burden in terms of data collection, reporting, and
analysis. Those required to collect data and report on indicators sometimes express concern that
they are spending more time on these tasks than on doing the work itself, adding, in many cases,
that they are not being provided additional resources to do so. There is also a general lack of
expertise, technical capacity, and data availability to effectively undertake numerous ambitious
requirements. The resulting reported data are often low quality—to the point that much of the
data are not ultimately useful and have been reported to “check off the box”. Also, many
indicators—including those currently in use by some of the largest climate change funders—are
still in the early stages of field testing. Until more experience reveals how telling and useful these
existing indicators are, it would be prudent to observe and learn from others’ experience while
not automatically relying on indicators that are in use elsewhere, as described above.

The tradeoff is that potentially important outcomes will not have associated indicators—at least
not across the board for all possibly applicable projects. By selecting fewer indicators, certain
issues will not be measured/reported on routinely, at least not in an indicator format. This
means that, at least in the context of standardized project-level indicators, certain sectors or
certain types of results, will not have associated indicators.

Some of the prominent climate change finance institutions (CIF, LDCF/SCCF, Adaptation Fund18)
have considered the tradeoffs and simplified and streamlined their indicators, and others (e.g.,
United Kingdom’s International Climate Fund (ICF)) are in the process of revising the ir
indicators considering these kinds of tradeoffs.

One way institutions have approached minimizing indicator burden without minimizing the
actual number of indicators is to allow projects to select which indicator(s) they will report on.
For instance, among several core indicators, projects could select one to two to report on. The
tradeoff of this approach is that any reporting will not cover a complete set of projects, and as
such it will not reflect trends or outcomes at the portfolio level.

F. Outcome and impact indicators are preferable over activities/process, and output indicators.

For resilience efforts on the whole, by far the easiest indicators to collect data and report on are
activities (e.g. stage of implementation) and output (e.g., number of trainings held or number of

18   The Adaptation Fund’s core indicators are listed in Annex 4.

                                                        46
bridges reinforced), therefore these have been more frequently reported on. These indicators
do not ultimately reflect results, even if they provide the groundwork upon which results are
made possible. But these process and output indicators can be misleading—for instance, the
number of trainings held may have no bearing on results if the trainings were poorly attended,
or if the trainings were held in a language attendees could not understand. This is not to say that
these indicators are not worth collecting—they are important for both accountability purposes
and to understand if the groundwork is being laid for achieving higher results. But they most
often should also be considered with some scrutiny, and designed to be substantive enough to
be meaningful.

The bigger-picture objective is to identify outcome indicators (e.g. percentage of public more
prepared for natural disasters) or impact indicators (e.g. economic development sectors more
resilient to shocks). However, these are the most difficult indicators to design and implement,
and real-world resilience is unpredictable given the long time scale of resilience, the constantly
evolving nature of resilience, and the challenges surrounding attribution of results to any
particular intervention, as noted previously in this paper.19

For these reasons, interim or intermediate (e.g., two-to-five year) outcome indicators are
increasingly recognized as the middle ground. Such indicators as the number of sector-
development plans that effectively incorporate climate resilience, or the percent of population
covered by emergency warning systems, are both measurable and can serve as valuable proxies
for longer-term outcomes and impact when those are not feasible to measure.

G. Think SMART—and beyond SMART

The predominant recommendation in the broader M&E field is to select “SMART” indicators
which are Specific, Measurable, Achievable, Relevant and Time-bound. 20 So-called SMART
indicators are designed to be clear and useful for tracking and analysis of trends toward
particular targets and identified goals.

SMART indicators are recommended for good reasons, however, there is also increasing
recognition that these types of indicators do not consistently capture shifts in the underlying
drivers of vulnerability and risk, or the nuance, complexity, or human or socioeconomic
dimensions of resilience. Discussions among experts turn to using both qualitative and
quantitative indicators to address these issues; however, qualitative indicators pose their own
challenges, such as not being able to aggregate and being vague in terms of progress and results.
This tension appears to not be resolved, and there are likely many ripe areas for exploring
creative solutions and learning opportunities around quantitative versus qualitative indicators.



19 Waiting for climate change to affect populations and for natural disasters to strike in order to measure
resilience is impractical.
20 SMART stands for Specific: Impacts and outcomes and outputs must use change language —they must

describe a specific future condition; Measurable: Results, whether quantitative or qualitative, must have
measurable indicators, making it possible to assess whether they were achieved or not; Achievable: Results
must be within the capacity of the partners to achieve; Relevant: Results must make a contribution to selected
priorities of the national development framework; and Time-bound: Results are never open-ended—there is an
expected date of accomplishment (UNDP 2009).

                                                     47
There are also alternative frameworks for indicator selection, which include the ADAPT
principles of adaptive learning and management, dynamic, active, participatory, and thorough
(see Villaneuva 2011). The Adaptation Fund also has a checklist for selecting indicators that are
valid, precise, practical/affordable/simple, reliable, sensitive, clear, useful, and owned
(Adaptation Fund 2014). There is no single “best” set of principles or checklists for indicator
selection. Rather, those who are selecting indicators should consider all of these concepts and
run any proposed indicators against a mental checklist to ensure they are informed given these
considerations.

G. Each indicator should be accompanied by a specific methodology.

No indicator is complete without guidance on methodologies to be used to ensure the indicator
is based on common assumptions and guidelines. Some methodologies are very simple and
open-ended. For example, some institutions allow reporting entities to choose their own
calculation approaches, including different methods for identifying baselines and different
assumptions or models for calculations. This provides flexibility and less burden; however, the
tradeoff is that reported indicators typically cannot be compared against each other, and it is not
possible to accurately aggregate data. Other institutions require very specific methodologies to
be used, and some of these are considered either very burdensome or not suitable for specific
circumstances.

Developing methodologies can be the hardest and most time consuming part of indicator
selection. Because the methodologies are where the practical realities of assumptions, analytical
requirements, data collection burden, and analytical considerations come into play, until the
methodologies are developed, indicators should not generally be considered final. Thankfully,
for many existing indicators, others have already developed methodologies, and these often can
be used outright or adapted for a new application.

H. Indicators can only go so far: monitoring and reporting on indicators will not answer
everything.

Even an ideal monitoring system using ideal indicators will not answer all questions of interest.
Evaluation can help to fill gaps, but it too cannot answer important questions all of the time.
“Evaluative” or other “learning” approaches can help to bridge gaps with both “soft” and “hard”
data and analysis. The question is about scaling the investment to match the demand and
business case, and to pick and choose which approaches to use for what purposes.

Finally, identifying indicators is typically an iterative process, therefore although some initial
scoping can take place based on current research and further input and discussion, it is likely
that a strong set of proposed indicators will take some time to develop through an engagement
and piloting process. Indicators could then be piloted through several volunteer project teams
that work across different program areas. Ideally this would entail minimal additional burden
on these teams, particularly if data on the indicators are already available.21 This exercise would
inform the viability and utility of the indicators, including the extent to which the indicators
could be aggregated, and ultimately how they could be used by the target audiences.

21In some cases these same indicators may already be reported on for other internal or external/funder
purposes.

                                                 48
Recommendation 5. Develop guidance on evaluation options

Given the lack of existing examples in the field, a priority will be to further scope options and
guidance for evaluation, considering factors such the matching certain types of projects with
particular evaluation approaches. For the time being, points to consider are included below.
These are again guided by discussion at the September 2015 workshop, trends in the field of
climate and disaster resilience M&E, and ideas developed for the first draft of this scoping paper
prior to the workshop.

1. Different evaluation approaches serve different purposes

As discussed earlier in this paper, there are several types of evaluation, and many methods that
can be used. These options could include, for example, rapid mid-term evaluations conducted
every one to two years to understand whether implementation should be adjusted based on
experience. There are several evaluation options, as well as options that are not traditionally
called evaluation per se, but that can still enhance evidence-based learning, such as using
information and communication technologies (ICT) to rapidly gain stakeholder input and using
that data to adjust project strategies in real time. Some options are outlined in the CIF suite of
Approaches to Evidence-based Learning throughout the Project Cycle (CIF 2014), but there are
more that could be explored as guidance is developed.

What type of evaluation to pursue should depend on the intended purpose and use, the
evaluation questions to be answered, the suitability for particular types of projects, the stage of
the project, evaluation funding levels, and availability of required expertise, among other
considerations.

Further, it is not necessary to evaluate every project, or to evaluate “final” end-of-project impacts
alone. Evaluations can also, for example, focus on early findings, process, governance, thematic
findings across interventions, etc. In practice, mixed method approaches are often
recommended.22 Impact evaluations may in fact be less appropriate or viable than other types
of evaluation for a majority of interventions.

Statistically rigorous impact evaluation using experimental or quasi-experimental design will be
one option, suitable for certain kinds of interventions, perhaps those with the following
characteristics:
        There is not existing evidence base of the intervention’s effectiveness: Instead, the
         evaluation will test the intervention’s effectiveness to establish an evidence base;
        The evaluation can be built up front into project design, particularly for evaluations
         aiming to use random control trials;23

22 See, for example, discussion in OECD 2015 which suggests that, given the multifaceted nature of adaptation,
it is essential to use a portfolio of monitoring and evaluation tools.
23 It is generally recommended to build plans for impact evaluation into the project design and budget up front,

to ensure that (a) the project is suitable for such evaluations (e.g., randomization is possible and the sample


                                                      49
       Control and treatment groups (of sufficient size and characteristics) can be identified,
        and there are no ethical, political, or other major conflicts in establishing these groups;
       The intervention will remain sufficiently stable during the time the evaluation is
        conducted;
       There is reason to believe that the results of the intervention (based on evaluation
        findings) can be replicated;
       The intervention has the potential to be influential—thus the results of the evaluation
        can be used to inform important decisions (justifying the evaluation investment); and
       Funding for the evaluation is available.

2. Both attribution and contribution are viable

Due to the many influencing factors affecting resilience, the reality that many donors or other
contributors are supporting the same resilience intervention, and methodological challenges
surrounding attribution, it is often hard or impossible for evaluations to be able to directly link
results to a singular intervention. For this reason, contribution to a particular change or result,
not attribution solely to one intervention, is often more realistically identifiable.

This practical reality can be difficult to accept, particularly with pressures to produce returns on
investment. But there is an increasing awareness and acceptance of this reality, and some M&E
systems are being designed to embrace contribution as the expected norm, even if identifying
attribution is still sought where possible.

3. Focus on evaluation of interim outcomes

For evaluations that focus on results, the measured outcomes or impacts necessarily need to be
identified and measured during the evaluation time frame. Given the long time horizon for
achieving resilience, this typically necessitates evaluating interim outcomes, such as changes in
behavior of a target population during the duration of a project, rather than long-term impact.
This practical reality is not well recognized yet, particularly when evaluation is focused on
identifying results (and the evaluations are called, for example, “outcome” or “impact”
evaluations).

Finally, it will be important to view evaluation as part of the broader M&E system, even though
it typically is also an independent function. Evaluation can and should, however, factor in and
incorporate all aspects of an M&E system including results frameworks and indicators.

These options and further guidance on where to match projects with particular options can be
pursued in more depth, and particular candidate projects can at least conceptually be matched


size will be large enough), (b) sufficient resources will be available to ensure a quality impact evaluation, and
(c) that key stakeholders are aware that such an evaluation will occur. However, impact evaluations using
quasi-experimental methods in lieu of random control trials can often be designed and implemented ex-post,
without prior planning or budgeting. In some cases, this option may even be preferable if conducting a random
control trial poses ethical problems (e.g., it is unethical to withhold program benefits from certain populations)
or is simply not possible for other reasons.

                                                       50
with opportunities to illustrate how evaluation could be undertaken in practice. While
developing guidance on options, consideration should be paid to the reality that only a small
group of evaluation experts understand the full landscape of evaluation—and the pros and cons
associated with various evaluation approaches. Even fewer experts deeply understand both
evaluation and climate and disaster resilience. Therefore, consultations with experts with
different background and experiences (from each other) is advised to create a more complete
picture and identify a suite of viable options.




                                             51
VI. Path Forward
This scoping study highlights the current state, challenges, and opportunities surrounding
climate and disaster resilience M&E. The research conducted for this scoping study, the
workshop focusing on this work in September 2015, and an upswell of other recent work in this
area provide a foundation upon which to develop an effective climate and disaster resilience
M&E system at the World Bank.

The WB has a timely opportunity to advance the current climate and disaster resilience M&E
work underway at the WB, which is thus far largely ad-hoc and unique to individual projects or
programs. In other words, the work thus far has not been driven by a clear, strategic, and cross-
cutting set of WB-driven goals and objectives for climate and disaster resilience. A
corresponding, principle-based and use-driven M&E system has not yet evolved. The WB can
advance this work by undertaking a within- and cross-program step-wise process to climate and
resilience M&E, resulting in an integrated M&E system that serves both learning and
accountability functions across the WB—from the project to the program and corporate levels.

As mentioned, other large institutions could also approach developing or refining climate and
disaster resilience M&E systems using a similar approach.

The following actions are advised to take this work forward:

1. Refine the overarching M&E principles to guide development of the overarching M&E system
   and its primary components.

2. Based on additional research and consultation, and informed by the preliminary ideas herein,
   develop a high-level results framework that can serve as a reference and, where applicable,
   as a basis for more specific project-level frameworks.

3. Once the above steps are completed, develop a proposed set of well-informed resilience
   indicators highlighting the pros and cons/tradeoffs involved with indicator options. Pilot
   data collection and reporting on these indicators could be done at the project level. Then
   based on pilot experience, the indicators could be further refined as needed for broader
   implementation. This process could easily take one year if not longer to complete. For some
   organizations this process of thoughtfully identifying and then pilot testing new indicators
   takes a few years.

4. Develop additional guidance on evaluation options, further outlining what types of
   evaluation approaches and methods may be suitable for different types of climate and
   disaster resilience projects and purposes. Consider financing and other resource
   requirements, planning and timing needs (e.g., when in the project cycle would certain
   evaluation approaches be appropriate?), and the type of capacity that would be needed.
   Create a decision tree or options matrix that incorporates these factors.
   The evaluation work in steps 2 and 3 could be done simultaneously, following the
   identification of the overarching M&E guiding principles. Ultimately, once implemented,


                                               52
   evaluations would also refer to results frameworks and indicators. In the meantime,
   however, developing evaluation guidelines is not dependent on completion of steps 2 and 3.

The development of an effective climate and disaster resilience M&E system takes time. A step-
wise, iterative approach with testing and refinement based on early experience in a variety of
project contexts helps to avoid premature full-scale implementation.

Beneficiaries, donors, managers, implementers, evaluators, and other key stakeholders can both
inform and be informed by this work on disaster and climate resilience M&E, which is evolving
quickly at the right time given the unprecedented nature of the challenge and the rapid rise in
global commitment to solving it.




                                              53
Annex 1. Bibliography

Adaptation Fund. 2014. Core Indicator Methodologies AFB/EFC.14/613. Washington, DC:
Adaptation Fund.

Arctic Council. 2013. Arctic Resilience Interim Report 2013. Stockholm Environment Institute
and Stockholm Resilience Centre. Stockholm, Sweden: Artic Council.

Bours, D., McGinn, C., Pringle, P. January 2014. Guidance Note 1: Twelve Reasons Why Climate
Change Adaptation M&E is Challenging. Phnom Penh and Oxford: SEA Change CoP & UKCIP.

Bours, D., McGinn, C., Pringle, P. May 2014. Design, Monitoring, and Evaluation in a Changing
Climate: Lessons Learned from Agriculture and Food Security Programme Evaluations in Asia.
Phnom Penh and Oxford: SEA Change CoP & UKCIP.

Brooks, N., Anderson, S., Burton, I., Fisher, S., Rai, N., Tellam, I. 2013. TAMD, an Operational
Framework for Tracking Adaptation and Measuring Development. Climate Change Working
Paper 5. London: International Institute for Environment and Development.

Churchman, C.W. 1967. "Wicked Problems." Management Science 14 (4). Application Series
(Dec., 1967), pp. B141-B142.

CIF (Climate Investment Funds). 2014. Approaches to Evidence Based Learning throughout the
CIF Project Cycle. Washington, DC: CIF.

CIF. 2015a. Dominica 2015 Strategic Climate Resilience Program Update. Internal draft not yet
public. Washington, DC: CIF.

CIF. 2015b. Pilot Program for Climate Resilience. Website. Washington, DC: CIF.

CIF. 2015c. PPCR 2014 Results Report. PPCR/SC.15/Inf.4. Washington, DC: CIF.

CIF. 2015d. PPCR Core Indicator Monitoring Data (see Dominica). Washington, DC: CIF.

CIF. 2015e. PPCR Results Framework and Monitoring and Reporting Toolkit. Washington, DC:
CIF.

CIF. May 2015f. Summary of the Co-Chairs Joint Meeting of the CTF and SCF Trust Fund
Committees. Internal document. Washington, DC: CIF.

CIF. 2015g. Mozambique: Sustainable Land & Water Resource Management Project. Washington,
DC: Climate-Eval.

Climate-Eval. 2014. Tackling a Key 21st Century Evaluation Challenge: International Conference
on evaluating Climate Change and Development. Website. Washington, DC: Climate-Eval.


                                                 54
Climate-Eval Community of Practice. 2015. Good Practice Study on Indicator Development,
Selection and Use Principles for Climate Change Adaptation M&E. Washington, DC: Climate-Eval
Community of Practice.

Commonwealth Scientific and Industrial Research Organisation (CSIRO) and GEF Scientific
Technical Advisory Panel (STAP). June 2015. The Resilience, Adaptation Pathways and
Transformation Assessment (RAPTA) Framework. Website. Washington, DC: Global
Environment Facility.

De Nys, E., Engle, N.L. 2015. Living with the Semi-arid and Proactive Drought Management in
Northeast Brazil: a New Perspective. Agua Brasil series. Report No. 90527. Washington, DC:
World Bank Group.

Dinshaw, A., Fisher, S., McGray, H., Rai, N., Schaar, J. 2014. Monitoring and Evaluation of Climate
Change Adaptation: Methodological Approaches. OECD Environment Working Papers, No. 74,
OECD Publishing.

Edmondson, Amy. 2012. Teaming: How Organizations Learn, Innovate, and Compete in the
Knowledge Economy. Cambridge, Mass.: Harvard Business School.

Environment Canada. 2010. Evaluation of the Improved Climate Change Scenarios Program
Final Report. Gatineau QC, Canada: Environment Canada.

Ethiopia Strategy Support Program II (ESSP II), International Food Policy Research Institute,
Institute of Development Studies, University of Sussex. 2013. Evaluation of Ethiopia’s Food
Security Program: Documenting Progress in the Implementation of the Productive Safety Nets
Programme and the Household Asset Building Programme. Sussex, England: International Food
Policy Research Institute, Institute of Development Studies, University of Sussex.

Frankenberger, T.R., Spangler, T., Nelson, S., Langworthy. M. 2012. Enhancing Resilience to Food
Security Shocks in Africa—Discussion Paper. Tucson, AZ: TANGO International.

GCF (Green Climate Fund). 2015. Decisions of the Board – Eighth Meeting of the Board, 14-17
October 2014. GCF/B.08/45, pp. 76-80. (Annexes VIII and IX.)

GEF (Global Environmental Facility). 2014. Updated Results-Based Management Framework for
Adaptation to Climate Change under the Least Developed Countries Fund and the Special Climate
Change Fund. GEF/LDCF.SCCF. 17/05/Rev.01. Washington, DC: GEF; pp. 6-7.

GEF IEO (Global Environmental Facility Independent Evaluation Office). 2014. Guidance
Document: Monitoring and Evaluation in the LDCF/SCCF. Evaluation Document No. 5.
Washington, DC: GEF IEO.

GFDRR (Global Facility for Disaster Reduction and Recovery). 2014a. Climate Change Window
Operations Manual. Internal document. Washington, DC: GFDRR.

GFDRR. 2014b. Evaluation Report 2014: Retrospective Evaluation of the GFDRR Program in a
Sample of Disaster-Prone Countries. Washington, DC: GFDRR.
                                                55
GFDRR. 2014c. GFDDR Thematic Notes - Leveraging. Washington, DC: GFDRR.

GFDRR. 2015a. Annual Report 2014. Washington, DC: GFDRR.

GFDRR. 2015b. Monitoring and Evaluation. Washington, DC: GFDRR.

GFDRR. 2015c. Monitoring and Evaluation Framework. Washington, DC: GFDRR.

GFDRR. 2015d. Terms of Reference: GFDRR Country Evaluation. Internal document. Washington,
DC: GFDRR.

GFDRR. 2015e. Who We Are. Washington, DC: GFDRR.

GFDRR. 2015f. Work Plan 2016-18. Washington, DC: GFDRR.

GFDRR and World Bank. 2014. Building Resilience: Integrating Climate and Disaster Risk into
Development. Washington, DC: GFDRR.

GIZ. 2014a. Monitoring and Evaluating Adaptation at Aggregated Levels: A Comparative Analysis
of Ten Systems. Bonn, Germany: GIZ.

GIZ. 2014b. Tailor-made monitoring & evaluation systems: addressing country-specific
information needs on climate change adaptation. Bonn, Germany: GIZ.

GIZ. 2015. Adaptation M&E Navigator. Bonn, Germany: GIZ.

GIZ and United Nations University. 2014. Assessing and Monitoring Climate Resilience: From
Theoretical Considerations to Practically Applicable Tools – A Discussion Paper. Bonn, Germany:
GIZ.

Green Climate Fund. 2015. Decisions of the Board – Eighth Meeting of the Board, 14-17 October
2014. GCF/B.08/45. Songdo, Republic of Korea: Green Climate Fund.

Herron, H., Roy, S., Bohn, B., Courtney, C., Hoagland-Grey, H. 2015. Addressing Climate Change
within Disaster Risk Management: A Practical Guide for IDB Project Preparation. Technical Note.
IDB-TN-806. Washington, DC: Inter-American Development Bank.

ICF International. 2014. Independent Evaluation of the Climate Investment Funds. Washington,
DC: World Bank.

IPCC. 2007. Climate Change 2007: Impacts, Adaptation and Vulnerability. Contribution of
Working Group II to the Fourth Assessment Report of the intergovernmental Panel on Climate
Change. M.L. Parry, J.P. Palutikof, P.J. van der Linden and C.E. Hanson, Eds. Cambridge, UK:
Cambridge University Press, 976 pp.

IPCC. 2012: Summary for Policymakers. In: Managing the Risks of Extreme Events and Disasters
to Advance Climate Change Adaptation. Field, C.B., V. Barros, T.F. Stocker, D. Qin, D.J. Dokken,
                                               56
K.L. Ebi, M.D. Mastrandrea, K.J. Mach, G.-K. Plattner, S.K. Allen, M. Tignor, and P.M. Midgley
(eds.). A Special Report of Working Groups I and II of the Intergovernmental Panel on Climate
Change. Cambridge, UK: Cambridge University Press; pp. 1-19.

Leiter, T. 2015. “Linking Monitoring and Evaluation of Adaptation to Climate Change across
Scales: Avenues and Practical Approaches.” In D. Bours, P. Pringle & C. McGinn (Eds.),
Monitoring and Evaluation of Climate Change Adaptation and Resilience Interventions. New
Directions for Evaluation, 147.

Levin, K., Cashore, B., Bernstein, S., Auld, G. 2012. “Overcoming the tragedy of super wicked
problems: constraining our future selves to ameliorate global climate change.” Policy Sciences
45(2): 123-152.

Mitchell, A. 2013. Risk and Resilience: From Good Idea to Good Practice - A Scoping Study for the
Experts Group on Risk and Resilience. Paris: OECD.

OECD (Organisation for Economic Co-operation and Development). 2006. Adaptation to Climate
Change: Key Terms. Paris: OECD.

OECD, 2009. Integrating climate change adaptation into development planning: A practice-
oriented training based on the OECD Policy Guidance. Paris: OECD.

OECD. 2014a. Guidelines for Resilience Systems Analysis: How to analyse risk and build a
roadmap to resilience. Paris: OECD.

OECD. 2014b. Monitoring and Evaluation of Climate Change Adaptation. Paris: OECD.

OECD. 2015. National Climate Change Adaptation: Emerging Practices in Monitoring and
Evaluation. Paris: OECD.

Olivier, J., Leiter, T., Linke, J. 2013. Adaptation made to measure: A guidebook to the design and
results-based monitoring of climate change adaptation projects. Second edition. Bonn, Germany:
GIZ.

Overseas Development Institute, GFDRR, and the World Bank Group. 2015. Unlocking the ‘Triple
Dividend’ of Resilience: Why investing in disaster risk management pays off. London and
Washington, D.C.: ODI and the World Bank Group.

Padwe, Jonathan. 2014. Bringing Innovation to Scale: A Synthesis of Learning from Four Projects
of the Economic Innovations Incentives Fund. Washington, DC: Oxfam America.

Rockefeller Foundation. 2015. Resilience webpage. New York: Rockefeller
Foundation.

Spearman, M. and McGray, H. 2011. Making Adaptation Count: Concepts and Options for
Monitoring and Evaluation of Climate Change Adaptation. Eschborn, Germany: GIZ.



                                               57
Tracking Adaptation and Measuring Development (TAMD). 2013. TAMD Climate Change
Indicators: Methodological Notes. London: International Institute for Environment and
Development.

Turnbull, M., Sterrett, C.L., Hilleboe, A. 2013. Toward Resilience: A Guide to Disaster Risk
Reduction and Climate Change Adaptation. Baltimore, MD: Catholic Relief Services.

UK DFID (Department for International Development). 2011. Defining Disaster Resilience: A
DFID Approach Paper. London: DFID.

UK DFID. 2015. Summary of ICF Key Performance Indicators. Internal document. London: DFID.

UNDP. 2007. Monitoring and Evaluation Framework for Adaptation to Climate Change. Draft for
comment. UNDP, New York

UNDP. 2009. The Handbook on Planning, Monitoring and Evaluating for Development
Results. New York: UNDP

UNFCCC (United Nations Framework Convention on Climate Change). 2014. Gender and Climate
Change. Website. Bonn, Germany: UNFCCC.

UNFCCC. 2015. What is Adaptation? Website. Bonn, Germany: UNFCCC.

UNODC (United Nations Office on Drugs and Crime). 2015. What is Evaluation? Website. New
York: UNODC.

Villanueva, P.S. 2011. Learning to ADAPT: Monitoring and Evaluation Approaches in Climate
Change Adaptation and Disaster Risk Reduction—Challenges, Gaps and Ways Forward. SCR
Discussion Paper 9. Brighton, UK: Institute of Development Studies.

Williams, A. 2014. Evaluation for Strategic Learning: Assessing Readiness and Results.
Washington DC: Center for Evaluation Innovation.

Williams, A. and GEF STAP. 2015. Climate Change Adaptation Monitoring & Evaluation: Lessons
from Monitoring & Evaluation in Climate-vulnerable Sectors. Internal review draft.

Williams, A. and World Bank E Institute. 2015. Climate Change Mitigation M&E E Learning
Course. Internal working draft.

World Bank. 2005. Productive Safety Nets Programme (PSNP). Washington, DC: World Bank.

World Bank. 2012, updated 2013. Core Sector Indicators and Definitions. Washington, DC:
World Bank.

World Bank. 2013a. Africa - Second phase of Senegal River Basin Multipurpose Water Resources
Development Project. Annex 1: Revised Results Framework and Monitoring Indicators.
Washington, DC: World Bank, pp. 50-56.


                                                 58
World Bank. 2013b. Project Appraisal Document: Natural Resources Management in a Changing
Climate Project, Annex 1: Results Framework and Monitoring. Report No: 74820-ML.
Washington, DC: World Bank, pp. 22-26.

World Bank. 2014a. Climate and Disaster Risk Screening Tools. Washington, DC: World Bank.

World Bank. 2014b. Foster Climate-Smart Agriculture. Washington, DC: World Bank.

World Bank. 2014c. Implementation Status & Results. Bosnia and Herzegovina Drina Flood
Protection Project (P143844). Report No: ISR16500. Washington, DC: World Bank, pp. 2-3.

World Bank. 2014d. Project Appraisal Document: Regional Disaster Vulnerability Reduction
Project, Annex 1: Revised Results Framework and Monitoring Indicators. Washington, DC:
World Bank, pp. 27-31.

World Bank. 2015a. 2014 Joint Report on Multilateral Development Banks’ Climate Finance.
Report No: 97398. Washington, DC: World Bank.

World Bank. March 2015b. Climate Smart Agriculture Indicators for Project – Draft. Internal
draft. Washington, DC: World Bank.

World Bank. 2015c. Corporate Scorecard. Washington, DC: World Bank.

World Bank. 2015d. Disaster Vulnerability Reduction Project. Washington, DC: World Bank.

World Bank. 2015e. IDA Results Measurement System. [dataset] Washington, DC: World Bank.

World Bank. 2015f. Impact Evaluation (IE) Concept Note: The Impact of Targeting Mechanisms
on Efficiency and Equity of Irrigation in Mozambique (P154869). August 2015. Internal
document. Washington, DC: World Bank.

World Bank. May 2015g. Understanding Long-Term Impacts in the Forest Sector: Predictive
Proxy Indicators. Internal Draft. Washington, DC: World Bank.

World Bank. 2015h. World Bank DRM and Climate Change Co-Benefit Analysis. Internal
document. Washington, DC: World Bank.

World Bank. 2012. Core Sector Indicators. Washington, DC: World Bank

World Bank, Climate Investment Funds, and PPCR. 2015. Key Lessons from the Pilot Program
for Climate Resilience. Internal working draft. August 2015. Washington, DC: World Bank.

World Bank Independent Evaluation Group. 2014. Adapting to Climate Change: Assessing World
Bank Group Experience. Phase III of the World Bank Group and Climate Change. Washington,
DC: World Bank.

World Health Organization. 2011. Gender, Climate Change and Health. Geneva: World Health
Organization.
                                              59
World Health Organization. 2012. Mainstreaming Gender in Health Adaptation to Climate
Change Programmes: User’s Guide. Geneva: World Health Organization.




                                            60
Annex 2. World Bank Project Indicator Examples

Example 1: Drina Flood Protection Project, Bosnia and Herzegovina (World Bank 2014c)




                                           61
Example 2: Regional Disaster Vulnerability Reduction Project, Saint Vincent and the
Grenadines (World Bank 2014d)




                                             62
Example 3: Senegal River Basin: Multipurpose Water Resources Development Project 2 (World
Bank 2013a)




                                          63
Annex 3. PPCR Results Framework (CIF 2015e)

                             TRANSFORMATION / PARADIGM SHIFT
  Global:
  CIF Final
                              Improved climate-resilient development consistent with other
  Outcome       Objective:
                              CIF objectives
   (15-20
   years)
                                               IMPACT
                              A1. Increased resilience of households, communities,
                Impact 1      businesses, sector and society to climate variability and climate
                              change
                               Change in % of households whose livelihoods have improved
  Country:                        (A1.1 - non-core optional indicator)
Contribution                   Change in budget allocations to support climate change/climate
                                  variability (A2.2 - non-core optional indicator)
 of Strategic   Indicator
Program for                    Change in losses/damages from CC/CR in PPCR areas (A1.2 -
                                  non-core optional indicator)
   Climate
 Resilience                    % of people with year round access to water (A1.4 - non-core
                                  optional indicator)
  (SPCR) to
                              A2. Avoided creation of new risks and reduced existing risks in
Transformat     Impact 2
                              society
 ive Impact
                               Degree of integration of climate change in national including
                                  sector planning (A2.1 - core indicator)
                Indicator      Change in budget allocations to support climate change and
                                  climate variability (A2.2 – non-core indicator)
                               Total Number of direct and indirect beneficiaries; Number of
                                  beneficiaries relative to total population (Scorecard 5)
                                               OUTCOMES
                              In order to prepare for and respond to climate variability and
                Outcome
                              climate change
                               Extent to which vulnerable households, communities,
                                  businesses and public sector use improved PPCR supported
                                  tools (B1 - core indicator)
                               Evidence of strengthened government capacity and coordination
 Country:                         mechanism to mainstream climate resilience (B2 - core
 SPCR                             indicator)
 Outcomes                      Evidence showing that climate information, products/services
                Indicator
                                  are used in decision making in climate sensitive sectors (B3 -
                                  non-core optional indicator)
                               Leverage of PPCR funding against public & private investments
                                  in climate sensitive sectors (B4 - non-core optional indicator)
                               Quality of & extent to which climate responsive
                                  instruments/investment models are developed & tested (B5 -
                                  core indicator)




                                               64
Annex 4: Reference List of Indicators Used by
Selected Institutions/Efforts

About this Reference List:
   This is a working draft reference. As such, it is not perfectly organized or refined; it is likely that
    some indicators could fit in different levels (e.g., outcome instead of impact or vice versa) or be
    associated with different topics.
   Grouping herein (by level or topic) does not necessary reflect how the source fund/effort has
    grouped their respective indicators. Different funds/efforts group indicators differently. Some
    indicators have intentionally been moved for the purpose of creating this reference to fit better as a
    consistent grouping with other indicators from different sources.
   Some indicators are currently being refined (e.g., UK DFID’s) or are in the draft stages (e.g., roughly
    half of GCF’s).
   Some indicators are not required to be reported on and likely have not yet been reported on even
    though they are listed as official indicators (e.g., PPCR’s optional indicators). This is important
    because it may mean there is little or no field experience in terms of implementation for these
    indicators.
   There are many other institutions/organizations/efforts with resilience indicators: Those listed in this
    reference reflect only a small selected group for illustrative purposes.

Acronyms

       AF                 Adaptation Fund
       CIF                Climate Investment Funds
       DFID               United Kingdom’s Department for International Development – International
                          Climate Fund
       GCF                Green Climate Fund
       ICF                International Climate Fund
       GFDRR              Global Facility for Disaster Reduction and Recovery
       LDCF/SCCF          Global Environment Facility Least Developed Countries Fund / Special Climate
                          Change Fund
       PPCR               Pilot Program for Climate Resilience
       TAMD               Tracking Adaptation and Measuring Development




                                                      65
Table 1. Summary Checklist of Indicators by Topic and Institution/Effort
  LEVEL / topic (shorthand)                                        Institution/Effort
  TRANSFORMATION / PARADIGM SHIFT           AF        DFID   GCF    GFDRR LDCF/SCCF     PPCR   TAMD
  Transformational impact                              ✔
  Climate-resilient sustainable
                                                             ✔                           ✔
  development
  IMPACT                                    AF        DFID   GCF   GFDRR    LDCF/SCCF   PPCR   TAMD
  Human resilience                                     ✔      ✔      ✔                           ✔
  Livelihoods (Jobs and Income)             ✔          ✔      ✔                ✔         ✔
  Physical/Assets/Economic Losses and       ✔                 ✔      ✔         ✔         ✔
  Damages
  Water access                                               ✔                           ✔
  Health measures                                            ✔
  Food Security                                              ✔
  Social, environmental, economic co-                        ✔
  benefits
  OUTCOME                                   AF        DFID   GCF   GFDRR    LDCF/SCCF   PPCR   TAMD
  Beneficiaries                             ✔          ✔      ✔                 ✔        ✔
  Policies, Regulations, & Planning                    ✔      ✔      ✔          ✔        ✔      ✔
  Institutional Coordination & Systems                                          ✔        ✔      ✔
  Finance & Investments leveraged                      ✔             ✔                   ✔
  Risk Identification & Risk Reduction                               ✔         ✔
  Mechanisms
  Institutional Capacity and Knowledge                 ✔             ✔         ✔                ✔
  Technologies & Innovative Solutions                        ✔                 ✔
  Preparedness / Early Warning Systems      ✔                ✔       ✔         ✔
  Risk Financing & Insurance                                         ✔
  Monitoring and Reporting Systems                                             ✔
  Awareness & Decision-Making                                ✔       ✔         ✔         ✔      ✔
  Development & Use of Tools and                             ✔                           ✔
  Products
  Ecosystems & Habitats                     ✔          ✔     ✔
  Financial Support                                                  ✔                   ✔       ✔
  OUTPUT                                    AF        DFID   GCF   GFDRR    LDCF/SCCF   PPCR   TAMD
  Training                                                                      ✔                ✔
  Supported Entities                                                 ✔
  Stakeholder Participation                                                                     ✔




                                                 66
Table 2. List of Indicators by Level, Topic, and Institution/Org
LEVEL /        Specific indicator language used by Institution/Effort
Topic

TRANSFORMATION / PARADIGM SHIFT INDICATORS
Transformational impact
        DFID   Extent to which ICF intervention is likely to have a transformational impact
Climate-resilient sustainable development
        GCF    Degree to which the Fund is achieving a climate-resilient sustainable development impact
               (draft – not yet adopted)
       PPCR    Improved climate-resilient development consistent with other CIF objectives (includes both
               core and optional indicator)

IMPACT INDICATORS
Human resilience
        DFID   Number of people with improved resilience as a result of ICF support
     GFDRR     Reduction in people affected from disasters
        GCF    Change in expected losses of lives and economic assets (US$) due to the impact of extreme
               climate-related disasters (draft – not yet adopted)
       TAMD    Numbers of people better able to cope with climate change and variability
Livelihoods (Jobs and Income)
          AF   Increased income, or avoided decrease in income
        DFID   (1) Number of direct jobs created as a result of ICF support;
               (2) Number of forest dependent people with livelihoods benefits protected or improved as a
               result of ICF support [also mitigation indicator]
        GCF    Number of males and females benefiting from the adoption of diversified, climate resilient
               livelihood options (draft – not yet adopted)
 LDCF/SCCF     Population benefiting from the adoption of diversified, climate-resilient livelihood options
       PPCR    Change in percent of households whose livelihoods have improved (optional indicator)
Physical/Assets/Economic Losses and Damages
          AF   Assets produced, developed, improved, or strengthened
        GCF    (1) Number and value of physical assets made more resilient to climate variability and
               change, considering human benefits (draft – not yet adopted);
               (2) Change in expected losses of lives and economic assets (US$) due to the impact of
               extreme climate-related disasters (draft – not yet adopted)
     GFDRR     (1) Reduction in economic losses from disasters;
               (2) Schools and other public infrastructure made safer (retrofitting or new construction)
 LDCF/SCCF     Type and extent of assets strengthened and/or better managed to withstand the effects of
               climate change
       PPCR    Change in losses/damages from CC/CR in PPCR areas (optional indicator)
Water Access
        GCF    Number of males and females with year-round access to reliable and safe water supply
               despite climate shocks and stresses (adopted)
       PPCR    Percent of people with year round access to water (optional indicator)

Health Measures
        GCF    Number of males and females benefiting from introduced health measures to respond to
               climate-sensitive diseases (adopted)

                                                    67
Food Security
       GCF      Number of food secure households (in areas/periods at risk of climate change impacts)
                (adopted)




                                                  68
OUTCOME INDICATORS
Beneficiaries
          AF    Number of beneficiaries (direct and indirect)
        DFID    Numbers of people supported by ICF programmes to cope with the effects of climate change
         GCF    Number of direct and indirect beneficiaries; Number of beneficiaries relative to total population
                (draft – not yet adopted)
 LDCF/SCCF      Number of direct beneficiaries
       PPCR     Number of people supported by PPCR to cope with CC/CR (core indicator)
Policies, Regulations, & Planning
        DFID    Level of integration of climate change in national planning as a result of ICF
         GCF    Institutional and regulatory systems that improve incentives for climate resilience and their
                effective implementation (draft – not yet adopted)
     GFDRR      (1) Countries/cities implementing new or revised policies to address disaster risks;
                (2) Number of countries with improved policy analysis; strategy reviews; feasibility studies;
                ﬁscal risk assessments; and ﬁnancial analysis tools;
 LDCF/SCCF      Regional, national and sector-wide policies, plans and processes developed and strengthened
                to identify, prioritize and integrate adaptation strategies and measures; Sub-national plans
                and processes developed and strengthened to identify, prioritize and integrate adaptation
                strategies and measures
       PPCR     Degree of integration of climate change in national including sector planning (core indicator)
        TAMD Representation of strategies that address climate change in relevant planning documents and
                processes
Institutional Coordination & Systems
     GFDRR      Number of countries with institutional capacity developed in the conduct of recovery
                assessments; development and institutionalization of good practice recovery planning; and
                implementation of standards in government systems
 LDCF/SCCF      Institutional arrangements to lead, coordinate and support the integration of climate change
                adaptation into relevant policies, plans and associated processes

       PPCR     Evidence of strengthened government capacity and coordination mechanism to mainstream
                climate resilience (core indicator)
       TAMD     Extent and quality of coordination of climate risk management across relevant institutions
Finance & Investments leveraged
        DFID    (1) Volume of public finance mobilised for climate change purposes as a result of ICF funding;
                (2) Volume of private finance mobilised for climate change purposes as a result of ICF funding
     GFDRR      (1) Financing for resilient recovery that GFDRR has helped leverage (e.g. post-disaster
                assessment and other assistance);
                (2) Investment made in risk reduction measures that GFDRR has helped leverage;
                (3) Amount leveraged in financial protection;
                (4) Post disaster countries where GFDRR helped leverage large scale investment in resilient
                recovery and risk reduction;
                (5) Number of countries where GFDRR helped leverage new investments in structural or non-
                structural risk reduction;
                (6) Number of countries where GFDRR helped leverage new contingent credit or risk
                ﬁnancing instruments
       PPCR     Leverage of PPCR funding against public & private investments in climate sensitive sectors
                (optional indicator)
Risk Identification & Risk Reduction Mechanisms




                                                    69
     GFDRR    (1) Number of countries with effective new solutions in risk assessment; open data practices;
              remote sensing; and institution building in place;
              (2) Number of countries provided with new analytical and technical products and tools to
              support risk assessment; data platforms; and remote sensing;
              (3) Number of countries with effective new solutions in risk reduction policy; land-use
              planning; building standards; strategy; and planning and investment in place;
              (4) Number of countries with improved policy analysis; sector speciﬁc norms; guidelines and
              tools
 LDCF/SCCF    Risk and vulnerability assessments, and other relevant scientific and technical assessments
              carried out and updated
Institutional Capacity and Knowledge
       DFID   Level of institutional knowledge of climate change issues as a result of ICF support.
     GFDRR    (1) Disaster affected countries using enhance capacity and improved planning to implement
              resilient recovery and risk reduction programs;
              (2) Number of countries with improved institutional capacity in sovereign disaster risk
              ﬁnancing; property catastrophe risk insurance; agricultural insurance; and disaster
              microinsurance;
              (3) Number of countries with improved institutional capacity in data collection, sharing and
              management; hazard and exposure modeling; mapping; risk assessment; and risk
              communication;
              (4) Number of countries with improved institutional capacity in risk identification, risk
              reduction, preparedness, financial protection, resilient recovery;
              (5) Number of countries with improved institutional capacity in risk reduction policy; land-use
              planning; building standards; strategy; and planning and investment
 LDCF/SCCF    Capacities of regional, national and sub-national institutions to identify, prioritize, implement,
              monitor and evaluate adaptation strategies and measures
      TAMD    Institutional capacity for decision-making under climatic uncertainty
Technologies & Innovative Solutions
        GCF   Number of technologies and innovative solutions transferred or licensed to support low-
              emission development as a result of Fund support (draft – not yet adopted)
 LDCF/SCCF    Extent of adoption of climate-resilient technologies/ practices
Preparedness / Early Warning Systems
         AF   Number of early warning systems
        GCF   Number of males and females reached by [or total geographic coverage of] climate-related
              early warning systems and other risk reduction measures established/ strengthened (draft –
              not yet adopted)
     GFDRR    (1) Increased accuracy and timeliness of weather forecasts and early warning;
              (2) Improved performance of national/city agencies in the quality and timeliness of emergency
              response (preparedness exercises; level of preparedness);
              (3) Number of countries with improved institutional capacity in the use of disaster risk
              information for early warning; search and rescue; and contingency planning;
              (4) Number of countries with effective new solutions in emergency management; public
              awareness; early warning; and service delivery of national hydromet services; in place;
              (5) Number of countries with improved policy analysis; hydromet feasibility studies; and
              operational guidelines;
              (6) Number of countries where GFDRR helped leverage new investments in preparedness or
              early warning
 LDCF/SCCF    (1) Number of people/ geographical area with access to improved, climate-related early-
              warning information;
              (2) Number of people/ geographical area with access to improved climate information services
Risk Financing & Insurance




                                                    70
     GFDRR       (1) Number of countries with effective new solutions in sovereign disaster risk ﬁnancing;
                 property catastrophe risk insurance; agricultural insurance; and disaster microinsurance in
                 place;
                 (2) Improved financial protection against disasters (reserves, contingency mechanisms or risk
                 transfer);
                 3) Countries adopting or improving budgetary mechanisms to appropriate and execute public
                 resources in case of disasters;
                 (4) Countries with more development property catastrophe risk insurance markets
Monitoring and Reporting Systems
 LDCF/SCCF       Countries with systems and frameworks for the continuous monitoring, reporting and review of
                 adaptation
Awareness & Decision-Making
           GCF   (1) Use of climate information products/services in decision-making in climate-sensitive
                 sectors;
                 (2) Number of males and females made aware of climate threats and related appropriate
                 responses (adopted)
     GFDRR       (1) Improved generation or communication of disaster risk information;
                 (2) Increased application of risk information in public policy and investment planning
 LDCF/SCCF       Public awareness activities carried out and population reached
      PPCR       Evidence showing that climate information, products/services are used in decision making in
                 climate sensitive sectors (optional indicator)
      TAMD       (1) Extent to which climate information is (i) used to inform responses to climate change, and
                 (ii) generated at all levels of society;
                 (2) Awareness of climate change issues, risks and responses
Development & Use of Tools and Products
           GCF   Use by vulnerable households, communities, businesses and public-sector services of Fund
                 supported tools, instruments, strategies, and activities to respond to climate change and
                 variability (draft – not yet adopted)
      PPCR       (1) Extent to which vulnerable households, communities, businesses and public sector use
                 improved PPCR supported tools (core indicator);
                 (2) Quality of & extent to which climate responsive instruments/investment models are
                 developed & tested (core indicator)
Ecosystems & Habitats
            AF   Natural habitats protected or rehabilitated
       DFID      Value of ecosystem services generated or protected as a result of ICF support
           GCF   (1) Coverage/scale of ecosystems protected and strengthened in response to climate
                 variability and change (draft – not yet adopted);
                 (2) Value (US$) of ecosystem services generated or protected in response to climate change
                 (draft – not yet adopted)
Financial Support
     GFDRR       (1) Amount $ in risk reduction;
                 (2) Amount $ in resilient recovery
      PPCR       Change in budget allocations to support climate change/climate variability (optional indicator)
      TAMD       Financial support for climate change mainstreaming & related initiatives
OUTPUT INDICATORS
Training
 LDCF/SCCF       Number of people trained to identify, prioritize, implement, monitor and evaluate adaptation
                 strategies and measures
      TAMD       Level of knowledge and training of key personnel in climate change issues and mainstreaming
                 processes

                                                      71
Supported Entities
     GFDRR    Number of post-disaster countries supported in conducting rapid and coordinated post-
              disaster assessments; developing post disaster recovery frameworks
Stakeholder Participation
      TAMD    Quality of stakeholder engagement in decision-making to address climate change




                                                72
73
Annex 5. Considerations Regarding Results Frameworks

The considerations on results frameworks below are based on a conceptual starting point
prepared for the initial draft of this paper and on input provided by participants at the September
23-24, 2015 workshop. Additional ideas provided by workshop participants can be found in the
separate workshop report.

The are different options in terms of how to approach results frameworks. As previously
mentioned, a common framework adopted by some peer institutions is a linear, bottom-to-top
theory of change (or logic model/log frame) that starts with inputs (or activities) at the bottom
and end with impact at the top (see Exhibit 2). This same information can be depicted
horizontally or vertically but reversed, with activities at the top and impacts at the bottom.

Exhibit A-1 below shows a simplified conceptual linear framework. In reality, the substance of
any such framework needs to be carefully constructed, and it may preferable given the diversity
of resilience work to have one, high-level framework that has relevance across programs and
then different frameworks for each project.


                       Exhibit A-1. Simplified Conceptual Example of a
                                  Linear Results Framework
                       (Simplified conceptual examples. Would need to be
                              tailored for each sector and project)




                                                74
There are several variations on the simplified linear framework. Most would involve relaying
more real-world complexity, such as the example shown below in Exhibit A-2, where a multi-
dimensional results pathway is combined with a vertical results hierarchy.

Importantly, linear frameworks—as well as other types of results frameworks—sometimes also
include assumptions and preconditions—to make explicit the required underpinnings of any
effective program/project design. These additions are recommended, at a minimum to be part
of the work done in developing the framework, even if they are not included in the final
visualization.


  Exhibit A-2. Example Results Framework: Climate Change Scenarios Program Level Logic
                               Model (Environment Canada)




Source: Environment Canada (2010).


Beyond a simple linear framework, there are many other alternative frameworks. Below are two
illustrative examples. It is helpful to keep in mind that there is no single best approach to
developing a framework: These are simply different examples to elicit ideas and perhaps serve
as starting points.

The first example is an M&E framework for climate change adaptation developed for the United
Nations Development Programme (UNDP 2007) (see Exhibit A-3). This example, also
reproduced in the Climate-Eval CoP Good Practices Study (Climate-Eval CoP 2015), shows a
simple thematic sector-breakdown with generalized processes intended to support adaptation
and corresponding indicators.


                                             75
                            Exhibit A-3. UNDP CCA M&E Framework




              Source: UNDP 2007 as cited in Climate-Eval CoP 2015.
              Note: DRR = disaster risk reduction; NRM = natural resource management




The second example is the Resilience Assessment Framework developed by Technical Assistance
to Non-Governmental Organizations (TANGO) (see Exhibit A-4). This framework shows an
alternative way to visualize multi-dimensional results. As described in the Climate-Eval Good
Practices Study, this TANGO Framework was developed as part of a 2013 expert consultation on
resilience measurement for food security conducted for the Food and Agriculture Organization
of the United Nations and the World Food Programme (Climate-Eval CoP 2015). The framework
has a strong geographic focus on Africa and a thematic emphasis on livelihoods, disaster risk
reduction, and food security. The TANGO Resilience Assessment Framework was first presented
in a discussion paper by Frankenberger et al. (2012).




                                               76
Exhibit A-4. TANGO Resilience Assessment Framework




                       77
Monitoring and Evaluation for Resilience-building Operations                           March
2016




Additional ideas generated by breakout groups

Linear Results Framework (Group 1 of 2 working on Results Frameworks)
Below in Exhibit A-5 is a rough conceptual results “linear” results framework identified by
the first breakout group. This group was tasked with identifying a hierarchical set of
resilience results ranging from outputs at the bottom to transformational impact at the top.

     Exhibit A-5. Report out from Workshop Breakout Group on Linear Results Framework

       Transformation
           Shared prosperity and sustainable economic growth
       Impact
           Increased resilience of people, firms, communities, places, and livelihoods to
              climate shocks, stresses, and natural disasters
           Reduced loss of life
           Reduced disruption, loss and damage, displacement
           Increased recovery
           Increased food, water, livelihood security
       Outcome
           Risk-reducing behaviors/practices by better protected people, firms,
             communities
           Better protected built infrastructure/ecosystems
           Improved risk management by institutions
           Science-based decision making
       Output
           Improved awareness, knowledge (sharing), tools, practices
           Strengthened built infrastructure and ecosystems
           Institutional capacity building
           Improved science and analysis
           Deploying financial instruments and social protection
           Improved participation in planning, implementation processes




                                              78
