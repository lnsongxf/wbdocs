    Evaluation of
    Resilience-Building
    Operations
    Operational Guidance Paper
    for Project Task Teams




                                           World Bank Report | August 2017
CLIMATE CHANGE | SUSTAINABLE DEVELOPMENT
ii                        E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     World Bank Report
     August, 2017
     © 2017 International Bank for Reconstruction and Development / The World Bank
     1818 H Street NW
     Washington DC 20433
     Telephone: 202-473-1000
     Internet: www.worldbank.org


     This work is a product of the staff of The World Bank with external contributions. The findings, interpretations, and
     conclusions expressed in this work do not necessarily reflect the views of The World Bank, its Board of Executive Directors,
     or the governments they represent.

     The World Bank does not guarantee the accuracy of the data included in this work. The boundaries, colors,
     denominations, and other information shown on any map in this work do not imply any judgment on the part of The
     World Bank concerning the legal status of any territory or the endorsement or acceptance of such boundaries.


     Rights and Permissions


     The material in this work is subject to copyright. Because The World Bank encourages dissemination of its knowledge, this
     work may be reproduced, in whole or in part, for noncommercial purposes as long as full attribution to this work is given.


     Any queries on rights and licenses, including subsidiary rights, should be addressed to World Bank Publications, The
     World Bank Group, 1818 H Street NW, Washington, DC 20433, USA; fax: 202-522-2625; e-mail: pubrights@worldbank.org.


     Cover photo: © iStock/Stellalevi. Used with the permission of iStock/Stellalevi. Further permission required for reuse.
     Report and Cover design: Lauren Kaley Johnson, GSDPM, The World Bank Group
﻿                                                                            iii




Evaluation of
Resilience-Building
Operations
Operational Guidance Paper for
Project Task Teams




                                           World Bank Report | August 2017
CLIMATE CHANGE | SUSTAINABLE DEVELOPMENT
iv   E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R
CONTENTS                                                                                                                                                                                            i




Contents



Acknowledgements.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iii

Glossary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . iv

Acronyms and Abbreviations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vi

Executive Summary. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1

Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3

Section 1: Setting the Stage.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

       Why evaluate resilience-building projects/programs? .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

       Building evidence and fostering learning on “what works” in resilience-building
       projects/programs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5

       Improving the design and delivery of projects/programs to enhance results and impact.. . . . . . . . . . . 6

       What makes resilience evaluation different?. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

       What informs the design of a resilience evaluation? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8

       Prerequisite steps to a robust evaluation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

Section 2: Step-by-Step Guide .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

       STEP 1: Establish the purpose, scope, feasibility, and audience of your evaluation. . . . . . . . . . . . . . . . . 14
                Core Evaluation Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
                Resilience-specific considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15

       STEP 2: Set up the evaluation decision-making, quality standards, and communication
       requirements.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
                Core Evaluation Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20
                Resilience-specific considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22

       STEP 3: Select the appropriate evaluation design and method. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
                Core Evaluation Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
                Resilience-specific considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27

       STEP 4: Identify data collection tools and methods .. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
                Core Evaluation Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
                Resilience-specific Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
ii                                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




            STEP 5: Manage the implementation of the evaluation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
                     Core Evaluation Considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
                     Resilience-specific considerations. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

     References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49

     Annexes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 51

            Annex 1: Feasibility Checklist for Planning a Project/Program Evaluation . . . . . . . . . . . . . . . . . . . . . . . . . 51

            Annex 2: Data Collection Methods and Tools. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52

            Annex 3: Resilience Indicator Frameworks. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54

            Annex 4: Contents of a ToR for Evaluation of a Resilience-Building Project/Program.. . . . . . . . . . . . . . 55




     Boxes
     Box 1: OECD DAC Evaluation criteria tailored to resilience-building projects/programs. . . . . . . . . . . . . . . . . . . . . . 16

     Box 2: Examples of resilience-focused explanatory and learning EQs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

     Box 3: Tracking and assessing processes of change. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40

     Box 4: Subjective assessments of resilience. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40




     Figures
     Figure 1: Three core factors informing resilience evaluation design. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8

     Figure 2: Designing and delivering evaluations: 5 steps. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

     Figure 3: Generic theory of change of a resilience project/program.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28

     Figure 4: Dissemination pathways. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47




     Tables
     Table 1: The broad range of evaluation designs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24

     Table 2: A checklist for defining the key attributes of resilience-building projects/programs. . . . . . . . . . . . . . . . . . 25

     Table 3: Exploring relevant questions, designs, and methods for different resilience-building
     projects/programs. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 31

     Table 4: Example data collection plan.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36

     Table 5: Pros and cons of composite indicators.. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
ACKNOWLEDGEMENTS                                                                                             iii




Acknowledgements




This publication is a product of the World Bank ‘Results Monitoring and Evaluation for Resilience Building
Operations’ (ReM&E) project, which is part of a broader Programmatic Approach on ‘Enhancing Climate
and Disaster Resilience of World Bank Sustainable Development Operations.’ This project is managed by
the Climate Change Strategy and Operations Team and the Sustainable Development Chief Economist
Office, under the Sustainable Development Vice Presidency and the Global Themes Vice Presidency.

The ReM&E team is led by Nathan Engle and Ulf Narloch. Core team members include Sundus
Siddiqi, and Karima Ben Bih. Additional support to the team has been provided by Anna Williams, Calli
VanderWilde, Christina Irene, and Silvia Marquina-Leon. The World Bank’s Independent Evaluation Group
has played a key role in facilitating the learning components of this project. Management oversight is
provided by Marianne Fay, Stephen Hammer, and Neeraj Prasad. The team also expresses gratitude to
the following individuals for their support in serving on the project’s Advisory Group: Rosina Bierbaum,
Nancy MacPherson, Heather McGray, Christine Roehrer, Christopher Nelson, Niels Holm-Nielsen, Holger
Kray, and Luis Andres.

This publication was prepared by Paula Silva Villanueva and Robbie Gregorowski (Resilience Monitor),
under the direction of Nathan Engle. Useful comments and edits were received from Anna Williams,
Calli VanderWilde, and Sundus Siddiqi. The team appreciates the peer reviewers that provided valuable
feedback, including World Bank’s Florence Kondylis, Anders Jensen, and Joseph Dickman. External peer
reviewers included Jon Kurtz, and Scott Chaplowe.

Finally, the team is deeply appreciative of funding from the Global Facility for Disaster Reduction and
Recovery, which has supported the ReM&E project and the drafting of this product.
iv                                     E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Glossary1



     Attribution: the ascription of a causal link between observed (or expected) changes and a specific
     intervention.

     Causal inference: the ability of evaluation designs and methods to demonstrate that an intervention
     causes an effect.

     Evaluation: the identification of causal effects related to a development intervention; the process of
     determining whether development investments lead to desired results, as well as other unanticipated
     (positive or negative) consequences.

     External validity: the degree to which the causal impact identified in an evaluation can be generalized
     to other situations. For an evaluation to be externally valid, it is necessary that the evaluation sample be a
     representative sample of all eligible units.

     Impact: the range of long-term effects (positive/negative, primary/secondary, direct/indirect, intended/
     unintended) produced by a development intervention.

     Indicators: quantitative or qualitative metrics that provide simple and reliable means to measure
     achievement, to reflect the changes connected to an intervention, and/or to help assess the performance
     of a development actor.

     Internal validity: the degree to which the causal impact estimates can be attributed to the development
     intervention as opposed to other phenomena; the evaluation uses a comparison group that is a valid
     estimate of the counterfactual.

     Intervention: an activity, project, program or policy that is intended to deliver development results.

     Monitoring: the continuous and systematic collection of data on specified indicators to track progress
     towards achievement objectives and use of allocated funds; used to inform management and
     stakeholders of the status of an on-going development intervention.

     Outcome: the likely or achieved short-term and medium-term effects of an intervention’s outputs; may be
     subdivided into immediate, intermediate, and final outcomes.

     Outputs: the products, capital goods, and services that are directly produced by an intervention; may
     also include intervention-related changes that are relevant to the achievement of outcomes.

     1	   Unless otherwise indicated, glossary terms are adopted from the Development Assistance Committee’s Glossary of Terms in Evaluation and Results-
     Based Management.
GLOSSARY                                                                                                        v




Resilience: the capacity of social, economic, and environmental systems to cope with a hazardous event
or trend or disturbance, responding or reorganizing in ways that maintain their essential function, identity,
and structure, while also maintaining the capacity for adaptation, learning, and transformation (IPCC
2014).

Results: the outputs, outcomes, and impacts (intended/unintended, positive/negative) of a development
intervention.

Results chain: the causal sequence for a development intervention that stipulates the necessary
sequence to achieve desired objectives beginning with inputs, moving through activities and outputs,
and culminating in outcomes and impacts. In some agencies, reach is part of the results chain. Defining
the results chain lays the groundwork for a results framework.

Results framework: the explicit articulation (graphic display, matrix, or summary) of the different levels,
or chains, of results expected from a particular intervention—project, program, or development strategy
(IEG 2012). A World Bank results framework has three main elements: (a) a statement of the project
development objectives (PDO); (b) a set of indicators to measure outcomes that are linked to the PDO
and a set of intermediate results to track progress toward achieving outcomes; and (c) M&E arrangements
specifying clear units of measurement for each indicator, baselines, annual and final targets for each
indicator, as well as the roles and responsibilities for collecting, reporting, and analyzing data on those
indicators (World Bank 2013).

Theory of Change: a description of how and why a development intervention is expected to deliver
desired results; details the causal flow of how and why changes will occur, as well as who must be
involved, who has interests at stake, and what steps must be followed for intended results to be reached
(Gertler et al. 2016).

Validity: the extent to which data collection strategies and instruments measure what they aim to
measure.
vi                          E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Acronyms and Abbreviations



     AoC	      Areas of Change                                             IFAD	              International Fund for Agricultural
                                                                                              Development
     BRACED	 Building Resilience and Adaptation to
             Climate Extremes and Disasters                                IPCC	              International Panel on Climate
                                                                                              Change
     CA	       Contribution Analysis
                                                                           M&E	               Monitoring and Evaluation
     CAPI	     Computer Assisted Personal
               Interviewing                                                MDC	               Mobile Data Collection

     CBA	      Community Based Approach                                    MRR	               Monitoring and Results Reporting

     DAC	      Development Assistance Committee                            ODK	               Open Data Kit

     DFID	     Department for International                                OECD	              Organisation for Economic
               Development                                                                    Co-operation and Development

     DiD	      Difference-in-Difference                                    PDO	               Program/Project Development
                                                                                              Objectives
     EQ	       Evaluation Question
                                                                           PRIME	             Pastoralist Areas Resilience
     ER	       Enhancing Resilience to Natural
                                                                                              Improvement through Market
               Disasters and the Effects of Climate
                                                                                              Expansion
               Change
                                                                           PROFOR	 Program of Forests
     ERG	      Evaluation Reference/Advisory/
               Consultation Group                                          RCT	               Randomized Control Trial

     FAO	      Food and Agriculture Organization                           ReM&E	             Results Monitoring and Evaluation for
                                                                                              Resilience-Building Operations
     FSIN	     Food Security Information Network
                                                                           RIMA	              Resilience Index Measurement and
     GIZ	      Deutsche Gesellschaft für
                                                                                              Analysis
               Internationale Zusammenarbeit
                                                                           ToC	               Theory of Change
     GP	       Global Practice
                                                                           ToR	               Terms of Reference
     HARITA	   Horn of Africa Risk Transfer for
               Adaptation                                                  TTL	               Task Team Leader

     ICF	      International Climate Fund                                  UNDP	              United Nations Development Program

     ICT	      Information and Communication                               USAID	             United States Agency for International
               Technology                                                                     Development

     IEG	      Independent Evaluation Group
Executive Summary




T
   o what extent are climate and disaster resilience-building projects/programs effective in achieving
   their objectives? How can projects/programs be improved in order to maximize impact and
   sustainability? Despite increasing attention on climate change and investment support for climate
and disaster resilience, answers to these questions are limited. With growing shares of resources, time,
and energy devoted to climate and disaster resilience-building projects/programs, additional evidence
demonstrating operational effectiveness is essential.

This document thus presents a five-step process to support World Bank Task Team Leaders (TTLs) in the
design of evaluations for resilience-building projects/programs. Steps are organized around key factors
TTLs should consider when planning, designing, implementing, and managing evaluations. Primarily
written for TTLs familiar with resilience-building, this document seeks to inform design and delivery of
relevant, robust, and useful evaluations.

While there is no standard approach to conducting an evaluation—each evaluation must be tailored to
the specific operational, geographic, socio-economic/institutional, and sector context of the project/
program, as well as the actors involved—there are general considerations that influence the success of
any evaluation. And these general considerations are the focus of this guide.

This document is not meant to serve as an all-encompassing or prescriptive manual for conducting
evaluations of climate and disaster resilience-building projects/programs. The purpose of this document
is rather to help TTLs know what to do differently when managing an evaluation for such interventions.
Although resilience-building can be very sector-specific, the document is not tailored to any specific area.
Rather, it draws on experience and insight from across a range of sectors of cross-cutting relevance. The
aim is that this guide should contribute to more coherent, robust, and useful evaluations of resilience-
building projects/programs regardless of the sector in question.




                                                                                                               1
2   E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R
Introduction




A
     s climate and disaster resilience-building projects/programs gain prominence as an approach for
     addressing climate and disaster risks, demand for empirical evidence on intervention effectiveness
     likewise grows. However, the nascence of resilience-focused evaluation (henceforth “resilience
evaluation”) leaves significant knowledge gaps in the field, and the methodological challenges
practitioners currently face impede their abilities to remedy such gaps. In order for practitioners to
holistically evaluate resilience-building projects/programs, and for institutions to expand upon the larger
body of resilience expertise, such challenges must be addressed.

This Operational Guidance Paper (henceforth “paper”) aims to provide the additional conceptual
and operational guidance support needed to improve evaluation design and delivery of World Bank
resilience-building projects/programs. The primary audience for the paper is World Bank Task Team
Leaders (TTLs) across different World Bank Global Practices (GPs)2 who do not consider themselves
technical evaluation experts, but who may be responsible for designing and implementing resilience
evaluations.

This paper is structured in two sections:
     •	 Setting the Stage: this section briefly highlights the importance of resilience evaluation and how it
        differs from ongoing internal self-evaluation efforts. The section also outlines the prerequisite steps to
        designing a resilience evaluation.
     •	 Step-by-Step Guide: the bulk of the paper is contained in this second section which presents a five-
        step evaluation design and delivery process. Each step considers both core evaluation considerations
        (e.g., those generic to any evaluation process), as well as key resilience-specific considerations.

This paper contributes to a larger effort by the World Bank—the “Results Monitoring and Evaluation for
Resilience-Building Operations” (ReM&E) project—to institutionalize and apply a systematic, robust, and
useful approach to monitoring and evaluation (M&E) for resilience-building projects/programs. This paper
focuses specifically on evaluation as opposed to the broader M&E concept. Guidance on designing an
M&E system, including results frameworks, results indicators, and monitoring and results reporting (MRR)
systems are currently being developed through complementary efforts.




2	     The World Bank’s 14 GPs include: Agriculture; Education; Energy and Extractives; Environment and Natural Resources; Finance and Markets;
Governance; Health, Nutrition, and Population; Macroeconomics & Fiscal Management; Poverty; Social Protection and Labor; Social, Urban, Rural, and
Resilience; Trade and Competiveness; Transport and Information and Communication Technologies; and Water.

                                                                                                                                                     3
4                            E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




    This paper should be read within the following confines:
     •	 It is not intended as in-depth technical guidance on evaluation methodology. Rather, it seeks to
        inform TTLs of good practices related to resilience evaluation, and to support TTLs as they navigate
        through the options at their disposal throughout evaluation design and delivery phases.
     •	 Resilience-building can be very sector-specific; however, this paper is not tailored to any particular
        theme. Rather, it draws on experience and insight from a range of cross-cutting areas to guide good
        practices in the area of “resilience.”
     •	 Although this paper draws on publically available literature, very little material on resilience evaluation
        has been produced to date. Formal evidence has therefore been combined with the authors’ tacit/
        experiential knowledge as well as information from interviews of World Bank operational teams.
     •	 The resilience-specific considerations and recommendations presented in this paper are intended to
        be instructive and discursive rather than definitive.
Section 1: Setting the Stage




Why evaluate resilience-building projects/programs?
Resilience is becoming a central focus of development interventions at cross-cutting levels—regions,
countries, provinces, cities, communities, households, and individuals—and among a range of cross-
cutting sectors/themes including: urban planning, food security, climate change adaptation, and disaster
risk management. Yet, knowledge regarding good practice on the design and delivery of resilience
evaluations is scarce. Differences stem from the lack of a common definition and understanding of
resilience as both a concept and a discipline, which in turn causes methodological challenges for
resilience evaluation in practice.

There is a clear demand for robust, coherent, and useful evaluations of resilience-building projects/
programs. Both during and after implementation of a resilience-building project/program, operational
teams as well as other stakeholders (including funders, policy makers, and beneficiaries) seek to
understand how the project/program is delivering on the expected results. Beyond accountability,
evaluations also play two critical roles, both of which are extremely important in the context of resilience:
(1) building evidence on what project/program components are (not) working, and (2) informing future
design and delivery of the project/program and others like it.



Building evidence and fostering learning on “what works” in resilience-
building projects/programs
As a rapidly changing-climate places increasing numbers of poor and vulnerable people at risk, the need
for resilience-building projects/programs heightens. However, evidence about what does (not) work
remains limited, driving a push for evaluation from policy makers, funders, researchers, and practitioners
who are interested in understanding why, and how, projects/programs succeed or fail. Such explanatory
analysis—that is, answering the “hows” and “whys” of project/program effectiveness—is central to the
evaluation of resilience-building projects/programs. By more explicitly focusing evaluations on generating
evidence and knowledge that informs decision-making, the World Bank can raise the value of its
evaluations (e.g., increasing the value of the benefits conferred to stakeholders relative to the cost of the
evaluation). The evaluative evidence generated on World Bank resilience-building projects/programs will
also further position staff within the GPs as leaders in designing and operationalizing resilience-building,
as well as build the confidence of task teams, donors, and clients in the ability of World Bank resilience-
building projects/programs to produce results.


                                                                                                                5
6                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




    Improving the design and delivery of projects/programs to enhance results
    and impact
    In addition to generating a broader body of evidence and learning on program/project effectiveness
    post-implementation, evaluations guide critical decision-making processes during project/program
    lifetime. The knowledge gleaned from evaluations can be used to improve the design and delivery of
    current project/programs—to provide “course corrections.” Lessons learned can be applied to future
    generations of projects/programs, increasing the chances of effectiveness and impact.

    In this paper, the authors emphasize evidence generation and learning as the primary focus of resilience
    evaluation; however, accountability and learning objectives should not be considered mutually exclusive.
    Project teams should be concerned with delivering the intended results of resilience-building projects/
    programs, as well as improving the design and delivery of future projects/programs through better
    understanding what does (not) work. This not only requires continuous engagement and collaboration
    with key stakeholders, but also innovative and qualitative evaluation designs that address the complex
    reality within which resilience-building projects/programs operate.

    Though interests may be spread across or even separate from project teams (e.g., when an independent
    evaluation is performed on the project, and not developed as a part of the project itself), this paper
    intends to reach teams of all forms.



        WHAT IS EVALUATION?

        For the purpose of this paper, evaluation is defined and framed as follows:

        “Evaluation is the process of determining whether development investments lead to desired results,
        identifying unanticipated consequences (positive or negative), and establishing intervention cause and
        effect.”

        Accountability through robust attribution is central to evaluation. At the same time, explanatory analysis,
        answering the “hows” and “whys” of program effectiveness, is central to program and policy learning. As
        development practitioners and policy-makers seek to replicate, generalize and scale-up projects/programs,
        they need to accumulate good practices to improve design and ensure future success.

        Key points concerning the definition and framing of “evaluation” adopted by this paper include:
         •	 Establishing robust causal inference, whether through experimental/counterfactual or generative/
            multiple causation, is central to evaluation; decisions inform the level of statistical rigidity of results.
         •	 The “value” of evaluation is that it can support accountability and learning imperatives, as well as
            improve the design and delivery of projects/programs to enhance results and impact.
         •	 The interactions between the attributes, context, and stakeholders involved in an intervention shape
            key evaluation questions (EQs) and available evaluation design options; attribution and contribution
            play a role in the evaluation of resilience-building interventions.
         •	 The inclusion of explanatory analysis in evaluation methods is relatively new.
         •	 Methods that support both causal inference and explanation are important.
S E C T I O N 1 : S E T T I N G T H E S TA G E                                                                                                     7




What makes resilience evaluation different?
While resilience-building projects/programs face many of same evaluation challenges as general
development projects (e.g., how to measure capacity, how to attribute results to a specific intervention
in isolation to contextual factors, etc.), they also face a number of new challenges.3 Added complexity is
due, in part, to the following:
     •	 Long time-frames: Building climate and disaster resilience is a long-term process that stretches far
        beyond the span of project/program management cycles. The real impact of these interventions may
        not be apparent for decades. How then are practitioners to define and measure achievements?
     •	 Contextual sensitivity and cross-scale interactions: Climate and disaster resilience must be
        grounded in the context, scale, sector, and nature of the endeavor—all of which vary widely—while
        the resilience of a system at any scale will strongly depend on the connections with the system at
        scales above and below. Multiplier effects, spill-overs, and demonstration effects may be difficult
        to identify and characterize ex ante. As such, impacts go beyond the intervention’s direct scope.
        Evaluation methods may be complex and costly to implement (e.g., impact on poverty or well-being
        indicators).
     •	 Uncertainty about actual climate change patterns: (including the frequency and intensity of
        extreme events, as well as their socio-economic impact) Although it is known that climate change will
        trigger more frequent and more severe shocks and stresses, the timing and consequences of such
        events remain unclear.
     •	 Shifting baseline data: Standard project/program evaluations track or compare results against
        baseline data. However, baseline comparison may be misleading since resilience-building
        interventions, by definition, take place in changing environments subject to evolving climate and
        disaster related hazards and risks.
     •	 The absence of a counterfactual: For interventions designed to address infrequent extreme events,
        comprehensive evaluation requires that the foreseen event occur. In the absence of such an event,
        the true impacts of a given intervention remain elusive. Interventions that address long-term risks
        from climate change, face the same challenges, as long-term climatic changes may not yet be evident
        at the time of project/program evaluation.
     •	 Inappropriateness of universal indicators for resilience: (given the context-specific nature of
        resilience) Evaluating resilience-building projects/programs can be difficult due to the cross-
        cutting nature of such operations. Resilience evaluation relies on specific context and on proxy
        measures, which may relate to the achievement of broader societal aims (e.g., well-being or human
        development). Indicators may also vary from simple measures, such as levels of education and
        average income, to more complex, intangible aspects including trust and leadership.
     •	 Contribution versus attribution: Evaluation efforts seek to demonstrate the extent to which
        changes can be attributed specifically to a particular endeavor. However, the causal linkages
        between an intervention and its effects can be difficult to determine, particularly when programs
        adopt an integrated approach to improving the resilience of policies, planning, and decision-making
        processes. Resilience-building operations are complex, and include fundamental uncertainties
        regarding causal relationships between inputs and outcomes.



3	    The summary provided builds on a series of 2013-2014 reports on M&E for climate change adaptation published by the SEA Change Community of
Practice and United Kingdom Climate Impacts Program (UKCIP).
8                                        E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




    These challenges make it necessary to fine-tune current evaluation approaches—especially with regards
    to performing baseline comparisons, developing indicators, and timing evaluation activities—to reflect
    the longer time horizon of the majority of resilience-building projects/programs.

    Resilience-building projects/programs are often designed for systems facing unpredictable trajectories,
    resulting in a need for expeditious feedback on operational performance. Real-time results monitoring
    and formative evaluation—particularly during ongoing shocks and stresses—can inform project/program
    modification while implementation in still underway. Thus, although this paper primarily focuses on final
    evaluations, the step-by-step guidance provided can also be applied to formative evaluations.

    The inherent complexity of “resilience” poses a unique set of challenges for resilience evaluation.
    Resilience must to be thought of in the context of “to what and for whom,” it must consider where
    capacity strengthening interventions provide people and/or systems with resilience, the extent to which
    resilience provides development gains, and how resilience reduces the impact of shocks and stresses on
    well-being.



    What informs the design of a resilience evaluation?
    The linkages between (1) EQs, (2) evaluation methods, and (3) resilience-building project/program
    attributes, shape and inform the selection of an appropriate evaluation design.4 Evaluation design needs
    to balance and align EQs with an appropriate range of evaluation methods, and the core attributes of
    a resilience-building project/program (Figure 1). “Attributes” relate to the specific features, contexts,
    locations, scales, and time horizons that define an intervention. This central logic, common to all
    evaluation designs irrespective of sector or theme, is considered good practice.

    It is important to note that resource availability and operational capacity are also key to appropriate
    evaluation design. These factors likewise will differ from project to project.


    FIGURE 1: Three core factors informing resilience evaluation design

                                                                            Evaluation
                                                                            questions




                                                                            Selecting
                                                                            Evaluation
                     Project/program                                         Design                                             Available
                         attribute                                                                                               designs




    Adapted from Stern et al., (2012).


    4	     For additional guidance on this subject, refer to Broadening the Range of Designs and Methods for Impact Evaluations [https://www.gov.uk/
    dfid-research-outputs/dfid-working-paper-38-broadening-the-range-of-designs-and-methods-for-impact-evaluations].
S E C T I O N 1 : S E T T I N G T H E S TA G E                                                                                                             9




Evaluation questions: EQs help to define the overall scope and focus of an evaluation by establishing
the purpose, audience, and intended results of the project/program. Defining a coherent, manageable,
and shared set of EQs early in the design and planning phase of an evaluation also facilitates the use of
data in collection, analysis, and reporting. The range of possible EQs for resilience-building operations is
explored in Step 1.

Range of evaluation designs: There is no single superior evaluation design and method; rather, different
evaluation designs and methods are best fit for different purposes. And while all have some weaknesses,
when well-executed, all have their strengths as well. The choice of overall evaluation design needs to
follow from the EQs being asked, while also taking into account the attributes of the resilience-building
project/program in question. The range of possible evaluation design options in the context of resilience-
building projects/programs is explored in more detail in Step 3.

Attributes of resilience-building projects and programs: World Bank resilience-building projects/
programs encompass a broad mix of sectors and GPs, and span diverse contexts, locations, scales, and
time horizons. These attributes in sum define the nature of a project/program and define the range
of evaluation designs that are technically and logistically feasible and appropriate. For example, an
experimental evaluation design based on randomized control trials would be inappropriate for a national
policy advocacy project spanning multiple countries because the project’s attributes make this approach
and design technically and logistically unfeasible. A non-exhaustive list of project/program attributes
relevant to the selection of evaluation design is discussed in Step 3.

These three central factors (EQs, evaluation methods, and resilience-building project/program attributes)
inform the structure of the step-by-step guidance presented in Section 2.



Prerequisite steps to a robust evaluation
Before engaging with the step-by-step guidance, a number of prerequisite steps should be considered.
Evaluations are most robust and useful when they are built into the design of a project/program from the
outset, and, in particular, when they can build on and utilize a project/program’s wider M&E efforts. This
is the case whether the evaluation is externally/ independently commissioned or commissioned under
an internal World Bank self-evaluation exercise.5 Therefore, projects/programs should adhere to the
following three prerequisite steps before commissioning an evaluation of World Bank resilience-building
projects/programs:

PREREQUISITE 1.	                 Define resilience according to context: Projects/programs are designed
                                 to address specific development needs or problems. It is difficult to know if
                                 projects have succeeded or failed in building resilience if the term in a particular
                                 development context is not clearly defined. The World Bank does not currently have
                                 a standard definition of resilience. This paper adopts the International Panel on
                                 Climate Change (IPCC) definition as a starting point (see Glossary).




5	    Self-evaluation is central to the World Bank result-management system. Yet, the type of evaluations required for knowledge generation and learning
about what works and what does not in strengthening resilience go beyond the scope of self-evaluation exercises (IEG 2016). Therefore, this paper focus-
es on voluntary evaluations that also respond to learning needs of management and teams.
10                                    E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Put simply, climate and disaster resilience is about the ability of individuals, households, communities,
     institutions or higher-level systems to deal with shocks and stressors without undermining their welfare
     or functions. It also captures the ability of such systems to improve and transform in spite of shocks and
     stresses. This leads to four foundational premises for any given project/program’s definition of resilience:
          1.	 It necessarily starts from a point of shocks and stresses that are based on a thorough analysis of the
            risks associated with the given contexts;
          2.	 It seeks to explain progress towards an anticipated outcome of interest despite such adversity;
          3.	 It is especially interested in the process of strengthening the abilities/capacities of systems from the
            household to institutional level to overcome such adversity; and
          4.	 It frames resilience as a “means to an end,” as an outcome required for achieving fundamental
            sustainable development goals such as income, health, and wellbeing (FSIN 2014).

     A clear definition of resilience should be a core component of a project/program’s design that informs
     the problem statement, and defines: to what the project/program is building resilience (e.g., floods,
     earthquakes, drought, etc.), to whom the project/program is providing resilience (e.g., households,
     communities, local government, a sector, a country, etc.), and through what activities and mechanisms the
     project/program is building resilience. The definition should also highlight what resilience outcomes the
     project/program is working towards—including what it seeks to help maintain in face of the previously
     identified shocks and stresses.

     Resilience is a unifying concept that enables multiple risks, shocks, and stresses along with their
     impacts on people, prosperity, and the planet to be considered together in the context of development
     programming. At the World Bank, this concept has the potential to resonate across, and thereby unify,
     different GP projects/programs. But, for this to be the case, coherent operational definitions of resilience
     must be integrated into resilience-building projects/programs from the outset.

     PREREQUISITE 2.	             Outline a resilience-building theory of change (ToC) and develop an
                                  appropriate results framework: Once it has a clear definition of resilience in place,
                                  a project/program should develop a results framework for its program/project
                                  development objective(s) (PDOs).6 The results framework should be specific to an
                                  intervention’s hierarchy of expected results, and should clearly articulate elements
                                  of logical cause-effect relationships between inputs, outputs, intermediate results/
                                  outcomes, and impacts (World Bank 2013).

     When developing the results framework, it is important to locate “resilience” at an appropriate level
     within a particular project/program’s results chain. The World Bank, like many other development
     institutions, conceptualizes resilience as an intermediate outcome of a project/program—that is, as a
     means rather than an end. However, the PDO should only express results that are within the control of the
     project/program and can be achieved within the project/program’s lifetime (IEG 2012; World Bank 2013).
     As resilience-building most often entails long-term endeavors and numerous interventions, World Bank
     task teams should generally consider increased resilience as a longer-term outcome beyond the control
     and lifetime of a single project/program.



     6	   For additional guidance on this subject, refer to Results Frameworks and M&E Guidance Note [siteresources.worldbank.org/PROJECTS/
     Resources/40940-1365611011935/Guidance_Note_Results_and_M&E.pdf] and Designing a Results Framework for Achieving Results: A How-to Guide [sit-
     eresources.worldbank.org/PROJECTS/Resources/40940-1365611011935/Guidance_Note_Results_and_M&E.pdf].
S E C T I O N 1 : S E T T I N G T H E S TA G E                                                                                                        11




A ToC is both a process and product. It generates a description of a sequence of events and how they
are expected to lead to a particular desired outcome. This description is captured in a diagram and
narrative that provides a guiding framework for a project/program’s stakeholders. According to Isabel
Vogel (2012), a leading ToC practitioner, “Theory of change starts from a baseline analysis of the context,
critical assumptions, and risks. It then maps out the logical sequence of changes that are anticipated as
being necessary amongst stakeholders and in the contextual conditions to support the desired long-term
change.” A coherent ToC explicitly defines the causal pathways through which change (e.g., increased
resilience) happens. The sequential narrative of a ToC is helpful for explaining ex ante how and why an
intervention is anticipated to deliver results.

Results frameworks develop a results-reporting system by translating the ToC into a set of appropriate
indicators for project/program specific outputs, outcomes, and impacts. For each indicator, the results
framework sets out data sources and reporting frequency. The eventually captured results are key to
regular progress monitoring and reporting, as well as evaluation.

The most robust starting point for an effective evaluation is a clearly defined and agreed-upon results
framework that has: (1) been informed by a ToC, and (2) identifies the desired resilience results and their
indicators.7

PREREQUISITE 3.	                 Decide whether to evaluate: The “value” in designing and delivering an
                                 evaluation should be clear from the outset. It is not always appropriate to conduct
                                 an evaluation—in many cases an evaluation will neither be feasible nor offer
                                 clear value.8 Evaluations can be costly in both time and resources, and evaluation
                                 budgets should be used strategically. There must be both a clear justification for
                                 the evaluation, how it will be used (generally accountability and learning), and the
                                 target audience for results sharing.

The following are examples where there may be clear justification and value in commissioning an
evaluation:
     •	 Innovative and/or untested projects/programs: testing innovative/new approaches or interventions
        for which there is a lack of robust evidence on results and impact in the given context;
     •	 Strategic projects/programs: flagship initiatives whose results can be used to inform key policy
        decisions; and
     •	 Replicable projects/programs: especially pilot programs which are due to be substantially scaled up
        or down, and/or projects/programs that have the potential to be expanded to different contexts.

Beyond the specific sample and setting in which the evaluation takes place, evaluation findings will
also have some relevance to broader contexts. Evidence on what works for whom, when, where, and
under which circumstances, can provide donors, clients, and implementing partners with evidence and
knowledge to more effectively design and manage future resilience-building projects/programs. Results
will also contribute to the on-going discussion on the design, delivery, and implementation of complex
resilience-building initiatives.




7	     Though this paper does not provide guidance on developing a resilience ToC or the associated results framework and indicators, complementary
efforts of the ReM&E project do provide such guidance. Teams are advised to refer these supporting materials.
8	     Refer to Annex 1 for a checklist for assessing whether a project/program can, and should be, evaluated.
12                            E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     It is important to highlight that even in the absence of a final evaluation, building in regular opportunities
     throughout a project/program for formative/mid-term evaluations can facilitate team and stakeholder
     participation, generate real time-learning, allow for course-correction during implementation, and
     increase the likelihood of meeting project objectives.

     The three-step process described above should be undertaken during the conceptualization and design
     of any project/program, enabling the integration of M&E at the earliest possible stages of the project
     cycle. Commissioning an evaluation without having explicitly followed these steps at the project/program
     concept and design phase is generally still feasible, but the evaluation will likely be less robust.

     The guidance provided in this paper assumes that the reader has already considered, and to a certain
     extent undertaken, the aforementioned prerequisite steps, as is necessary to meaningfully engage with
     the step-by-step guidance for the resilience evaluation that follows.
Section 2: Step-by-Step Guide




T
   his section provides a five-step guide to designing and managing a resilience evaluation in the form
   of a light-touch framework. The steps have been devised with the intention that a TTL would lead
   the process from Step 1 through to Step 4 to inform the scoping of an evaluation (see Figure 2). After
which, Terms of Reference (ToR) would be used to commission an evaluation specialist/consultant.
However, in certain circumstances, a TTL may want to work in partnership with a preferred evaluation
contractor beginning with Step 1.


FIGURE 2: Designing and delivering evaluations: 5 steps

                                                STEP 1
               Establish the purpose, scope, feasibility, and audience for the evaluation



                                                STEP 2
               Set evaluation decision-making, ethics, and communication requirements



                                                STEP 3
                        Select the appropriate evaluation approach and design



                                                STEP 4
                               Identify data collection methods and tools



                                                STEP 5
                Manage evaluation implementation; Share and promote use of findings




                                                                                                            13
14                             E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     At the beginning of each step, a brief summary (Main Messages) highlights key resilience-specific
     considerations and challenges. The details of each step are then provided among two sub-sections:
      •	 Core evaluation considerations: the generic, key evaluation concepts and questions that TTLs
         need to weigh when planning or managing the evaluation step in question. Within the framework,
         these considerations are not elaborated upon in detail as they are generic to robust evaluation best-
         practice, and thus have already been thoroughly reviewed.
      •	 Resilience-specific considerations and challenges: an introduction to the central issues relevant to
         designing and delivering a resilience evaluation. These sections aim to both highlight and explore
         what is unique or different for evaluation in the context of resilience-building.

     Each step concludes with a Further Reading box that provides links to relevant materials on both general
     evaluation resources and resilience-specific resources. All sources are available online and in the public
     domain.

                                              Establish the purpose, scope, feasibility,
               STEP 1                         and audience of your evaluation



         MAIN MESSAGES
          •	 The unique nature of resilience-building projects/programs requires that the evaluation criteria
             be tailored to the specific context of projects/programs. In addition to Organisation for Economic
             Co-operation and Development (OECD) Development Assistance Committee’s (DAC) criteria,
             connectedness, flexibility/adaptability, legitimacy, and equity should be considered.
          •	 EQs matter—questions should seek to explain what project/program elements did/did not work
             through evidence based-answers. Questions should be viewed as an opportunity to learn and inform
             the development of good-practices.




     Step 1 involves clearly defining the purpose, target audience, and feasibility of the evaluation at the
     project/program outset.

     A clear evaluation purpose serves as the                                     Core Evaluation Considerations
     basis for identifying the key EQs, design, and                               PURPOSE
     methods. Defining the purpose and objectives of                              •	 What is the primary purpose of the
     an evaluation is the most important planning step.                              evaluation?
     If the purpose is not clearly defined, it is unlikely                        •	 What are the key EQs?
     that the subsequent evaluation will be robust,
                                                                                  AUDIENCE
     coherent and/or useful. In this step:
                                                                                  •	 Who is the primary audience for the
      •	 TTLs along with the clients/stakeholders need
                                                                                     evaluation?
         to define the main purpose of the evaluation
         and main EQs. Evaluations can be carried out                             FEASIBILITY/EVALUABILITY
         for a range of reasons and it is important to be                         •	 Is the evaluation feasible in theory and
         clear about exactly why a specific evaluation is                            practice?
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                                               15




       being undertaken. Are clients/stakeholders interested in the impact of the project/program? How can
       the project/program be improved? Should the evaluation look at the whole project/program or only a
       specific component?
     •	 Establishing a set of key EQs will also help to define the overall scope and focus of the evaluation.
        Defining a coherent, manageable, and shared set of EQs early in the design and planning phase of an
        evaluation will make it easier to decide what data to collect and what methods to use, how to analyze
        the data, and how the evidence generated will be reported and shared.

The individuals or organizations that will employ the evaluation findings are the primary audience
of an evaluation. Identifying the audience and deciding the purposes of an evaluation go hand-in-hand.
These tasks should jointly inform decisions about evaluation priorities, scope, and focus. Incorporating
the concerns of clients/stakeholders into both the design of the evaluation and the selection of EQs
will facilitate the use of evaluation findings in decision-making. The best evaluations, regardless of type,
involve clients/stakeholders from the start. Resilience evaluation, like any other evaluation, should thus
entail proactive engagement between task teams and clients/stakeholders.

In addition to defining the evaluation’s purpose and rationale, it is necessary to assess evaluation
feasibility. Planning an evaluation involves trade-offs, and TTLs will have to weigh design feasibility (in
terms of time, money, and expertise) against the likely benefits to be derived. Most of the time, resource
availability will influence the choice of evaluation design, and/or limit the scope of the evaluation (the
number of questions, size of the sample, data collection, and analysis options).

         TTLs should lead discussions about evaluation feasibility. Discussions provide an excellent
         opportunity for TTLs to establish clients’/stakeholders’ agreement on the value of the
         evaluation and to determine the amount and type of resources necessary to support it. In
         some cases, engagement results in an expanded scope; the vision expressed by clients/
         stakeholders might require additional resources.

Annex 1 provides a checklist for assessing whether a project/program can, and should, be evaluated.



Resilience-specific considerations
Evaluation criteria should be tailored to the nature and context of resilience-building projects/
programs. OECD-DAC evaluation criteria, “Relevance, Effectiveness, Efficiency, Impact, and
Sustainability” provide a useful starting point for identifying and defining EQs—following these criteria
is the simplest way to ensure evaluation EQs are comprehensive. In the context of resilience-building
operations, “Relevance, Effectiveness, Efficiency, Impact, and Sustainability” must be tailored to the
resilience field. These evaluation criteria are interlinked and interdependent, and each sheds light on the
project/program in question from a slightly different evaluative perspective. When read together, the
criteria should inform the creation of key EQs.9 While TTLs should ideally aim to address all five criteria,
evaluations meant to address a specific learning purpose or mandate may instead focus in-depth on, and
develop specific EQs around, one or two criteria. Box 1 provides considerations for each of the criteria.



9	     A practical example of the application of the OECD DAC criteria in a resilience-building program can be found in the Evaluation Roadmap
of the EU approach to Building Resilience to withstand Food Crises in African Drylands 2007-2015 [ec.europa.eu/smart-regulation/roadmaps/
docs/2017_devco_007_building_resilience_to_withstand_food_crises_in_african_drylands_en.pdf].
16                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     BOX 1: OECD DAC EVALUATION CRITERIA TAILORED TO RESILIENCE-BUILDING
     PROJECTS/PROGRAMS10

                               The extent to which the activity is suited to the priorities and policies of the
            RELEVANCE
                               target group, recipient, and donor

     The relevance of the resilience-building project/program intervention might shift over time with changing
     climatic context and circumstances. Assessing risk, capacities, and vulnerabilities is key to evaluating relevance.
     If a risk and vulnerability analysis has already been carried out, its accuracy and use should be assessed.
     The following questions should be considered when evaluating the relevance of a resilience-building
     project/program:
           •	 Is the resilience-building project/program based on accurate (and up-to-date) analysis of risk and
              vulnerabilities? To what extent are the objectives of the project/program still valid?
           •	 Does the project/program address relevant causes of risk and vulnerability, key dynamics between the
              two, as well as their driving factors?
           •	 Are the stated goals and objectives relevant to the central issues of resilience-building? Are the
              activities and outputs of the project/program consistent with attaining the overall project objective(s)
              and goal(s)?
           •	 Are the activities and outputs of the project/program consistent with the intended impacts and effects?

       EFFECTIVENESS           A measure of the extent to which an activity attains its objectives

     The effectiveness of a project/program relates to its crucial outcome patterns, such as: coping/adaptive
     capacity (the capacity of the relevant stakeholders to cope with and reduce the risk posed from climate
     change); adaptive measures (from policy formulation to new farming and climate modeling techniques); and
     “mainstreaming” (among ministries, sectors, and stakeholders) among others.
     Evaluation against this criterion should therefore be relatively straightforward, providing that measurable
     objectives and indicators have been stated and clearly defined at the outset (a challenge further explored
     in Step 3). While effectiveness depends on resilience outcomes, it also depends on the resilience process,
     including capacity building, information exchange, policy formulation, and learning.
     Complications arise when evaluations are extended to examine the impact of resilience-building projects/
     programs on higher-level results such as poverty, health, etc. Care must be taken that achieving resilience
     objectives does not occur at the detriment of the population/system in question—for example, by
     exacerbating the level of poverty or creating a negative longer-term impact on vulnerability. All resilience-
     building evaluations should therefore include measures of the overall development impact the project/
     program expects to have addition to how well it has achieved project/program objectives (this is further
     explored in Step 3).
     The following questions should be considered when evaluating the effectiveness of a resilience-
     building project/program:
           •	 To what extent were the objectives achieved/ are likely to be achieved?
           •	 What were the major factors influencing the achievement or non-achievement of the objectives?

            EFFICIENCY         The outputs (qualitative and quantitative) in relation to the inputs.

     As an economic term, efficiency signifies that the activity uses the least costly resources possible in order to
     achieve the desired results. This generally requires comparing alternative approaches to achieving the same
     outputs, to see whether the most efficient process has been adopted.
     Resilience-building projects/programs involve deciding on acceptable levels of risk and vulnerability
     (defined to some extent by communities, policy-makers, and funders in a collaborative way) as potential
     trade-offs with the resource investments needed to reduce these risks (and thus increase resilience).
     10	    The adaptations made to the DAC Criteria are based on Evaluating Climate Change Adaptation from a Development Perspective
     [http://www.ids.ac.uk/publication/evaluating-climate-change-adaptation-from-a-development-perspective].
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                      17




      The following questions should be considered when evaluating the efficiency of a resilience-building
      project/program:
          •	 Were activities cost-efficient?
          •	 Were objectives achieved on time?
          •	 Was the program or the project delivered in the most efficient way compared to alternatives?

                                      The positive and negative changes—either direct or indirect, intended or
               IMPACT
                                      unintended—produced by a development program or project.

      This involves the main longer-term effects resulting from the activity on the local social, economic,
      environmental, and other development outcomes. The examination should be concerned with both
      intended and unintended results and must also include the positive and negative impact of external factors,
      such as changes in terms of trade and financial conditions.
      As mentioned above, considerations of impact are closely related and interlinked when considering the
      impact of a particular project/program. In the context of resilience-building projects/programs, the criterion
      should be used to identify and evaluate the overall development impact (as defined in the ToC) of a policy
      or program. This issue is further discussed in Step 4.
      The following questions should be considered when evaluating the impact of a resilience-building
      project/program:
          •	 What has happened as a result of the project/program?
          •	 How has the situation changed over time, and what changes can be attributed to intervention?
          •	 What real difference has the activity made to the beneficiaries?
          •	 Has the intervention led to policy changes? By whom? How do these policies relate to underlying
             vulnerabilities?

                                      The degree to which the benefits of an activity can be expected to continue
        SUSTAINABILITY
                                      after donor funding has been withdrawn.

      In the context of resilience outcomes, sustainability is concerned with looking beyond the immediately
      recognizable project/program impact(s). It seeks to understand the probability of interventions providing
      resilience to risk and other benefits over time. It also considers the broader environmental, social, and
      economic impacts associated with a project/program’s implementation.
      Thus, there is potential overlap between “Sustainability,” “Equity,” (which embodies social concerns), and
      “Efficiency” (which embodies economic concerns). Resilience-building activities that are more equitable
      and/or more efficient are more likely to be sustainable as well.
      The pursuit of sustainability provides an opportunity to prioritize investments that offer “win-win” solutions,
      or those investments that offer social, economic, and environmental benefits even in the absence of
      anticipated climate impacts.
      Sustainable resilience-building projects/programs are likely to include strong elements of partnership-
      building, and stakeholder engagement. They are likely to focus on interventions that integrate among
      existing development processes and mechanisms, and that cut across key sectors (such as water
      management, agriculture, health, and education).
      The following questions should be considered when evaluating the sustainability of a resilience-
      building project/program:
          •	 Which steps created long-term processes, structures, and/or institutions for resilience-building? How
             do they do so?
          •	 To what extent did the benefits of a project/program continue after donor funding ceased?
          •	 What were the major factors influencing the (non) achievement of project/program sustainability?
18                                   E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     In the context of resilience-building projects/programs, four additional criteria should be considered
     alongside those emphasized by OECD-DAC:
       •	 Connectedness: Connectedness refers to the need to ensure that activities are carried out in a
          context that takes longer-term and interconnected problems into account. Resilience-building relies
          on integrated programming—working across sectors with a long-term commitment to improve
          resilience capacities. To be successful, projects/programs should ensure that partners and sectors
          work together and adopt complementary, synergistic strategies that promote resilience (Fanknberger
          et al. 2016). Connectedness questions the extent to which different types of activities have been
          integrated and sequenced to address multidimensional challenges and the extent to which the
          project/program worked with key actors in the context within which it operates, so as to maximize
          long-term impact and transformative change.
       •	 Flexibility/adaptability: Flexibility/adaptability refers to the ability of a particular project/program to
          respond to unforeseen crises and unexpected events. Assessing flexibility questions how the project/
          program addressed uncertainty and unpredictability about climate shocks and stressors.
       •	 Legitimacy: Legitimacy refers to the active participation of project/program beneficiaries/
          stakeholders. During times of shock or stress, the actors within the system need to take advantage
          of the capacity and resources that a project/program has made available. Active participation of
          project/program beneficiaries/stakeholders is not unique to resilience interventions, but it is key to
          their success. Projects/programs that lack legitimacy have a lesser chance of full implementation.
          Legitimacy is best assessed by engaging with a comprehensive and representative range of project/
          program beneficiaries/stakeholders. EQs related to transparency, participation, and inclusion in
          decision-making processes should be raised in the context of legitimacy. For example:
           }} Did project/program beneficiaries/stakeholders support project/program activities?
           }} To what extent were beneficiaries/stakeholders consulted? To what extend did they participate in
              project/program design and implementation?
           }} Were beneficiaries/stakeholders informed of potential risks/negative consequences of the project/
              program activities?
       •	 Equity: Equity refers to the distribution of project/program benefits, costs, and risks amongst the
          population. Pro-equity interventions prioritize most vulnerable groups with the aim of achieving
          well-being for all (UNICEF 2011). Resilience-building projects/programs aim to reduce vulnerability
          in the context of climate change shocks and stresses, specifically. Vulnerability heavily depends on
          socioeconomic factors, however. This not only implies that different groups may have to be uniquely
          targeted, but also that the impacts of any given project/program may vary across groups. The World
          Bank Environmental and Social Framework supports this thinking (2014).11 The assessment of equity
          questions, includes for example:
           }} To what extent has an intervention targeted the most vulnerable groups?
           }} How have project/program activities (un)successfully avoided the (further) marginalization of such
              groups?
           }} Equity is important for instrumental reasons as well: projects/programs that are inequitable
              undermine the potential for welfare gains in the future (Brooks et al. 2011).




     11	  Refer to the World Bank Environmental and Social Framework [documents.worldbank.org/curated/en/311951468331802393/pdf/898130BR0CODE-
     200Box385287B00PUBLIC0.pdf].
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                   19




Explanatory and learning questions about how the project/program worked should be
included in evaluation. How and why did the project/program make a difference, if any?


      NOTE
      To provide effective learning opportunities, projects/programs need relevant objectives to be built into the
      designing, planning, and implementation stages of the evaluation. This requires thinking not only about
      introducing learning oriented questions, but also about making the following recommended “spaces”
      available for learning and feedback, both during, and after, the evaluation.



  •	 Which factors were necessary and/ or sufficient for the resilience-building project/program to work?
  •	 What was the process/ mechanism by which the project/program led or contributed to the resilience
     outcomes?
  •	 What difference did the project/program make (in terms of resilience) to different population groups,
     and under what circumstances?

These EQs focus primarily on explanation. They often focus on processes and intermediate outcomes,
and lend themselves to more qualitative and mixed-method designs including theory-based, case-based,
and participatory approaches. Such questions also attempt to address more recent concerns about
unanticipated outcomes that can require an “explanation” focus. Box 2 provides two illustrative examples
of explanatory- and learning-oriented EQs.




      BOX 2: EXAMPLES OF RESILIENCE-FOCUSED EXPLANATORY AND LEARNING EQS

      HARITA
      The impact evaluation associated with the HARITA (Horn of Africa Risk Transfer for Adaptation) project
      explores how the initiative impacts beneficiaries through specific causal pathways by asking (Oxfam 2015):
        •	 How does the project impact the agricultural decisions that farmers make and the outcomes of those
           decisions on their resilience and livelihoods?
        •	 Why do we observe certain impacts and not others, and why do impacts differ across types of farmers
           and conditions?

      PRIME
      The impact evaluation associated with the Ethiopia Pastoralist Areas Resilience Improvement and Market
      Expansion (PRIME) project questions the underlying processes for resilience by asking (Baseline Survey
      Report January 2015):
        •	 Which project’s interventions strengthen the ability of vulnerable households to withstand and recover
           from stressors and shocks affecting their economic activities? In what ways?
20                              E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




         FURTHER READING
         General evaluation resources:
         Manage an Evaluation or Evaluation System [documents.worldbank.org/curated/en/311951468331802393/
            pdf/898130BR0CODE200Box385287B00PUBLIC0.pdf]

         How to Design and Manage Equity-Focused Evaluations [evalpartners.org/sites/default/files/EWP5_Equity_
            focused_evaluations.pdf]

         Evaluating the Sustainable Development Goals: With a “No One Left Behind” Lens through Equity-Focused and
             Gender-Responsive Evaluations [www.evalpartners.org/sites/default/files/documents/evalgender/Eval-SDGs-
             WEB.pdf]


         Resilience-specific resources:
         DFID BRACED Knowledge Manager Evaluation Plan [http://www.braced.org/
            resources/i/?id=8adc8698-39fa-4bf7-9de7-3f2fedec7f3f%20]




                                               Set up the evaluation decision-making, quality
              STEP 2                           standards, and communication requirements


         MAIN MESSAGES
          •	 The concept of resilience adds value as it cuts across sectors and GPs. Knowledge sharing across GPs
             is essential to improving resilience practice, making internal knowledge management a key activity and
             output of evaluation.
          •	 By design, resilience evaluations occur over a time horizon of several years and require multiple
             interactions with beneficiaries and stakeholders. Key stakeholders should be engaged in the evaluation
             processes from the start.



     Step 2 involves formal evaluation planning
     activities, the first of which should include defining
                                                                                   Core Evaluation Considerations
     decision-making, ethics, and communication                                    DECISION-MAKING AND MANAGEMENT
     practices. Because evaluations require careful                                •	 Who will be responsible for making
     planning, they should be managed as a discrete                                   decisions? For assuring effective
     part of the larger project/program. Evaluations                                  management? For monitoring quality?
     also require qualified personnel, a clear                                     QUALITY STANDARDS
     organizational structure, and defined tasks..                                 •	 How will quality standards be defined and
                                                                                      managed?
     A variety of decisions must be made during                                    •	 How will ethical concerns be defined and
     evaluation design, including: what the focus                                     addressed?
     of the evaluation will be; who will undertake
                                                                                   COMMUNICATIONS
     the evaluation; how data will be collected and
                                                                                   •	 How will evaluation findings be
     analyzed; how the evaluation will be reported;
                                                                                      communicated?
     and who will have access to the final report. It is
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                                                       21




important to clearly define who will be involved in making these decisions, what their role will be, and
how decisions will be made. Therefore, in this step:

TTLs and the client need to jointly establish processes for stakeholder consultation and decision-
making with regards to evaluation design and management. A variety of advisory groups may be
integrated with the evaluation so as to incorporate a wider range of perspective and expertise, and
to foster greater ownership of the evaluation process by key stakeholders. Important structures and
processes may include:
  •	 Evaluation management team: Evaluation management often involves a designated management
     team whose responsibilities include: selecting and supervising the work of externally contracted
     evaluators (from revising the inception report to editing drafts of the final report; providing technical
     guidance to the evaluators; and managing operational aspects of the evaluation, such as budget,
     field visits, and stakeholder contact). The management team should be composed of key task team
     members with the technical expertise to undertake an evaluation (e.g., M&E specialists, climate
     change specialists, sector specialists, economists, etc.).
  •	 Evaluation reference/advisory/consultation group (ERG): This group provides technical guidance
     and advice on evaluations without making any actual decisions. This may include providing input on
     EQs and the relevance of results. Members of this group may include external experts, experienced
     evaluators, and stakeholders who possess relevant knowledge (for example, knowledge about the
     policy context of the project/program). An ERG is normally formed by experts that are not part of
     the task team. Given that advisory groups take time to organize and manage, TTLs should consider
     whether the project will benefit from an ERG instead of immediately seeking direct consultation from
     targeted experts.
  •	 Fundamental principles of established evaluation practice should be applied: Evaluation team
     independence, participation, transparency, and inclusiveness are particularly important evaluation
     principles.12
  •	 Important ethical issues must be considered: Ethical considerations are relevant for any type of
     evaluation, but are especially important in the context of experimental and/or quasi-experimental
     designs which tend to target specific groups of individuals and communities. For example, in an
     agriculturally-focused resilience project that provides farmers with weather resistant seeds, concerns
     may arise with respect to seed distribution. Some farmers receive the seeds (treatment group), while
     others do not (the control), yet given the opportunity, all would likely benefit.13
  •	 Communication and evidence/knowledge sharing from World Bank resilience work should be
     central to TTL roles: Documented evidence and learning are essential to improving policy and
     practice. The application of evaluation findings often depends on how well the report material is
     communicated. A clear strategy for communicating the results of an evaluation should be in place.
     The plan needs to describe which results will be communicated, how they will be communicated,
     and to whom they will be communicated. Outside of an evaluation report, findings can also be
     shared via other publications such as policy briefs or newsletters, as well as through round-table
     discussion/presentations among operational task teams and key stakeholders. The targeted
     audience and available budget should inform a team’s choice of media. Where possible, TTLs


12	    For additional guidance on this subject, refer to How to Guide for Managers and Commissioners of an Evaluation [https://ieg.worldbankgroup.org/
Data/reports/ecd_man_evals.pdf].
13	    For additional guidance on this subject, refer to Managing Evaluations: A How-To Guide For Managers and Commissioners of Evaluations (Chapter
3) [https://ieg.worldbankgroup.org/Data/reports/ecd_man_evals.pdf] and Ethical Guidelines for Evaluation [http://www.unevaluation.org/document/
detail/102].
22                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




         should also consider communicating real-time findings prior the written report. This supports
         immediate uptake and use of findings. Step 5 provides further information on presenting and
         sharing findings and lessons.



     Resilience-specific considerations
     As mentioned previously, resilience evaluations require a built-in learning component. In practice, this
     means that to the greatest extent possible, TTLs should:
      1.	 Involve key stakeholders in the evaluation process and share learning from the beginning.
         Involving beneficiaries and stakeholders in shared-learning processes and integrating their
         involvement into evaluation structures and processes from the outset, is particularly important
         for resilience-building projects/programs given their broad time horizons. In practice, this means
         ensuring that stakeholders who contribute data or evidence to the evaluation are involved in shaping
         the evaluation’s findings, conclusions, and recommendations. It also means that evidence generated
         through an evaluation should be relevant to all contributing parties. For example, lessons and
         recommendations should be tailored to benefit implementation teams (informing course correction
         and enhanced design), as well as the primary client. Finally, particular care should be taken under
         Step 2 in terms of evaluation governance, ethics, and management to ensure that the data and
         evidence generated under the evaluation is not perceived as “extractive” by stakeholders.
      2.	 Establish internal learning mechanisms. In addition to engaging primary stakeholders in learning
         processes, TTLs should, as far as possible, foster internal learning to improve practice within the
         World Bank. The concept of resilience adds value as it cuts across sectors and GPs, and knowledge
         sharing across GPs is essential to improving resilience-building practice. It is through establishing
         internal (within the World Bank) and external (with counterpart institutions, as well as stakeholders
         and beneficiaries) mechanisms from the start that learning and improvement of resilience-building
         projects/programs can be secured and sustained, thereby supporting further buy-in and investment.
         TTLs should plan for internal knowledge management and shared learning processes as a key activity
         and evaluation outcome. This means:
         •	 Considering the knowledge demands the evaluation places on GPs from the outset.
         •	 Tailoring the final knowledge products to provide insight to a TTL’s respective GP, other GPs, and
            larger World Bank units. In practice, this might mean that TTLs produce a small set of tailored
            supplementary products in addition to the final evaluation report. These could include:
           }} A webinar for relevant regional teams, country teams, and/or implementing partners that
              provides feedback on what their data and inputs generated in terms of findings and lessons.
           }} A brief public domain summary document to share with other World Bank GPs working on
              resilience as well as wider partner institutions also investing in resilience-building.




         FURTHER READING
         General evaluation resources:
         Evaluation Ethics, Politics, Standards, and Guiding Principles [dmeforpeace.org/sites/default/files/M14_NA.pdf]
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                       23




                                                     Select the appropriate evaluation
               STEP 3                                design and method


      MAIN MESSAGES
        •	 One design does not fit all: the selection of evaluation designs should be tailored to the core attributes
           of the resilience-building project/program. Causation and attribution is unlikely to be clear, simple,
           or linear. Resilience-building is a complex process with fundamental uncertainties about the causal
           relationships in the change process. Evaluation designs should take a “complex systems” perspective
           and situate the project/program to be evaluated within its wider context.
        •	 From the perspective of adaptive learning, experimental and quasi-experimental designs may be less
           well-suited to respond to the complex conditions under which resilience-building projects/programs
           operate. TTLs should focus on which types of complementary or alternative designs are best suited to
           a given project/program’s contextual reality.
        •	 Resilience-building is only proven in the face of shocks and stresses. If such an event does not occur,
           it may be difficult to determine if the project/program has accomplished its expected outcomes and
           impact. Having a well-articulated ToC can help to accommodate more qualitative based approaches
           that do not necessarily depend on shocks and stresses to manifest.
        •	 Evidence of resilience-building takes time. Evaluations commissioned to report during, or immediately
           after, a project/program should recognize that the scope of results will be limited



Step 3 involves defining and selecting an overall
evaluation design appropriate for meeting the                          Core Evaluation Considerations
goals and objectives of the evaluation. It returns to
                                                                       OVERALL DESIGN
core concepts introduced in the previous section
                                                                       •	 Which design is most appropriate to
entitled, “What informs the design of a resilience
                                                                          address the EQs?
evaluation?” (see Section 1): balance and align EQs
with project/program attributes in order to define                        }} Experimental design.
and select an appropriate evaluation design.                              }} Quasi-experimental design.
                                                                          }} Qualitative design including theory-
A wide range of evaluation designs exist and                                 based, participatory, a nd case study-
there is no single superior evaluation design for                            based approaches.
producing evidence. Each evaluation design best
                                                                       UNDERSTANDING PROJECT/PROGRAM
fits a different purpose. While all have some short-                   ATTRIBUTES
comings, when well-executed all have important                          •	 Which evaluation designs are likely to be
strengths.                                                                 technically and logistically feasible given
                                                                           the project/program attributes?
The purpose of this section is to briefly introduce
TTLs to a selection of key evaluation designs and
methods. It is not a comprehensive review of evaluation design and methods. Regardless of the level
of expertise, as TTLs plan for evaluation it may be useful to involve an expert with advanced training in
evaluation design and methods.

A generic overview of the range of appropriate evaluation designs is presented in the Table 1 along
with a headline analysis of perceived advantages and disadvantages. To reiterate, the choice of overall
24                             E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     evaluation design needs to follow from the kinds of EQs posited, the attributes of resilience-building
     project/program (including the available resources/expertise available to implement the evaluation), and
     the context in which the project/program is situated.

     TABLE 1: The broad range of evaluation designs

                                   QUANTITATIVE APPROACHES – focus on attribution
         Design                                           Basis for causal
                           Description                                                         Advantages                       Disadvantages
        approach                                            inference
      Experimental    Compares                       Counterfactuals; the               Causal relationships               Limited
      Designs         intervention with non-         co-presence of cause               between variables can              external validity
                      intervention area              and effects                        be established                     (generalizability) due
                      Uses controls that are         Robust estimate of                                                    to the controlled
                      randomly assigned              the counterfactual                                                    experimental
                                                                                                                           environment
                                                     Less suitable for more
                                                     complex, long-term                                                    Ethical concerns by
                                                     interventions, where                                                  denying/delaying
                                                     many factors seek to                                                  the benefits for the
                                                     produce change                                                        intervention to a
                                                                                                                           control group
                                                                                                                           Resource intensive

      Quasi-          Compares                       Counterfactuals; the               Enables                            Does not control for
      experimental    intervention with non-         co-presence of cause               experimentation when               extraneous variables
      Designs         intervention area              and effects                        random assignment is               that may influence
                      Uses controls or                                                  not possible                       findings
                      comparison groups                                                 Avoids ethical issues
                      that are not randomly                                             caused by random
                      assigned                                                          assignment


                            QUALITATIVE APPROACHES – focus on contribution and learning
         Design                                           Basis for causal
                           Description                                                         Advantages                       Disadvantages
        approach                                            inference
      Theory-based    Uses TOC to draw               Identification/                    Can often be                       Does not provide
                      conclusions about              confirmation of causal             undertaken in                      a quantitative
                      whether and how                processes or ‘chains’              circumstances where                measure of the size of
                      an intervention                Supporting factors                 other approaches                   attribution
                      contributed to                 and mechanisms at                  (e.g., experimental
                      observed results.              work in context                    designs) cannot be
                                                                                        used
      Cased-based     Analysis of a particular       Comparison across
      approaches      unit or instance               and within cases
                                                                                        Allows conclusions
                      obtained through               of combinations of
                                                                                        to be drawn on the
                      extensive description          causal factors
                                                                                        relative cause-effect
                      and analysis                   Analytic                           elements of an
                                                     generalization based               intervention.
                                                     on theory

      Participatory   Involves stakeholders          Validation by                      Enables evaluators to
      approaches      of a project/program           participants that                  arrive at findings on
                      in all the stages of the       their actions and                  why interventions are
                      evaluation process.            experienced effects                working or are not
                                                     are ‘caused’ by                    working in particular
                                                     program                            contexts
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                            25




Considerable further reading on the underlying rationale and nature of each presented evaluation design
is available within the public domain. For the purposes of this paper, two points are worth noting:
  1.	 Methodologically, there are key differences between these designs. As a general rule, experimental
      and quasi-experimental designs focus on establishing and quantifying results through linear cause
      and effect (direct attribution) with the use of a counterfactual. In contrast, qualitative designs tend to
      focus more on explanation, make generalizations based on program theory/logic, and confirm results
      through causal processes or chains. Methods that focus on linear cause and effect are generally not
      well-suited to resilience evaluation as resilience is premised on complex systems thinking, numerous
      interdependencies, and uncertain causal linkages between activities and actual results.
  2.	 Different design options are not mutually exclusive. As of late, mixed-method approaches (evaluation
      designs that combine quantitative and qualitative methods to support both robust causal inference
      and explanation) are gaining favor. In the context of World Bank resilience-building projects/
      programs, evaluation designs are likely to be required to robustly answer both quantitative and
      qualitative questions.

The core attributes of a given projects/programs. While it is almost impossible to provide generic
guidance on which types of resilience-building projects/programs are suited to which evaluation designs,
it is possible to provide a non-exhaustive “list” of which project/program attributes align well with which
evaluation designs. The attributes and questions explored in Table 2 correspond to the contexts and
challenges encountered by most resilience-building projects/programs. As such, the list should resonate
with TTLs exploring the particular attributes of a resilience-building project/program irrespective of
sector/theme. Assessing key project/program attributes is a natural starting point from which to develop
EQs and determine available and feasible evaluation designs.

TABLE 2: A checklist for defining the key attributes of resilience-building projects/programs

                                                                                                          Project/program-
                           Resilience-building project/program attributes checklist
                                                                                                           specific details
                              Attribute 1 - Nature and focus of the World Bank resilience interventions

 What intervention is the project/program delivering?
     •	 What sector(s) is the project/program focused on?
     •	 Is the project/program defined by a single or package of interventions?
     •	 Is the project/program defined by a complex set of interventions?

                                                         Attribute 2 - Scale

 Over what scale is the project/program being delivered?
     •	 In what geographic locations is the project/program being implemented?
     •	 At which conceptual scale(s) does the project/program focus? What is the primary unit
        of intervention and measurement: individual, household, community, province/ state
        regional, national, multi-national?

                                                       Attribute 3 - Duration

 How long is the project/program timeframe?
     •	 Are evidence/results from resilience-building expected during this project/program life-
        cycle? What is the anticipated nature of these results?
     •	 Are significant results likely to be delivered after the end of the project/program?
26                              E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




                                                                                                                                  Project/program-
                       Resilience-building project/program attributes checklist
                                                                                                                                   specific details
                             Attribute 4 – Nature, focus and accessibility of the stakeholders

     Are the beneficiaries and wider stakeholders clearly defined?
       •	 Is the project/program targeting a clearly defined set of direct beneficiaries?
       •	 How accessible are the projects/program respondents? What are the geographic
          areas evaluators must reach? (e.g., conflict settings or very rural areas may have low
          accessibility)
       •	 Do the results of the project/program depend on working alongside a wider set of
          indirect beneficiaries and stakeholders?

                                                       Attribute 5 - Wider context

     What are the key contextual factors that may influence the project/program?
       •	 Is it possible to assess the (potential) impact of (climatic) shocks and stresses?
       •	 Are the wider contextual factors (political, economic, environmental, social, etc.) and
          their potential impact(s) (positive or negative) on the project/program clearly defined
          and understood?
       •	 What other external factors/actors can affect evaluation of the resilience intervention?
          (e.g., a disease outbreak, civil unrest, other implementing organizations that can affect
          the evaluators’ ability to collect data, and/or analyze attribution of certain measured
          changes to the project/program, etc.)

                        Attribute 6 - Level of the investment relative to the scale of the challenge

     To what extent does the investment in the project/program address the nature of the
     challenge?
       •	 What results are realistic given the scale of investment in the project/program?
       •	 Is the project/program likely to make a contribution to addressing a larger development
          challenge?
       •	 Outside of the project/program, which other actors/institutions are also playing a role in
          addressing the challenge?

                           Attribute 7 - Nature of the project/program and evaluation audience

     What evidence and new knowledge are funders/wider audiences of the project/program
     expecting to gather from the evaluation?
       •	 Are the funders the primary audience for the evaluation?
       •	 Are the funders more interested in evaluative evidence for accountability, learning, or
          both?

                                            Attribute 8 - Practical and logistical factors

     What are the key practical and logistical factors that define the project/program?
       •	 What level of resourcing is available for the evaluation in terms of funding?
       •	 How much time do evaluation and project/program team members have available for
          the project/program?
       •	 Are there wider practical and logistical factors that may influence the evaluation (e.g.,
          issues of seasonality, access to project/program sites, political sensitivities, etc.)?
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                               27




Resilience-specific considerations
The previous section looks at the general considerations involved in selecting an appropriate evaluation
design and how these may be approached in designing the evaluation of a resilience-building project/
program. Key characteristics of resilience/resilience-building projects/programs necessitate that TTLs
pay special attention when selecting an appropriate evaluation design for such interventions—resilience-
building is in essence a complex process, it takes time to identify evidence of resilience results, and
resilience-building can only be proven successful if resilience is witnessed in the face of a shock or stress.

Understand that resilience-building is a complex process. Successful resilience-building is
multifaceted, and takes place in complex environments with fundamental uncertainties about the causal
relationships amongst change processes. Evaluation specific that seek to demonstrate the extent to which
changes can be directly attributed to a particular activity are faced with a unique set of challenges that
should not be underestimated, as the causal linkages between an intervention and change in a complex
context can be very difficult to determine (Levine 2014). This is particularly the case when projects and
programs take an integrated approach to resilience-building through delivering different “packages”
of interventions to various beneficiary or stakeholder groups, and/or when projects/programs aim to
improve policies, or planning and decision-making processes. In these cases, results typically depend on
a complex interaction factors, many of which are not under the control of the project/program.

Given this complexity, evaluation designs should take a “complex systems” perspective, situating the
project/program in question within its wider context. Causation is unlikely to be clear, simple, or linear.
Rather, observed results are likely to stem from multiple, unpredictable interactions and feedback loops—
many of which may come from factors outside of the project/program. Those designing evaluations
need to be cognizant of such issues when considering which evaluation designs are technically and
logistically feasible. For example, experimental designs are unlikely to be technically feasible for
assessing large scale (e.g., regional and national policy-influencing) projects/programs which involve
multiple actors, complex interactions, and feedback loops. Experimental design is also inappropriate
given that the project/program is intended to contribute to a higher, system-level change process.
Similarly, a complicated resilience-building project/program that delivers various different “packages”
of interventions to different groups of beneficiaries at different times and locations will likely struggle
to support an experimental design. However, it may be feasible to evaluate a particular “package”
in a particular context using experimental design since it will be much easier to select robust control/
comparison groups.

Experimental or quasi-experimental designs are likely the least well-suited for these kinds of
interventions. Alternative or complementary designs are rather best suited to the contextual reality of
resilience-building projects/programs. The emerging field of work on complex systems is relevant to
resilience-building and should be consulted to help frame and inform evaluation designs (see “Further
Reading” at the end of Step 3).


Be realistic and pragmatic about results—evidence of resilience strengthening can take
time

Over short timescales, resilience-building projects/programs are unlikely to generate evidence at
the outcome and impact level in terms of sustainable improvements in the resilience of individuals,
28                                    E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     households, communities, and populations to shocks and stresses. A frequently encountered problem
     is the apparent mismatch between the relatively short timescale associated with resilience-building
     projects/programs (frequently from two to five years) and the timescales over which it is reasonable to
     expect to see evidence of improvements in resilience at the outcome and impact level. This is further
     complicated by the unpredictable onset, frequency, and duration of climatic stresses.

     In practice, the length of the project/program determines the relevance of this challenge—e.g., if the
     project/program is seven years long, it may be possible to measure higher-level results during the final
     evaluation. For shorter programs, evaluations commissioned at the end of a project/program’s lifetime
     will likely only be able to gather evidence on and assess lower-order resilience-building activities, outputs,
     and processes. More meaningful assessment of resilience-building outcomes, impact, and sustainability
     requires a longer timescale.

     Figure 3 demonstrates a generic ToC for resilience-building. Teams should identify a realistic estimate of
     how far a given project/program will take them along a ToC pathway toward increased resilience. This will
     inform the degree to which resilience can be meaningfully assessed.


     FIGURE 3: Generic theory of change of a resilience project/program


             Activities
           implemented


                                            Resilience capacity
                                              strengthened


                                                                                     Effective resilience
                                                                                     response adopted

                                                                                                                                National/sub-national,
                                                                                                                                individual, household
                                                                                                                                 wellbeing improved
                                                                                                                                   (or maintained)

     Adapted from Béné et al. 2017.




     If an evaluation is intended to report on “higher-order” resilience results (those associated with resilience
     at the outcome and impact level) then evaluation design should include running at least one final round
     of data collection significantly after project/program closure. This may be framed as a formalized ex-post
     evaluation, but at the very least it involves a round of data collection and final reporting that is “ex-post.”
     The precise timing afterward is difficult to define but should be generated from the project/program’s
     ToC, collective assumptions about the chronology of anticipated results, and when those events can
     reasonably be expected.

     These designs will be costlier and may entail some logistical challenges, such as engaging with key
     project/program team members etc., who will likely have dispersed and therefore be unavailable to
     participate in the evaluation. In addition, TTLs may struggle to identify mechanisms to finance and
     account for the evaluation given that the project/program budget has already closed. However, ex-post
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                                                        29




evaluation is not unprecedented—under the Program of Forests (PROFOR), the concept of predictive
proxy indicators (due to long-term time horizons) has been applied to forestry. Such indicators enable the
program to track and assess the impacts of forest-related investments over time.14

In the absence of ex-post evaluation, it will be difficult to determine if the project/program has
accomplished its expected resilience-strengthening outcomes and impact. "TTLs should address two
fundamental implications for evaluation approaches and designs related to this issue of “maturation of
effect:”
  1.	 Evaluation approaches and designs should be based on pragmatic and realistic expectations of
      the nature and level of the anticipated results within the project’s/program’s overall implementation
      time. Evaluations commissioned during or immediately after a project/program should recognize
      that the scope will be limited to the results achieved within the operational timeframe (as opposed
      to its “economic lifetime,” etc.). This may not reflect the resilience-building benefits of the project/
      program. In addition, all evaluations should recognize their methodological limitations, including
      limitations related to measuring longer-term results that are expected to mature after project/
      program closure.
  2.	 Evaluations aiming to assess resilience-building with respect to longer-term outcomes and impact-
      level results are likely to require approaches and designs that rely on rounds of data collection that
      continue beyond the project/program timeframe (possibly on the scale of 5-10 years). The impacts
      of resilience-building projects/programs are largely dependent on how deliverables are used after
      project/program completion. It may take some time before benefits or the impact of outcomes on
      the wider context of project/program are realized. Therefore, it is suggested that, when possible and
      feasible, resilience outcomes should be measured beyond project completion.

Genuine resilience-building is only proven in the face of shocks and stresses

Because of the “latent” nature of resilience, it is only possible to definitively know if a project/program
has built resilience to climate shocks and stresses if beneficiaries are observed to have strengthened
resilience in the face of shocks and stresses that actually occur. For example, an evaluation of a village-
level flood defense construction project will only definitively demonstrate improved resilience if
households in both treatment and control villages are surveyed before and after a similar flood event.
Among other things, resilient households will have the ability to maintain assets and health status when
faced with the flood. If such a shock or stress event does not occur, it may be difficult to determine if
the project/program has accomplished its expected resilience-strengthening outcomes and impact.
Though not as robust a method, a well-articulated ToC can help to provide more qualitative approaches
to assessment that do not necessarily depend on the occurrence of shocks and stresses. TTLs should
recognize that in these cases, the “learning” purposes of the evaluation might be compromised.

It is important to acknowledge some of the inherent limitations for assessing resilience-building projects/
programs. This not only includes challenges related to timeframes or the absence of shock/stress events,
but also the inherent complexity of operational contexts—which can challenge causal analysis and the
validity of counterfactuals (attribution). Examples akin to those provided by Béné et al. (2017) in Squaring
the Circle provide a better understanding of how ongoing evaluation efforts are addressing such
challenges in practice.


14	   For additional guidance on this subject, refer to Understanding Long-Term Impacts in the Forest Sector: Predictive Proxy Indicators [https://www.
profor.info/content/understanding-long-term-impacts-forest-sector-predictive-proxy-indicators].
30                            E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Identify and define the most appropriate and feasible evaluation design

     Table 3 brings all the discussions under Step 3 together in three hypothetical project examples, that
     respectively illustrate the three broad evaluation designs (experimental, quasi-experimental, and
     qualitative/mixed-method) previously introduced. Each example presents a combination of attributes and
     EQs that intentionally bias the selection of a particular evaluation design. The cases are not intended to
     be definitive but rather to introduce readers to possible design selections that balance project/program
     attributes and EQ selection. The examples are based on three broad intervention types:
      •	 Project 1 – a village-level flood defense/flood drainage construction project illustrative of a
         straightforward, single-point intervention project/program that supports an experimental evaluation
         design;
      •	 Project 2 – a climate resilient, pro-poor livelihoods diversification program illustrative of a multi-
         intervention resilience strengthening program that supports a quasi-experimental evaluation design;
         and
      •	 Project 3 – a national adaptive social protection policy formulation program illustrative of a large-
         scale complex policy process that supports a qualitative/mixed-method evaluation design.
TABLE 3: Exploring relevant questions, designs, and methods for different resilience-building projects/programs

            Factor 1                                                     Factor 2                Factor 3
                                                                                                                             POTENTIAL METHODS                              NOTES
      DEFINING ATTRIBUTES*                                             HEADLINE EQs         AVAILABLE DESIGNS

                                                             Example project 1 – A village-level flood defense / flood drainage construction project

    •	 Attribute 1 - Nature and       •	 EQs based on determining                       •	 Experimental design           •	 Randomized Control Trial            •	 Evaluation design will need
       focus of the interventions        if the flood defense / flood                      deemed feasible and              (RCT) through household                to consider evaluation
       – single intervention;            drainage construction                             appropriate as project           surveys at baseline and                ethics when control groups
       delivered at a single village-    project has had an impact,                        attributes suggest               endline in treatment and               are denied the potential
       level location with a well-       and quantifying how large                         a narrowly defined               control households and                 benefits of an intervention.
                                                                                                                                                                                                  S E C T I O N 2 : S T E P - B Y- S T E P G U I D E




       defined set of household          that impact is.                                   intervention with clear and      villages defined and selected    •	 Control groups will need
       beneficiaries                  •	 Headline EQ – To what                             linear cause and effect          by proximity to the flood           to be based on some clear
    •	 Attribute 2 – Scale –             extent has household                              relationship between             defense infrastructure.             and explicit assumptions
       distinct geographical             and community resilience                          the flood defense/flood       •	 Control group selection             about their exposure to
       location, engaging at             increased as a result of                          drainage project and the         based on random selection of        similar flood risk and the
       the village-level through         the flood defense/flood                           development results.             households in representative        village-level impact of
       households                        drainage construction        •	 Establishing a                                     sample of villages with             exposure to this risk. Ideally
    •	 Attribute 3 – Duration            project?                        counterfactual should be                           matching characteristics to         both treatment and control
       – distinct project start       •	 Sub EQs:                        straightforward as surveys                         treatment village, with specific    villages should experience
       and completion dates for                                          can be taken before and                            emphasis on similar exposure        the same rainfall/flood
                                         }} What effect has the flood    after the flood defense/                           to similar flood risk.              events.
       infrastructure construction          defense/flood drainage
    •	 Attribute 5 – Wider                  construction had on
                                                                         flood drainage construction •	 Qualitative explanatory                                 •	 Evaluation design will
                                                                         with both treatment and        module could be included                                   need to be based on clear
       context – project designed           the assets, savings, and     control groups—villages        in the household survey                                    and explicit assumptions
       to address specific climatic         incomes of households?       who face the same flood        to explain ‘how’ the flood                                 on decreasing spill over
       shock—higher frequency
                                         }} Has the flood defense/       risk but have not benefited    defense/flood drainage                                     and trickle-down effects if
       and intensity rainfall causing
                                            flood drainage               from the construction of a     construction has improved                                  villages are very close to
       flooding—by enhancing
                                            functioned as intended       village-level flood defense.   the assets, savings, and                                   each other.
       absorptive capacity of
                                            in the face of severe                                       incomes of households and
       village households
                                            rainfall and flood risk?                                    communities.
                                                                                                                         •	 Other resilience elements
                                                                                                                            – evaluation design should
                                                                                                                            include an element which
                                                                                                                            explores resilience in the
                                                                                                                            face of shocks and stresses—
                                                                                                                            both how the project itself is
                                                                                                                            resilient and what this means
                                                                                                                            for the resilience of beneficiary
                                                                                                                            households and communities.

*    Attributes from Table 2, above, as they relate to each example.
                                                                                                                                                                                                  31
                                                                                                                                                                             32




           Factor 1                            Factor 2                        Factor 3
                                                                                                            POTENTIAL METHODS                         NOTES
     DEFINING ATTRIBUTES                     HEADLINE EQs                 AVAILABLE DESIGNS

                                        Example project 2 - A climate resilient pro-poor livelihoods diversification program

•	 Attribute 1 - Nature and focus •	 EQs based on determining         •	 Quasi-experimental               •	 DiD relies on data           •	 Robust quasi-experimental
   of the interventions – a pro-       if livelihoods program            design deemed most                  generated through               design requires careful
   poor livelihoods diversification    has had an impact and             appropriate given                   various forms of panel          pairing of communities
   program targeting several           establishing the relative         establishing cause and              survey including:               in order to ensure both
   village communities in multiple     contributions of different        effect in a classic, linear        }} Comparing matched             treatment and control
   locations, and based on             packages of interventions.        sense is challenging due              individuals from early        groups face the same
   packages of interventions        •	 Headline EQ – To                  to the complexity of the              intervention vs. late         climate shocks and
   combining village savings and       what extent have key              project and resilience as a           intervention households       stresses, as well as the
   loans associations, provision       determinants of beneficiary       concept.                              and communities using         same exposure to these
   of climate information, and         resilience—savings,            •	 Therefore, counterfactuals            a baseline and endline        shocks and stresses.
   improved seed varieties.            income, food security—            need to be constructed                panel household survey.    •	 Confounding factors—
•	 Attribute 2 – Scale – distinct      increased as a result of the      via quasi-experimental                                              outcomes potentially
                                                                                                            }} Comparing matched
   geographical location,              program’s interventions?          methods that permit the                                             influenced by other
                                                                                                               high-intensity vs.
   engaging at the household        •	 Sub EQs:                          comparison of matched                                               variables/factors beyond
                                                                                                               medium-intensity
   and community across a clearly                                        individuals and households                                          the direct package of
                                       }} Which interventions/                                                 package groups using
   defined set of villages.                                              in control and treatment                                            interventions, making
                                           packages of                                                         a comparative baseline
•	 Attribute 4 – Nature and focus                                        groups.                                                             it difficult to attribute
                                           interventions work to                                               and endline household
   of stakeholders – primary focus                                    •	 There are a number of                                               quantitative changes in the
                                           strengthen resilience                                               panel survey.
   on targeting the most climate                                         methods available under                                             resilience outcome solely
                                           and in which village                                             }} Matching procedures to        to the project.
   vulnerable households within            contexts?                     the quasi-experimental
                                                                                                               compare individuals from
   target communities, a clearly                                         “family.”                                                         •	 Panel surveys rely on
                                                                                                               representative baseline
   defined set of direct recipient                                    •	 A difference-in-difference                                           surveying the same
                                                                                                               and endline panel
   beneficiaries.                                                        (DiD) method allows                                                  people at the baseline
                                                                                                               surveys from ‘target’
•	 Attribute 5 – Wider context                                           comparison between                                                   and endline, which may
                                                                                                               (treatment) and ‘non-
   – the complexity and context-                                         those receiving project                                              not be possible given the
                                                                                                               target’ (control) villages.
   specificity of resilience-building                                    interventions (in technical                                          disruptive nature of climate
   requires implementers                                                 terms ‘treatment’                                                    shocks and stresses.
   to combine individual                                                 communities) with those                                          •	 Panel surveys also rely
   interventions into packages to                                        not receiving interventions                                         on control and treatment
   address the multidimensional                                          at all, or receiving fewer,                                         communities to face very
   nature of resilience.                                                 less targeted or intensive,                                         similar climatic and policy
•	 Attribute 8 – Practical and                                           interventions (e.g., ‘control’                                      changes.
   logistical factors – phased                                           communities).
   rollout of different packages
   to different communities at
   different times.
                                                                                                                                                                             E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R
               Factor 1                           Factor 2                     Factor 3
                                                                                                       POTENTIAL METHODS                          NOTES
         DEFINING ATTRIBUTES                    HEADLINE EQs              AVAILABLE DESIGNS

                         Example project 3 – Supporting and informing the formulation of a national adaptive social protection policy

•	 Attribute 1 - Nature and focus          •	 EQs based on defining    •	 Qualitative design       •	 Framing the evaluation          •	 Theory-based methods
   of the interventions – supporting          the contribution of         is deemed most              under a theory-based               such as CA rely on a strong
   and informing the formulation of a         the project to shaping      appropriate given           approach driven off the            and shared description of
   national adaptive social protection        and informing the           that a number of the        project’s ToC will support         a project’s ToC, including
   program working with a broad set           wider national policy       project attributes makes    the identification and             the wider contextual
   of national, government, and civil         and programming             a design based on           confirmation of the multiple       assumptions and risks.
   society stakeholders to influence          environment on              establishing attribution    causal processes and            •	 CA is useful for considering
                                                                                                                                                                          S E C T I O N 2 : S T E P - B Y- S T E P G U I D E




   the creation and content of a new          adaptive social             through a counterfactual    pathways at work.                  and understanding
   national policy agenda.                    protection.                 impossible—broadly       •	 Contribution Analysis (CA)         complex, non-linear causal
•	   Attribute 4 – Nature and focus of     •	 Headline EQ – To            defined project             as a method will allow the         mechanisms, including
     stakeholders – project involves a        what extent has the         delivered in a complex      relative contribution of the       better understanding ‘how’
     broad range of stakeholders from         project contributed to      national context,           project to the wider change        and ‘why’ certain processes
     anticipated beneficiaries to civil       shaping and informing a     through various             process to be tested and           deliver observed results in
     society advocacy organizations,          national adaptive social    partners, and with the      established.                       certain settings.
     as well as local and national            protection policy and       aim of influencing and
                                                                                                   •	 CA will also provide a          •	 Policy processes take
     government partners.                     program?                    informing policy, and
                                                                                                      deeper understanding of            time -assessing a project’s
                                                                          with a long-term and
•	   Attribute 5 – Wider context –         •	 Sub EQs:                                                the supporting factors and         contribution to ‘higher-
                                                                          unpredictable results
     informing a national policy and          }} What are the critical                                mechanisms at work in that         order’ results trajectories
                                                                          ‘trajectory.’
     program in a wider socio-economic           factors that either                                  context.                           can be slow—with evidence
     and political context, with a range                               •	 A range of qualitative                                         of results at the impact level
                                                 enable or constrain                               •	 Complementing the
     of other actors and interest groups                                  methods are available,                                         only available several years
                                                 the formulation                                      CA method with some
     supporting or challenging the policy.                                broadly characterized as                                       after the end of the project.
                                                 of a national                                        participatory and/or case-
                                                                          theory-based, case-
•	   Attribute 6 – Level of investment           adaptive social                                      based methods in a mixed        •	 Qualitative designs are
                                                                          based, or participatory.
     relative to the scale of the                protection policy and                                method design will allow           generally better suited
     challenge – comparatively small             programming?          •	 A qualitative mixed-        for:                               to support generalization
     investment to inform the design                                      method approach can                                            beyond the site-specific
                                              }} What can be learned      combine elements of         }} Validation by participants
     of a national policy relative to the                                                                that their actions and          project. Developing
                                                 from the project         theory-based, case-
     overall scale of investment required                                                                experienced effects are         typologies of context can
                                                 about informing and      based, and participatory
     to operationalize a national social                                                                 ‘caused’ by the project.        support generalizations
                                                 influencing adaptive     approaches.
     protection safety net program.                                                                                                      under these conditions,
                                                 social protection                                    }} Comparison across
•	   Attribute 7 – Nature of the funding                                                                                                 allowing lesson-learning on
                                                 policies and                                            and within cases or
     modality – technical assistance                                                                                                     policy influencing projects
                                                 programs in other                                       combinations of causal
     component of an operation                                                                                                           to be transferred between
                                                 countries?                                              factors with the potential
     combined with a multi-donor trust                                                                                                   country contexts.
                                                                                                         to generalize lessons in
     fund implemented in partnership
                                                                                                         other contexts to support
     with local and national governments.
                                                                                                         replication.
                                                                                                                                                                          33
34                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     The examples provided above are simplifications of how key project/program attributes inform feasible
     and appropriate evaluation design selection. Although World Bank project/programs cannot be
     simply classified according to these three examples, they should help orient TTLs during the resilience
     evaluation design process. By completing the attributes checklist and revisiting the three examples, TTLs
     should be able to get a general sense of how to approach their own project/program, and hence, begin
     to define and elaborate a feasible evaluation design.



         FURTHER READING
         General evaluation resources:
         NONIE Guidance on Impact Evaluation [siteresources.worldbank.org/EXTOED/Resources/nonie_guidance.pdf]

         Introduction to Mixed Methods Approach in Impact evaluation [https://www.interaction.org/resources/training/
              guidance-note-3-introduction-mixed-methods-impact-evaluation]

         Broadening the Range of Designs and Methods for Impact Evaluations [https://www.gov.uk/government/uploads/
            system/uploads/attachment_data/file/67427/design-method-impact-eval.pdf]


         Resilience-specific resources:
         Assessing resilience: why quantification misses the point [https://europa.eu/capacity4dev/file/20275/
            download?token=8q95bJei]

         Complex Systems [https://oxfamblogs.org/fp2p/tag/complex-systems/]

         How do you measure the difficult stuff (empowerment, resilience) and whether any change is attributable to your
            role? [https://oxfamblogs.org/fp2p/how-do-you-measure-the-difficult-stuff-empowerment-resilience-and-
            whether-any-change-is-attributable-to-your-role/]

         Impact Evaluation Guidebook for Climate Change Adaptation Projects [www.adaptationcommunity.
            net/?wpfb_dl=260]

         Laying the Foundation for Measuring Resilience [http://www.itad.com/reports/
             laying-foundations-measuring-resilience/]
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                      35




                                                     Identify data collection tools
               STEP 4                                and methods


      MAIN MESSAGES
        •	 Resilience cannot be tracked by one universal quantitative indicator; instead resilience tracking requires
           a combination of a multidimensional indicator frameworks and/or composite indices coupled with
           qualitative process indicators.
        •	 Reliable evaluation of resilience-building projects/programs requires four separate types of data:
           project results data, climate/weather data, impact level data, and contextual data.
        •	 Effective evaluations need to build on long-term, high-frequency monitoring efforts.




Step 4 involves selecting data collection methods
and tools to produce the high-quality data needed                       Core Evaluation Considerations
to answer the EQs, gather evidence for indicators,                      QUALITATIVE TOOLS AND METHODS
and deliver valid, reliable evaluation findings.                        •	 What set of qualitative tools and methods
                                                                           are most appropriate and feasible?
As discussed in Section 1, defining the
                                                                        QUANTITATIVE TOOLS AND METHODS
results framework is a prerequisite step
                                                                        •	 What set of quantitative tools and
to commissioning an evaluation. Specific,
                                                                           methods are most appropriate and
observable, and measurable indicators help
                                                                           feasible?
define exactly what “success looks like.” The data
collected against each indicator will be used to                        SAMPLING
answer the EQs.                                                         •	 What sampling strategies are most
                                                                           appropriate and feasible?
  •	 TTLs that have already identified resilience
     indicators at the planning stage (again,
     guidance on indicator development/selection is provided through complementary activities in the
     ReM&E project), would benefit from reviewing and revising them as part of the evaluation design
     process. This is particularly the case when, for example, the pre-established current indicators do not
     adequately and/or appropriately address the data needs of the EQs.

Once the EQs and appropriate design and indicators have been identified, the next step is to
develop a data collection plan. A data collection plan enables TTLs to move from design to data
collection and analysis. When selecting the best data collection method for each indicator, TTLs need to
consider:
  •	 Have the data already been collected or is it necessary to create a new data set?
  •	 Who (within the team and outside of the team) is best able to provide the information?
  •	 Can the evaluation afford the costs associated with the method you select?
36                                    E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Table 4 gives an example of how a data collection plan is usually structured.

     TABLE 4: Example data collection plan

                                                                                                         Data collection
       Question to                                 Required
                            Indicator(s)                                                          Methods/                                      Resources
       be answered                                   data                   Sources                                        Sample
                                                                                                 Instrument                                     Required




     Source: Adapted from Deutsche Gesellschaft für Internationale Zusammenarbeit (GIZ) 2016


     The development of a data collection plan involves the identification of data sources as well as
     data collection methods and tools. Data collection methods can be either primary or secondary, and
     quantitative, qualitative, or a combination of the two. A review of secondary data sources—including
     official statistics, project records, and social media—should precede any primary data collection. The
     use of reliable and relevant secondary data represents tremendous cost and time savings to the project.
     Every effort should be made to establish what secondary data exist and their potential to be used for the
     evaluation. It is also critical to invest the time to investigate data gaps so as to inform what data collection
     exercises should be prioritized for the future.

     However, existing data do not always provide the information required to effectively evaluate projects,
     and even relevant secondary data may not be useful if the data are out of date and/or the situation has
     changed since collection. With this in mind, primary data collection is sometimes necessary.

     Primary data collection methods vary from quantitative and qualitative:
      •	 Quantitative data collection methods rely on sampling and structured data collection instruments that
         fit diverse experiences into predetermined response categories. They produce results that are easier
         to summarize, compare, and generalize.
      •	 Qualitative data collection methods play an important role in evaluation by providing useful
         information to understand the processes behind observed results. Furthermore, qualitative methods
         can be used to improve the quality of survey-based quantitative evaluations by expanding or
         clarifying quantitative findings.

     Mixed methods combine both qualitative and quantitative data collection methods to potentially offer a
     “richer picture” of what is being examined. Annex 2 provides a summary of the main data collection tools
     and methods. It is beyond the scope of this guidance paper to address the full process of deciding which
     method(s)— quantitative, qualitative, and/or mixed—are most appropriate for which type of EQs.
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                                                     37




Good evaluations rely on good data. The lack of quality data, including missing baseline and
monitoring information, remains a serious challenge for evaluations. Such gaps limit possibilities for
before/after comparisons and make it more difficult to understand how an intervention has contributed
to changes over time. Baseline data are often not collected for a variety of reasons: budget and time
constraints, insufficient project/program planning, political constraints, and delayed commissioning of
an evaluation. Better planning early on, and the integration of planning specific M&E stages into project
designs (as described in Step 1) should help to improve this situation.

In the absence of baseline data, secondary data from censuses, surveys, administrative records,
interviews, etc. can be used for reconstructing baseline data.15

Making valid and robust statements about projects/programs results largely depends on a sound
sampling strategy. Sampling involves identifying a representative subset of the project/program target
population. The sampling strategy is defined by the overall evaluation design. Experimental and quasi-
experimental designs will tend to involve relatively large-scale sets of data. More qualitative approaches
will tend to involve smaller samples and more in-depth interviews and questionnaires.

Guidance on sampling strategies is generic to all evaluations, and is readily available. It is beyond the
scope of this paper to provide such guidance—suggested references are provided at the end of Step 4.



Resilience-specific considerations
Develop resilience indicators. TTLs, beneficiaries, and stakeholders will need to jointly develop
indicators that capture the aspects of resilience they identified in the project ToC. This collaboration can
be done as an extension of the participatory process discussed in Step 2. Selecting resilience indicators is
a major conceptual and technical challenge, made even more so when the aim is to also produce
indicators that are transparent, robust, representative, replicable, comparable, and easy to understand. As
with secondary data, it is useful to identify if any existing indicators can be used for resilience as opposed
to reinventing the wheel and developing one’s own. For example, the indicators that can populate an
index approach can often be drawn from standard sector indicators.



      NOTE
      Identifying resilience indicators is not an easy task. In light of the numerous challenges related to evaluating
      DRM and CCA projects/programs, “counting” the number of people benefitting from interventions
      had become a generally accepted proxy for vulnerability reduction. The assumption was that people
      participating in such projects/programs have access to the knowledge, assets, and other resources required
      to reduce their vulnerability to climate and disaster risk, as well as to strengthen their adaptive capacity.
      The limitations of this approach are now widely acknowledged as critiques have been raised about (1)
      the output nature of the indicator (as opposed to the outcome/impact) and (2) the underlying assumption
      that investment equitably builds capacity (or reduces vulnerability) across all beneficiaries (Bene et al.
      2015). This, coupled with the acknowledgement that resilience cannot be tracked by any one universal
      quantitative indicator, is leading to the emergence of a set of multidimensional indicator frameworks and
      composite indices.


15	  For additional guidance on this subject, refer to Reconstructing Baseline Data for Monitoring and Evaluation – Data Collection Methods [sitere-
sources.worldbank.org/INTUKRAINE/Resources/328335-1212401346836/2BaselineReconstruction.pdf].
38                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Decide whether to use a composite index or integrated indicator frameworks. TTLs will need to
     decide whether to use composite indices, constructed by aggregating individual indicators, or individual,
     disaggregated indicators. The options are as follows:
      1.	 Use a number of individual indicators, each representing a different aspect of resilience that is
          relevant to the project. Indicators are measured and recorded separately for each unit being sampled.
      2.	 Develop a composite index, combining indicators that quantify key elements of resilience that are
          relevant to the project/program into a single measure. Individual indicators are often weighted
          before being combined using a mathematical equation designed around a conceptual framework of
          resilience. Creating a measurement system based on composite indicators poses a set of technical
          challenges including if and how to group them into different dimensions, and if and how they should
          be weighted. The pros and cons of using composite indicators are summarized in Table 5.

     TABLE 5: Pros and cons of composite indicators

                                 Pros                                                                             Cons

      Can summarize complex, multi-dimensional                                May send misleading messages if poorly
      realities                                                               constructed or misinterpreted

      Easier to interpret than trying to find a trend in                      May mask important information about individual
      many separate indicators                                                indicators

      Facilitate communication of findings                                    May invite too simplistic conclusions

      Enable users to compare complex dimensions
      effectively

     Adapted from Beccari 2016


     A composite index can be especially useful for resilience-building projects/programs, as resilience to
     climate extremes and disasters is considered to be a composite attribute representing the capacity to
     cope with, respond to, and adapt to shocks and stresses (IPCC 2014). Therefore, measuring resilience
     improvements as a result of a project/program’s activities requires measuring changes in composite
     attributes. However, this raises a number of challenges (Beccari 2016):
      •	 Availability of relevant quantitative and qualitative data needed to conceptualize resilience. In many
         cases, data availability, rather than true relevance, tends to be the primary factor in selecting the
         variables to include in an index.
      •	 Benchmarking and communicating index results. In the absence of agreed upon benchmarks, it can
         be difficult to determine whether the index value demonstrates if a government or community's
         performance is sufficient or if it needs to be improved.
      •	 Methodological uncertainties associated with aggregation are significant and require a large number
         of value judgments. Ultimately, there may be merit in considering disaggregated measures of
         resilience based on consultative, stakeholder-driven processes, rather than technical analysis that
         leads to a single number or ranking.

     Decide what approach works best according to each project/program’s specific context.
     Consideration of the intended audience is highly important in determining if an index is appropriate and
     at what level of aggregation data should be presented. If composite indices are considered to be more
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                    39




relevant, then it is strongly recommended that the disaggregated data representing the individual
constituent indicators are preserved. This enables the relative importance of individual indicators and the
factors they represent to be transparently unpacked, which is critical for understanding how and why
resilience has changed. This is vital both for learning and assessing the contribution the project/program
has made to individual changes in resilience.



      NOTE
      Indicators can be used to define resilience across a number of contexts, scales, and sectors. Resilience is
      often defined in terms of capacity and asset indicators, as they can be easily tailored to specific projects/
      programs; this is sensible and likely represents the best available solution. However, clear methodological
      issues relate to differences in interpretation, definition, data collection, and reporting across different
      resilience-building projects/programs. Resulting inconsistencies in data collection and reporting can limit
      the ability to compare or aggregate across projects/programs.

      Annex 3 provides a selection of resilience indictors and measurement frameworks, which have been recently
      conceived for measuring changes in the levels of resilience at the household and community level. Guidance
      on indicator development/selection is provided through complementary activities within the ReM&E project.




Gather four types of data. Reliable evaluation of resilience-building projects/programs requires four
separate types of data: project results data, climate/weather (shock and stress) data, impact/results level
data, and contextual data:
  1.	 Project results data, which aim to capture achievements at different levels of the results framework
      and ToC. The evaluation of resilience-building projects/programs places particular emphasis on
      outcome level achievements—did the project build resilience or contribute to significant outcomes
      that are indicative of a resilience-building trajectory? There are significant benefits however in also
      evaluating the processes followed by the project. For example, if project/program outcomes are
      highly dependent on stakeholder capacity to develop plans or conduct risk assessments, it may be
      important to evaluate the processes the project/program followed to build such capacity; changes
      in knowledge, motivation, incentives, and behavior would be important to evaluate. Project results
      data should focus on supporting processes in addition to concrete quantifiable outcomes. Box 3
      provides an example of a qualitative approach to gather information on the processes that may lead
      to resilience outcomes.
      }} Subjective reports from beneficiaries and wider project/program stakeholders are likely to be as
         important and accurate as a quantitative indicator of success of greater resilience in the face of
         climate shocks and stresses (Jones and Samman 2016). It may therefore be pertinent to collect
         attitudinal data, or conduct interviews, workshops, or focus group discussions to collect such
         supplementary data. Box 4 provides an example of an emerging qualitative approach to gathering
         information on beneficiary and stakeholder perceptions of resilience capacities.
      }} Blending quantitative and qualitative indicators that strike a balance between practicality
         and comprehensiveness as well as measuring intangible changes in areas such as local
         perceptions of resilience and individual agency and social ties should be incorporated into
         planning, budgeting, data collection, and selection of the evaluation approach.
40                                E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     BOX 3: TRACKING AND ASSESSING PROCESSES OF CHANGE

     The ToC of the Building Resilience and Adaptation to Climate Extremes and Disasters (BRACED) program
     identifies four Areas of Change (AoC) to explain how BRACED will contribute to improvements in resilience.
     These AoCs represent a set processes or causal pathways through which the program aims to achieve
     resilience outcomes. The four AoCs are defined as:

      Changes in knowledge               Changes in the                        Changes in the quality                Changes in decision-
      and attitude in relation           capacities and skills                 of partnerships to                    making processes
      to resilience-building,            of national and local                 deliver interventions.                through inclusive
      in order to further                government, civil                                                           participation, as one
      strengthen policies and            society, and private                                                        key aspect of a resilient
      practices.                         sector to manage the                                                        system.
                                         risks of climate extremes
                                         and disasters.

     BRACED projects collect data against these processes on annual basis and are self-reported by
     implementing partners following a set of progress markers. This enables the program to unpack the
     ‘missing middle’ by understanding the process by which outputs contribute to meaningful outcomes. The
     results of from the first-year assessment can be found in the Routes to Resilience: Insights from BRACED
     Year 1 Report [http://www.braced.org/resources/i/?id=ed1d6676-a044-4f26-a99d-562785272bdb].
     Source: Adapted from Silva-Villanueva et al. 2016




     BOX 4: SUBJECTIVE ASSESSMENTS OF RESILIENCE

     In essence, what matters in subjective assessments is whether or not stakeholders “feel” more resilient in
     the face of shocks and stresses. A range of methods, surveying tools, and applications—such as open and
     semi-structured interviews—are useful for qualitative measurements of household resilience. For example,
     the evaluation of the United Nations Development Programme’s Community Based Approach to Local
     Development (UNDP CBA) project in Kazakhstan (2013), assessed the achievement of the project outcomes
     via workshops with communities by asking beneficiaries about changes in their vulnerability levels to climatic
     risks. Participants were asked four indicator questions to which they respectively assigned a score from zero
     to five (five meaning significant impact, confidence; zero denoting low impact, lack of confidence):
      •	 How serious is the current climate change impact, causing the reduction of water level in the Talas
         River, on your livelihood?
      •	 If / In the case that the unfavorable years such as 2008 become a normality, how serious will the impact
         on your livelihood with the existing agricultural practices be?
      •	 How serious are the barriers to using the new water charging method (autumn and early spring
         irrigation)?
      •	 How confident is the community in the reduction of its vulnerability to the climate change risks using
         the autumn and early spring irrigation technology?
     Adapted from United Nations Development Programme 2012
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                                                        41




  2.	 Climate/weather (shock and stress) data, which reflect the climatic context in which the project/
      program is being delivered. Gathering climate data is critical so that the effects of exposure can
      be incorporated within the evaluation. Systematically generating primary climate/weather data is
      not likely to be possible as a result of cost and capacity constraints; most projects/programs will
      need to rely on data generated by national meteorological organizations (primarily accessible
      through national meteorological offices). Evaluation teams relying on this method should attempt to
      determine whether data are sufficiently accurate, timely, and localized for use in analysis of resilience
      outcomes.16
  3.	 Impact/results level data, which demonstrate that resilience-building is having the anticipated
      positive developmental impact.
      }} If the ultimate goal of resilience-building projects/programs is the improvement (or at a minimum,
         the non-deterioration) of long-term individual or household wellbeing in the face of shocks and
         stresses, then the indicators used to measure results should measure change in an individual’s or a
         household’s wellbeing. Impact level data are not necessarily only related to the individual; impacts
         could also be measured as avoided damages/costs to infrastructure, and maintenance of key
         ecosystems, for example.
      }} Gathering impact level data may be required when the purpose of the evaluation is to assess
         the extent to which the project had an impact/contributed to changes in the well-being of
         beneficiaries, the region, or the country. Indicators may include nutritional indicators, GDP, food
         security, etc.
  4.	 Contextual data, which reflects the wider context in which the project/program is being delivered.
      The inherent complexity of resilience drives a need for data beyond the specific project/program—a
      need for data that are useful for understanding the broader system in which a project/program sits.
      Doing so helps address the spatial and temporal challenges faced by resilience evaluation. Relevant
      data may include physical/environmental, national and/or regional policies, market forces, and other
      wider macro-level factors. A narrow focus on project results would risk overly-narrow interpretations of
      change processes, and thus the key results and lessons derived.

Generating and managing these four independent datasets presents a set of challenges. Resilience
measurement dynamics refers to a framework or model where the four datasets are brought together
in a system or model and dynamically integrated. Projects should try to analyze the combination and
interaction of the four parameters on a case-by-case basis. To date, there is no established good practice
model for the systematic integration of these data. However, examples and guidance have emerged,
including the Resilience Index Measurement and Analysis tool (RIMA) developed and tested by FAO
(2016); and the more recent Enhancing Resilience to Natural Disasters and the Effects of Climate Change
(ER) program from a joint initiative involving the Government of Bangladesh and the World Food
Program.17,18 Any solution needs to dynamically integrate resilience-building results in a climatic shock
and/or stress context over time.

Be careful about the challenges with experimental (and oftentimes quasi-experimental) evaluations.
Experimental evaluations typically involve the use of large sample surveys that are often conducted at


16	   For additional guidance on this subject refer to Measuring Shocks and Stressors as Part of Resilience Measurement [www.fsincop.net/fileadmin/
user_upload/fsin/docs/resources/1_FSIN_TechnicalSeries_5.pdf].
17	   RIMA is a quantitative approach that enables a rigorous analysis of how households cope with shocks and stressors, and also helps explain why and
how some households cope with shocks and stressors better than others. Refer to the RIMA website [http://www.fao.org/resilience/background/tools/
rima/en/] for additional guidance on this subject.
18	   Refer to Béné et al. 2017.
42                                      E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     the household level. TTLs must weigh a number of considerations when planning and designing such a
     survey—some of which may be specific to resilience-building projects/programs:
       •	 Sample design: this requires the identification of different sample populations (a subset of the
          wider population or community in which the activity is taking place) and the allocation of households
          to a control or a treatment group. The process of establishing an appropriate sampling strategy
          requires an understanding of the project/program and the context in which it is operating. Technical
          and statistical considerations—e.g., how precise or accurate do estimates need to be, and how
          will “contamination” be controlled—will influence the size and distribution of the sample. Such
          considerations are not discussed in detail here as they are not necessarily specific to resilience-
          building projects/programs, and they have been comprehensively covered in other World Bank
          Impact Evaluation documents.19 However, several design considerations are specific to climate or
          disaster resilience-building projects/programs including:
           }} Shock alignment: in general, control and treatment groups need to be broadly similar to facilitate
              comparison (for example, groups should be socio-economically similar in terms of income levels,
              access to services, etc.). For projects/programs associated with climate-related shocks and
              stresses, there is also a need to consider ensuring that the control and treatment populations are
              subject to similar enough shocks to permit comparison. For example, two different communities
              in close geographic proximity may be similar in socio-economic characteristics but suffer from
              quite different shocks and stresses—one may be nearer to a river which floods, while the other
              may suffer from landslides, both of which are associated with intense, unseasonal rain. These
              shocks or stresses will affect different aspects of the community making comparison challenging.
              Understanding and organizing a sample in a manner that acknowledges these shocks/stresses in
              advance is advisable. The unpredictable frequency, timing, intensity, and location of climate shocks
              and stresses further complicates matters by raising the possibility of treatment and control groups
              suffering different shocks at different times within the project/program lifecycle. This has the
              potential to undermine the basis of the treatment-control relationship, which is a key limitation of
              quantitative approaches that rely on counterfactuals for assessing resilience-focused interventions.
              A potential alternative is to conduct an evaluation post-shock. The impact evaluation of the PRIME
              program in Somalia and Ethiopia provides a recent example of this methodology in practice.20
           }} Shock-driven attrition and the mobility of climate-vulnerable populations: attrition, the rate at
              which respondents ‘drop out’ of a sample between survey rounds, is an issue for all evaluations.
              Resilience-building projects/programs may be dealing with communities and households whose
              shock response, in extreme cases, may be to abandon their homes and move elsewhere. This has
              the potential to prevent teams from re-establishing contact with the same respondents at future
              survey rounds. Furthermore, given that resilience-building projects/programs often target the most
              vulnerable communities and households, interventions may involve working with communities
              in extreme climatic conditions—for example in the Sahel region. Pastoralist populations in the
              Sahel are accustomed to extreme climate conditions and frequently move in search of water and
              fodder as a coping strategy. Tracking such mobile populations for an evaluation can be extremely
              challenging. Finally, the extended timeframe often necessary for resilience evaluations (5-10 years
              after project completion) also poses challenges with respect to attrition.



     19	   Refer to Gertler et al. 2011 and Khandker et al. 2010.
     20	   With the onset of the 2015-2016 El Niño drought in Ethiopia, the program took advantage of this opportunity to rigorously evaluate interventions
     implemented under the USAID-funded PRIME project. Additional information on the PRIME impact evaluation can be obtained through Mercy Corps
     [https://www.mercycorps.org/sites/default/files/Mercy%20Corps_PRIMEandDroughtResilience_2017_FullReport.pdf].
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                             43




  •	 Surveys: Surveys can be very costly and projects may not be able to afford their use. As part of a data
     collection plan (see introduction of Step 4), TTLs should discuss the possibility of drawing from
     existing secondary datasets—if they are deemed sufficiently accurate, localized, and timely. Possible
     resources include the Living Standard Measurement Surveys and the Poverty and Equity database.
     For those projects that can afford conducting household surveys, the construction of an appropriate
     survey instrument (questionnaire) is critical. For resilience-building projects/programs, it may be as
     important to understand how respondents interpret their current resilience levels as it is to
     understand changes in factors that the evaluator believes affect resilience (e.g., income or savings).
     Subjective questions can be combined with more objective ones to test and triangulate a
     respondent’s understanding of resilience.



      NOTE
      Technical expert experience is required to design the sample size and composition for
      quantitative surveys. Getting the sample size and composition right is critical to ensuring the
      statistical credibility of the evaluation. It is also a highly technical task that requires advanced
      knowledge of statistics and sampling methodology. It is important that the individual or firm
      designing the survey be familiar with the geography, culture, and other characteristics of the local
      environment from where the sample is to be drawn. TTLs should consult or hire a technical expert
      who possesses the requisite methodological and local knowledge to design the sample size and
      composition.




Frequency and timing of data collection from a baseline. A baseline is made up of data on a set
of selected indicators as they exist at a particular point prior to the implementation of a project’s/
program’s interventions. The time of year the baseline and subsequent rounds of surveys are conducted
is important—particularly for resilience-building projects/programs. Data collection should attempt to
account for seasonality of livelihoods. Surveys should be planned from the baseline onwards at a similar
time of year for each round, and with a clear climate- and context-based rationale for this timing. This
may involve avoiding or targeting particular times (e.g., post-harvest, tropical cyclone seasons, dry
season, etc.).

Efforts should be made to generate robust baseline data on climate conditions as well as targeted
resilience-building processes and outcomes. A major challenge for evaluating resilience-building
projects is the uncertainty about actual climate change patterns and their effects. A baseline is crucial
to measure the project’s impact, as it provides a reference point against which a change can actually
be measured. However, given the uncertainty about how and when climate change impacts will unfold,
pre-and post-project/program data may lose validity if climatic conditions change from the start of the
project/program. This challenge of “shifting baselines” is problematic in terms of planning since the shifts
change the context of the resilience-building projects/programs.

A viable approach, if evaluation resources and flexibility allow, can be to wait for a climatic shock/stress
to occur, and to then conduct a baseline shortly thereafter. This will offer a snapshot of resilience status
following the shock/stress. The comparison point, and trigger for the subsequent survey round, would be
after the subsequent occurrence of a similar hazard. Assuming the resilience-building project/program
44                             E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     is delivered in the interim, it is feasible to assess the extent to which any improved resilience between
     the two events is attributable to project/program’s interventions. This approach will work best with rapid
     onset shocks such as flood events, typhoons, and hurricanes as they have relatively distinct event profiles.
     This also assumes (perhaps unrealistically so) that hazard events with relatively similar event profiles will
     occur in the same locations in subsequent years.

     It is necessary to consider the potential ethical challenges associated with delivering a household/
     community survey in the aftermath of a climate shock/stress when a “do no harm” approach serves as
     a guiding principle. Certainly, there may be concerns about survey fatigue amidst the calamity of the
     aftermath. But if the survey is to help the respondents in the long-term, the benefits may offset the ethical
     concerns. A more important, serious ethical concern would be if the implementation of a resilience
     intervention in a community earmarked to receive assistance is delayed for the sake of obtaining post-
     crisis baseline data first; that is, that measurement takes precedence over timely and warranted service
     delivery.

     To date, discussions about how to address the methodological challenge of measuring resilience results
     in the absence of a shock/stress (during the lifetime of the project) remain limited. By monitoring and
     measuring changes in resilience indicators, embedded in a sound ToC, over time, and by assessing the
     contributions of the project/program to these changes, evaluations can, in principle, measure project/
     program results against proxy indicators even in the absence of significant climate or other shocks

     Build in robust monitoring systems. Data collection frequency is another key consideration. Changing
     contexts require that baselines be revised to provide a more accurate basis for comparison between
     how events unfolded in light of the intervention, and how they would have unfolded in its absence.
     Effective evaluations need to build on long-term, high-frequency monitoring efforts (Barret and Heady
     2014). Timing baseline, mid-line, and end-line surveys to allow enough time for effects to be detectable
     should be considered alongside the purpose of the evaluation. If effects are unlikely to take place during
     the project lifetime, but rather be seen farther in the future, then an ex-post evaluation is likely suitable.
     However, if the evaluation purpose is to draw out lessons solely for the specific project/program, then an
     ex-post evaluation might not be necessary.
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                                        45




      FURTHER READING
      General evaluation resources:
      Data Collection and Analysis Methods for Impact Evaluation [https://www.unicef-irc.org/publications/pdf/brief_10_
         data_collection_analysis_eng.pdf]

      Baselines and Targets, Performance Monitoring & Evaluation Tips [siteresources.worldbank.org/INTPOVERTY/
         Resources/335642-1276521901256/premnoteME4.pdf]

      Reconstructing Baseline Data for Impact Evaluation and Results Measurement [siteresources.worldbank.org/
         INTPOVERTY/Resources/335642-1276521901256/premnoteME4.pdf]

      Define ethical and quality evaluation standards [http://www.betterevaluation.org/en/plan/manage_evaluation/
          ethical_evaluation]


      Resilience-specific resources (on indicators):
      Béné, C., T. Frankenberger, and S. Nelson. 2015. “Design, monitoring and evaluation of resilience interventions:
         Conceptual and empirical considerations.” IDS Working Paper 459, Brighton: Institute of Development
         Studies. Available from: https://www.researchgate.net/publication/280013739_Design_Monitoring_and_
         Evaluation_of_Resilience_Interventions_Conceptual_and_Empirical_Considerations

      Béné, C., F.S. Chowdhury, M. Rashid, A.S. Dahil, and J. Ferdous. 2017. “Squaring the circle: reconciling the need
         for rigor with the reality on the ground in resilience impact assessment.” World Development. http://dx.doi.
         org/10.1016/j.worlddev.2017.04.011

      Food Security Information Network (FSIN). 2015. “A common analytical model for resilience measurement: Causal
         framework and methodological options.” FSIN Technical Series No. 2, Rome. Available from: http://reliefweb.
         int/sites/reliefweb.int/files/resources/FSIN_Paper2_WEB_1dic.pdf

      Lisa, E., F. Shipper, and L.A. Lansgton. 2015. “A comparative overview of resilience measurement frameworks.” ODI
          Working Paper 42, London: Overseas Development Institute. Available from: https://www.odi.org/sites/odi.org.
          uk/files/odi-assets/publications-opinion-files/9754.pdf

      Winderl, T. (2014). “Disaster resilience measurements: Stocktaking of on-going efforts in developing
         systems for measuring resilience.” UNDP. Available from: http://www.preventionweb.net/files/37916_
         disasterresiliencemeasurementsundpt.pdf

      United States Agency for International Development (USAID). 2014. Design and use of composite indices in
          assessment of climate change vulnerability and resilience. Available from: http://pdf.usaid.gov/pdf_docs/
          PA00K67Z.pdf
46                             E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




                                              Manage the implementation
              STEP 5                          of the evaluation
     By now, TTLs along with key stakeholders
     have defined the evaluation in terms of: (Step               Core Evaluation Considerations
     1) the scope and audience; (Step 2) the main                 TASKS UNDER THIS STEP INCLUDE:
     management arrangements that will guide
                                                                  1.	 Commission the evaluation
     decision-making processes and the communication
     strategy; (Step 3) the design and methodology);              2.	 Manage the implementation of the
     and (Step 4) the main data collection methods.                   evaluation
     Through Steps 1-4, TTLs have therefore identified            3.	 Present, share, and communicate the
     the foundational elements of evaluation. Step                    findings
     5 provides guidance on managing the actual
     implementation of the evaluation through a
     series of tasks that are relatively general to good evaluation implementation and management. The few
     resilience-specific considerations that are relevant under Step 5 are clearly highlighted.

     Negative experiences with evaluators are largely the result of unclear expectations, undefined research
     questions, and limited involvement between the program staff and the evaluator. One specific example
     is not communicating sensitive findings early as they emerge, but rather waiting until the written report
     to share them. To prevent these problems, TTLs should not contract out the evaluation until they have
     completed at least the first four steps of the planning process described in this paper. The more complete
     an Evaluation Plan, the better the ToR will be for the evaluator/contractor, and thus the greater likelihood
     of a successful evaluation.



     Task 1: Commission the evaluation
     If TTLs are contracting out the project evaluation, they will need to prepare a ToR. Steps 1-4 should inform
     the development of an evaluation ToR, which outlines both what is expected of the evaluator/evaluation
     team and from the evaluation process itself. The particularities of evaluating resilience-building projects/
     programs should be reflected in the ToR (Annex 4 offers a quick reference for what TTLs should consider
     when crafting a ToR for resilience-building projects/programs). Despite the paper’s recommendation to
     first carry out Steps 1-4, commissioning the evaluation will often occur prior to completely finalizing the
     evaluation design.
      •	 All parties involved in commissioning the evaluation should have ownership of the contents of the
         ToR—the consultative process for reviewing and finalizing this document is therefore very important.
         TTLs should strategically consult key stakeholders—such as line ministries, project units, and so forth—
         to solicit input and recommendations, and should reflect these in the document where possible.
      •	 As discussed in Step 2, a primary goal of conducting a successful evaluation is that stakeholders are
         engaged as active participants in the evaluation process and findings. This ensures that results are
         meaningful and useful to those ultimately responsible for improving the project/program. Given this
         premise, the critical skills of an effective evaluator should include the ability to listen, negotiate, bring
         together multiple perspectives, analyze the specific situation, and assist in digesting the most useful
         and important information into final products.
S E C T I O N 2 : S T E P - B Y- S T E P G U I D E                                                              47




Task 2: Manage the implementation of the evaluation
Following from Steps 1-4, TTL development of a workplan that includes realistic timeframes, clear
deliverables, and salient milestones, is crucial for ensuring the evaluation stays on track and achieves
intended results. The workplan should specify: what will be evaluated, the purpose and criteria for the
evaluation, the key EQs, and how data will be collected, analyzed, synthesized, and reported.

After designing the evaluation and collecting the relevant data, the information must be described,
analyzed, and interpreted. Ultimately, evaluators and TTLs will need to answer resilience-focused
questions such as: Has the project/program delivered or contributed to strengthened resilience? How?
Why or why not?

Evaluation findings need to be subject to reliable quality assurance processes. Before finalizing findings
and recommendations, the following questions should be considered.
  •	 Can the results be attributed to the resilience-building projects/programs? With what degree of
     confidence is it possible to make claims of contribution and attribution?
  •	 Can the resilience-building projects/programs be expected to work elsewhere, and under what
     conditions?
  •	 What potential sources of bias could have influenced the results?



Task 3: Present, share, and communicate the findings
TTLs should work alongside external evaluators to identify key findings, lessons, and recommendations,
and present and share these deliverables with others. To maximize the value of the evaluation, lessons
should feed into three different dissemination and learning pathways (Figure 4).


FIGURE 4: Dissemination pathways


                                     Sharing evidence and lessons with beneficiaries and direct stakeholders
         Pathway 1                   to prompt reflection on what works and how to act on recommendations



                                     Sharing evidence and lessons within and across GPs to support the use of
         Pathway 2                   evaluation results both in ongoing and future WB projects/programs



                                     Sharing evidence and lessons globally to
         Pathway 3                   inform initiatives and policies beyond the WB




Ultimately, the defining feature of all evaluations is the extent to which the findings are used to inform
decisions and contribute to the broader knowledge base both within, and external to, the World Bank.
The likelihood of results being applied beyond a project/program increases if findings are presented and
communicated in an effective manner. Different pathways require different levels of engagement and
communications strategies, and at different points in time.
48                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




      •	 Pathway 1: Conclusions and recommendations should be developed in a participatory format. For
         example, initial findings could be presented to a group of key stakeholders who would then work with
         evaluators to draw useful conclusions.
      •	 Pathway 2: The evaluation findings should facilitate linking knowledge to action and should contain
         useful information for informing practice across GPs within the World Bank. The preparation of
         specific communications such as policy briefs that target other TTLs and focus on practical issues can
         support the use of evaluation findings.
      •	 Pathway 3: Beyond stakeholders and World Bank colleagues, TTLs should also share the findings
         and lessons learned with relevant policymakers and other donors on a global scale. This may entail
         sharing findings in conferences, workshops, and policy processes so as to contribute to the on-going
         global debate about resilience projects/programs and their evaluation.

     Having completed the evaluation, learning, and dissemination processes, TTLs, stakeholders, and
     decision-makers should be better able to understand and improve outcomes and impacts and thus make
     more lasting contributions to building climate and disaster resilience.



     Resilience-specific considerations
     Recommendations made in the present can prove to be off the mark a few years later because of climate
     change. Therefore, it is even more important to develop such recommendations together with project/
     program stakeholders. When developing the framework conditions, it may be necessary to clarify the spatial
     and temporal validity of recommendations as well as the assumptions under which they were made.




         FURTHER READING
         General evaluation resources:
         Bonbright, D. 2012. Use of Impact Evaluation Results. Impact Evaluation Notes. No 4. Interaction, Rockefeller
            Foundation. Available from: https://www.interaction.org/sites/default/files/Use%20of%20Impact%20
            Evaluation%20Results%20-%20ENGLISH.pdf

         Center for Disease Control. 2013. Evaluation Reporting: A guide to help ensure use of Evaluation findings.
            Evaluation Guide. Atlanta, GA: US Dept. of Health and Human Services. Available from http://www.cdc.gov/
            dhdsp/docs/evaluation_reporting_guide.pdf


         Resilience-specific resources:
         An Evaluation Plan for a resilience strengthening programme – BRACED Evaluation Plan - DFID BRACED
            Knowledge Manager Evaluation Plan
REFERENCES                                                                                                                     49




References



Barrett, C.B. and D.D. Headey. 2014. Measuring Resilience in a Volatile World: A proposal for a multicountry system of
    sentinel site. 2020 Conference Paper 1, Washington, D.C.: International Food Policy Research Institute. Retrieved from:
    http://ebrary.ifpri.org/cdm/ref/collection/p15738coll2/id/128134

Beccari, B. 2016. “A Comparative Analysis of Disaster Risk, Vulnerability and Resilience Composite Indicators.” PLoS
   Currents, 8. Retrieved from: https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4807925/

Béné, C., T. Frankenberger, and S. Nelson. 2015. “Design, Monitoring and Evaluation of Resilience Interventions: Conceptual
   and Empirical Considerations.” IDS Working Paper 459, IDS, Brighton. Retrieved from: http://www.ids.ac.uk/publication/
   design-monitoring-and-evaluation-of-resilience-interventions-conceptual-and-empirical-considerations

Béne,C., F.S. Chowdhury, M. Rashid, S.A. Dhali., and F. Jahan. 2017. “Squaring the Circle: Reconciling the Need for Rigor
   with the Reality on the Ground in Resilience Impact Assessment.” World Development, http://dx.doi.org/10.1016/j.
   worlddev.2017.04.011

Bergamini, N., R. Blasiak, P. Eyzaguirre, K. Ichikawa, D. Mijatovic, F. Nakao, and S. M. Subramanian. 2013. "Indicators
   of resilience in socio-ecological production landscapes. United Nations University Institute of Advanced Studies,
   Yokohama. Retrieved from: http://www.bioversityinternational.org/uploads/tx_news/Toolkit_for_the_indicators_of_
   iesilience_in_socio-ecological_production_landscapes_and_seascapes_1844.pdf

Brooks, N., S. Anderson, J. Ayers, I. Burton, and I. Tellam. 2011. Tracking adaptation and measuring development. Report
   prepared for the International Institute for Environment and Development. Retrieved from: http://pubs.iied.org/
   pdfs/10031IIED.pdf

Brooks, N., E. Aure, and M. Whiteside. 2014. Final report: Assessing the impact of ICF programmes on household and
   community resilience to climate variability and climate change. Report prepared for Department for International
   Development. Evidence on Demand, UK. Retrieved from: https://www.gov.uk/dfid-research-outputs/final-report-
   assessing-the-impact-of-icf-programmes-on-household-and-community-resilience-to-climate-variability-and-climate-
   change

FAO (Food and Agriculture Association of the United Nations). 2013. “Resilience Index: Measurement and Analysis Model.”
   FAO, Rome. Retrieved from: http://www.fao.org/3/a-i4102e.pdf

Frankenberger, T., J. Kurtz and B. Sagara. 2015. “Mercy Corps’ Approach to Measuring Resilience.” Discussion Paper No.2.
    Mercy Corps. Retrieved from: https://www.mercycorps.org/research-resources/resilience

FSIN (Food Security Information Network). 2014. “Resilience Measurement Principles: Towards and agenda for
    measurement.” FSIN, Technical Series No1. Retrieved from: http://www.fsincop.net/fileadmin/user_upload/fsin/docs/
    resources/FSIN_29jan_WEB_medium%20res.pdf

Gertler, Paul J., S. Martinez, P. Premand, L.B. Rawlings, and C.M.J. Vermeersch. 2016. Impact Evaluation in Practice, Second
   Edition. Washington, DC: Inter-American Development Bank and World Bank. Retrieved from: https://openknowledge.
   worldbank.org/handle/10986/25030

GIZ (Deutsche Gesellschaft für Internationale Zusammenarbeit). 2015. Impact Evaluation Guidebook for Climate Change
    Adaptation Projects. GIZ, Bonn, Germany. Retrieved from: http://www.adaptationcommunity.net/?wpfb_dl=260
50                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     IEG (Independent Evaluation Group). 2012. Designing a Results Framework for Achieving Results: A How-to Guide. IEG,
         World Bank Group, Washington, DC, USA. Retrieved from: https://siteresources.worldbank.org/EXTEVACAPDEV/
         Resources/designing_results_framework.pdf

     ——. 2015. Managing Evaluations: A How-To Guide For Managers and Commissioners of Evaluations. World Bank Group,
       DC, USA. Retrieved from: https://ieg.worldbankgroup.org/Data/reports/ecd_man_evals.pdf

     ——. 2016. Behind the mirror: A report on the self-evaluation systems of the World Bank Group. IEG, World Bank,
       Washington, DC,USA. Retrieved from: http://documents.worldbank.org/curated/en/902331469736885125/
       Behind-the-mirror-a-report-on-the-self-evaluation-systems-of-the-World-Bank-Group

     IFAD (International Fund for Agricultural Development). 2015. “Measuring Climate Resilience:
        Environment and Climate Change.” IFAD, How To Do Notes. Retrieved from: https://www.ifad.org/
        documents/10180/338cf851-0ff2-4589-8a0f-da616cf43751

     IPCC (International Panel on Climate Change). 2014. Climate Change 2014: Synthesis Report. Contribution of Working
        Groups I, II and III to the Fifth Assessment Report of the Intergovernmental Panel on Climate Change. [Core Writing
        Team, R.K. Pachauri and L.A. Meyer (eds.)]. IPCC, Geneva, Switzerland, 151 pp.

     Jones, L and E. Samman. 2016. “Measuring subjective household resilience: insights from Tanzania.” Working Paper,
        BRACED, London, UK. Retrieved from https://www.odi.org/sites/odi.org.uk/files/resource-documents/10651.pdf

     Oxfam. 2015. “Resilience in Thailand: Impact evaluation of the project ‘Development and scaling up of a climate change
        community-based adaptation model for food security.’” Effectiveness Review Series 2014–15. Retrieved from: http://
        reliefweb.int/sites/reliefweb.int/files/resources/er-resilience-thailand-effectiveness-review-141215-en.pdf

     Stern, E., N. Stame, N. Mayne, and K. Forss. 2012. “Broadening the Range of Designs and Methods for Impact Evaluations.”
         DFID Working Paper 38, UK Department for International Development, London, UK. Retrieved from: https://www.gov.
         uk/government/uploads/system/uploads/attachment_data/file/67427/design-method-impact-eval.pdf

     Silva-Villanueva, P., C. Gould, and G. Gregorowski. 2016. BRACED M&E Guidance Notes. Retrieved from: http://www.braced.
          org/contentAsset/raw-data/761757df-7b3f-4cc0-9598-a684c40df788/attachmentFile

     UNDP (United Nations Development Program). 2012. Final grantee project evaluation CBA pilot project. Retrieved from:
       https://erc.undp.org/evaluation/documents/download/7554

     Vogel, I. 2012. ESPA Guide to Working with Theory of Change for Research Projects. Ecosystem Services for Alleviation of
        Poverty. Retrieved from http://www.espa.ac.uk/files/espa/ESPA-Theory-of-Change-Manual-FINAL.pdf

     Wilson, D. and G. Yaron. 2016. “Laying the foundations for measuring resilience.” BRACED Knowledge Manger Working
         Paper, London, UK. Retrieved from: http://itad.com/wp-content/uploads/2016/09/BRCJ4791_Working_Paper_09.16_
         WEB.pdf

     World Bank. 2013. Results Frameworks and M&E: A Guidance Note. Prepared by OPCS, World Bank, Washington, DC, USA.
        Retrieved from: http://siteresources.worldbank.org/PROJECTS/Resources/40940-1365611011935/Guidance_Note_
        Results_and_M&E.pdf




      
ANNEXES                                                                                                51




Annexes



Annex 1: Feasibility Checklist for Planning a Project/Program Evaluation


    Program Design Elements
     •	 The project’s/program’s objectives, outputs, and activities are clear enough to be able to
        evaluate progress, results and/or impact.
     •	 There is adequate and reliable program information available (e.g., monitoring data) to
        engage in an evaluation.
     •	 The project’s/program’s stage is appropriate for the envisioned evaluation.
     •	 The project/program has adequate sustainability and stability. Political will and financial
        resources exist to sustain the intervention while the evaluation is being conducted, and the
        program design is not likely to change abruptly during the evaluation period.

    Resource and Logistical Considerations
     •	 The evaluation manager and/or commissioning agency staff have sufficient time for this
        evaluation during the proposed timeframe.
     •	 Stakeholders who have an interest in the evaluation will have the appropriate time and
        opportunities to participate.
     •	 Sufficient funds are available for evaluation design and data collection and analysis, or
        additional funds can be raised or leveraged as needed.

    Utility
     •	 There is a high probability that the evaluation will be used to improve the project/program.
     •	 The proposed evaluation design is appropriate, given available resources.
     •	 Intended users have expressed interest in the findings.
    Source: IEG 2015.




 
52                                                 E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Annex 2: Data Collection Methods and Tools
     The following table provides a summary of the main qualitative and quantitative data collection methods
     and tools.

     Method                                   Description                                   Advantages                                     Disadvantages
                                  Systematic analysis of existing              •	 Does not interrupt the                     •	 Time consuming
         Document review




                                  documentation, including                        program                                    •	 Data is limited by what exists
                                  quantitative and descriptive                 •	 Little or no burden on                        and is available
                                  information about the initiative,               others                                     •	 Data may be incomplete
                                  its outputs, and its outcomes.
                                                                               •	 Can provide historical or                  •	 Documentary evidence can be
                                  Includes documentation from
                                                                                  comparative data                              difficult to code and analyze
                                  capacity development activities,
                                  donor reports, and other evidence            •	 Introduces little bias

                                  Use of a detailed observation                •	 Allows one to learn about                  •	 Time consuming
                                  form to record information on-site              the project/program as it is               •	 Having an observer can
         Observation




                                  about how a program operates                    occurring                                     introduce bias
                                                                               •	 Can reveal unanticipated                   •	 Subject to (site) selection bias
                                                                                  information of value
                                                                                                                             •	 Can be difficult to categorize or
                                                                               •	 Flexible in the course of                     interpret observed behaviors
                                                                                  collecting data
                                                                                                                             •	 Can be expensive

                                  Collection of information directly           •	 Many standardized                          •	 Sample may not be
                                  from a defined group of people                  instruments available                         representative
                                  to (1) get a general idea of a               •	 Can be anonymous                           •	 May have low return rate
                                  situation, (2) generalize about a
                                                                               •	 Allows for a large sample                  •	 Wording can bias responses
                                  population, or (3) to get a total
                                  count of a particular characteristic         •	 Standardized responses                     •	 Closed-ended or brief responses
         Survey




                                                                                  are easy to analyze                           may not provide the “whole
                                  Surveys can also be used to
                                                                               •	 Able to obtain a large                        story”
                                  assess the quantity and quality of
                                  infrastructure and assets                       amount of data quickly                     •	 Trained specialists are required
                                                                               •	 Relatively low cost                           for survey design, planning, and
                                                                                                                                data analysis
                                                                               •	 Convenient for
                                                                                  respondents                                •	 Larger surveys can be costly and
                                                                                                                                time-consuming to implement

                                  Solicitation of responses                    •	 Often better response rate                 Time consuming
     (face-to-face,




                                  to questions designed to                        than surveys                               •	 Requires skilled interviewer
       telephone)
        Interview




                                  obtain in-depth information                  •	 Allows flexibility in                      •	 Less anonymity for respondent
                                  about a person’s impressions                    questions/probes
                                  or experiences; can be fully                                                               •	 Qualitative data more difficult to
                                                                               •	 Allows more in-depth                          analyze
                                  structured, semi-structured, or
                                                                                  information to be gathered
                                  unstructured

                                  Small group (6 to 8 people)                  •	 Multiple perspectives                      •	 Requires skilled facilitator
                                  interviews to explore: in-depth                 collected in one session                   •	 Limited number of questions
         Focus group interviews




                                  stakeholder opinions; similar                •	 Allows for in-depth                           can be asked
                                  or divergent points of view;                    discussion                                 •	 Group setting may inhibit, bias,
                                  judgments about a development
                                                                               •	 Group interaction can                         or influence opinions
                                  initiative or policy; gather
                                                                                  produce greater insight                    •	 Data can be difficult to analyze
                                  information about their behaviors,
                                  understanding and perceptions of             •	 Can be conducted in short                  •	 Not appropriate for all topics or
                                  an initiative; or collect information           timeframe                                     populations
                                  around tangible and non-tangible             •	 Can be relatively
                                  changes resulting from an initiative            inexpensive compared to
                                                                                  interviews
ANNEXES                                                                                                                                                53




 Method                                   Description                    Advantages                                 Disadvantages

                                 Qualitative in-depth            •	 Can provide insight on the         •	 Subject to sampling bias
                                 interviews, often one-on-          nature of problems and             •	 Must have some means to verify
                                                                    give recommendations for              or corroborate information
                                 one, with a wide range of          solutions
      Key informant interviews




                                 stakeholders who have first-    •	 Can provide different
                                 hand knowledge about the           perspectives on a single
                                 initiative’s operations and        issue or on several
                                                                    issues	
                                 context. These experts can
                                 provide particular knowledge
                                 and understanding of
                                 problems and recommend
                                 solutions. The majority of
                                 questions are open-ended and
                                 meant to stimulate discussion


Advances in, and the spread of, Information and Communication Technology (ICT) have opened up a
wide range of new opportunities for innovations in resilience monitoring and evaluation (M&E). These
include:
  •	 Mobile data collection (MDC): the use of mobile phones, tablets, or PDAs for data collection.
     There are many mobile phone applications (referred to as platforms) which allow evaluators to build
     an MDC survey for Computer Assisted Personal Interviewing (CAPI). These platforms enable the
     customization of a survey to include specific data from photographs and voice recordings, to GPS
     coordinates. Platforms vary in ease of use and features, with some of the most notable available free
     of charge—including the World Bank Platform.21 Such platforms offer many benefits when compared
     to hand-written surveys, including reduction of coding/input errors and increased speed and
     efficiency in cleaning and analyzing data.
  •	 Crowd-sourcing: with the advance of mobile phone access, crowd-sourcing for data collection is
     an emerging method for data capture. Crowd-sourcing is accomplished by allowing, requesting,
     and empowering individuals to send in their observations, data, or information through their mobile
     devices.
  •	 Remote-sensing: advances in technology have increased the availability of remote sensing data,
     making the use of remote sensing for M&E of crop yields, land degradation, soil moisture content,
     irrigation and drainage system performance, etc. technically and economically feasible.




21	   World Bank's CAPI software is available from: http://go.worldbank.org/CALISV6BF0; Open Data Kit (ODK) provides another useful platform that is
available from: https://opendatakit.org/
54                                   E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     Annex 3: Resilience Indicator Frameworks
     The following table provides a selection of recently conceived indicators and measurement frameworks
     useful for measuring changes in the levels of resilience at the household and community level.

                         Indicator                                                                    Description
         Resilience Index for Households                    The indicator includes six dimensions: income and food, services,
         [www.fao.org/3/a-i4102e.pdf]                       assistance, assets, adaptive capacity, and stability.

         (FAO 2013)                                         The Resilience Index has also been incorporated into an econometric
                                                            approach, the Resilience Index Measurement and Analysis (RIMA)
                                                            model [http://www.fao.org/resilience/background/tools/rima/en/],
                                                            which is used to compare household livelihood groups.

         Resilience Framework                               Two resilience modules have been introduced in the IFAD household-
         [https://www.ifad.org/                             and community-level questionnaires for impact evaluation: ex ante
         documents/10180/338cf851-0ff2-4589-                measures of household assets, livelihood capitals, and initial conditions,
         8a0f-da616cf43751]                                 as well as measures related to household risk aversion and risk
                                                            management strategies (ranked and scored by self-rated importance
         (IFAD 2015)                                        and occurrence). Modules can be expanded with ex post metrics,
                                                            ranking, and scoring adaptive capacity by self-rated importance and
                                                            occurrence after a particular shock has occurred.

         DFID Key Performance Indicator 4                   KPI 4 is an outcome indicator under the UK Government’s International
         [https://www.gov.uk/dfid-research-                 Climate Fund (ICF) most notably used in DFID’s Building Resilience and
         outputs/final-report-assessing-                    Adaptation to Climate Extremes and Disasters (BRACED) program.
         the-impact-of-icf-programmes-on-                   It measures the number of people with improved resilience due to
         household-and-community-resilience-to-             a project intervention. The specific context of a project determines
         climate-variability-and-climate-change]            the set of diverse measurement processes that can be applied. One
                                                            key step of the process in measuring the KPI is the design of context-
         (Brooks et al. 2014)                               specific resilience indicators that capture how project activities affect the
                                                            resilience of households as defined the project’s ToC.

         The Toolkit for Indicators of Resilience           Presents a participatory “assessment workshop” approach, involving
         in Socio-Ecological Production                     the discussion and scoring of 20 indicators designed to capture a
         Landscapes and Seascapes                           community’s perceptions of factors affecting the resilience of their
         [https://www.bioversityinternational.              landscapes and seascapes. The participation of the local community
         org/e-library/publications/detail/                 and stakeholders allows them to evaluate current conditions and reach
         toolkit-for-the-indicators-of-resilience-in-       agreement on priority actions.
         socio-ecological-production-landscapes-
         and-seascapes/]
         (Bergamini et al. 2013)


      
ANNEXES                                                                                                         55




Annex 4: Contents of a Terms of Reference (ToR) for Evaluation of a
Resilience-Building Project/Program
1.	 Background and Rationale
  •	 Briefly describe the project/program to be evaluated. This section should provide information
     about the project/program to be evaluated–e.g., what is the main objective and strategy of the
     project/program? What is its logic or theory of change (ToC)? What is the geographical scope and
     timeframe? Who are key stakeholders? What is the project/program’s budget?
  •	 Describe the rationale, background and overarching purpose of the evaluation. Why this
     evaluation, at this point of time? Is the purpose accountability, learning, or both? Will the evaluation
     be used to decide on future funding? To provide input to new strategy?


2.	 Specific Objectives of the Evaluation and EQs (Step 1)
  •	 Describe the scope, timeframe, objectives, and target audience of the evaluation. This section
     should describe the focus of the evaluation, including the time period, types of activities, target
     groups, etc. to be included in the evaluation of the resilience-building project/program.
  •	 Describe the EQs. List the key specific questions the evaluation should answer.


3.	 Evaluation Design and Approach (Step 3 and 4)
  •	 Describe the approach and methodologies to be used. What design should be used? Why is
     this design appropriate? What collection methods and tools should be used? How should it be
     conducted? What level of stakeholder engagement is expected?


4.	 Decision Making and Management (Step 2)
  •	 Describe the management arrangements for the implementation of the evaluation. This section
     should describe any decision-making arrangements (such as an advisory group or management
     team) in terms of their organization and function. It should describe the participation of other
     stakeholders. It should also outline the key responsibilities of the World Bank in the process of the
     evaluation and identify the logistical support needed.
  •	 Describe the guiding principles of the evaluation. What research ethics or procedures should the
     evaluator follow?
  •	 Describe the evaluation team composition/professional qualifications required for the
     evaluation. Does the evaluation require an individual evaluator or a team of evaluators? What
     specific expertise and skills are required?


5.	 Deliverables and Schedule
  •	 Describe expected outputs and timing. Describe the tasks, outputs, and reporting requirements
     (reports, presentations briefs, etc.), along with proposed timing, who will use them, and how they
     will be used. Include the frequency and types of meetings expected to be held with the evaluator.
56                           E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     6.	 Budget and Payment
       •	 Specify the amount budgeted for the evaluation, clearly stipulating what the figure includes. Or, if
          the budget is flexible, evaluators may be asked to provide their own estimates based on tasks they
          propose. Any pertinent details related to payment should be included in this section.


     7.	 Submission Guidelines and Selection Criteria
       •	 If the ToR is part of a competitive process to identify potential evaluators, the ToR should provide
          instructions regarding the proposal format, content, and submission process.


     8.	 Additional References or Resources
       •	 To the extent possible, the ToR should identify useful information sources for the evaluator. The
          ToR should be viewed as an important body of knowledge to be drawn on while planning and
          conducting the evaluation. Easily accessible references may be listed in the text of the ToR, or as
          annexed materials.
ANNEXES   57
58                               E VA L U AT I O N O F R E S I L I E N C E - B U I L D I N G O P E R AT I O N S : O P E R AT I O N A L G U I D A N C E PA P E R




     CLIMATE CHANGE | SUSTAINABLE DEVELOPMENT
